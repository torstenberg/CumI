---
title: Assessment of the cumulative impact from physical pressures on benthic biotopes in the Baltic Sea using the CumI indicator
author: Torsten Berg, MariLim
date: 2022-08-31
output: html_document
editor_options: 
  chunk_output_type: console
---

# How to use this document
This is an R markdown document. The R code within this document can be executed using the R `library(knitr)`:

```{r help-eval-code, eval=FALSE}
library(knitr)
# purl() is the same as knit(..., tangle=TRUE)
source(purl("CumI-assessment.Rmd"))
```

The documentation can be produced together with executing the R code using:

```{r help-make-doc, eval=FALSE}
library(rmarkdown)
library(knitr)
render("CumI-assessment.Rmd")
```

If you do not want to evaluate the R code, but just render the document, use `knitr::opts_chunk$set(eval=FALSE)` before rendering.

# General setup

For the assessment for work with this script, all data files need to be present on your computer. The data are GIS files from various sources and they need to have specific file names and attribute table columns to work directly with this script. A folder "Data" comes together with this script and enables you to run the current assessment without changing the script, as long as the script is in the same directory as the 'Data' folder and the Data folder is filled witht the necessary data folders and fines:

Set the directory of the data folder in the following code chunk.

```{r setup}
# --> YOU SHOULD CHANGES THIS LINE FOR YOUR SETUP ON YOUR OWN MACHINE <--
myDir <- "/Users/Torsten/Marilim/OneDrive/OneDrive - MariLim Gesellschaft für Gewässeruntersuchung mbH/MSRL/CumI-R/Data-2022"
```

# R packages to use
The R code uses the following libraries which should be installed first (if not present):

```{r}
n1 <- Sys.time()
print(paste("--- CumI ---: starting at",n1,sep=" "))
print("--- CumI ---: loading libraries ...")
library(dplyr)
# library(naniar)
library(stringr) # using str_detect
library(tibble)
library(sf)
library(rgdal) # for species raster data
# library(knitr) # already done above if needed
```

# Some R functions

```{r include=FALSE}
print("--- CumI ---: defining some R functions ...")
```

## General GIS-related functions

R has no function corresponding to a true union in GIS. `st_union` in the sf library is not equivalent. Since we need lots of real union operations here, we need a custom function. The following code ist from [stackowerflow](https://stackoverflow.com/questions/54710574/how-to-do-a-full-union-with-the-r-package-sf) and illustrates the process. It is the basis of our function:

```{r eval=FALSE}
a1 <- st_polygon(list(rbind(c(0, 10), c(45, 10), c(45, 90), c(0, 90), c(0, 10))))
a2 <- st_polygon(list(rbind(c(45, 10), c(90,10), c(90, 90), c(45, 90), c(45, 10))))
b1 <- st_polygon(list(rbind(c(15, 5), c(75, 5), c(75, 50), c(15, 50), c(15, 5))))

a <- st_sf(station=c(1, 2), geometry=st_sfc(a1, a2))
b <- st_sf(type="A",	geometry=st_sfc(b1))

st_agr(a) = "constant" #to avoid warnings, but see https://github.com/r-spatial/sf/issues/406
st_agr(b) = "constant"

#Operations
plot(st_geometry(st_union(a,b)))

op1 <- st_difference(a,st_union(b)) #notice the use of st_union()
plot(st_geometry(op1), border="red", add=TRUE)

op2 <- st_difference(b, st_union(a)) #notice the order of b and a and st_union()
plot(st_geometry(op2), border="green", add=TRUE)

op3 <- st_intersection(b, a) #notice the order of b and a
plot(st_geometry(op3), border="blue", add=TRUE)

# union <- rbind(op1, op2, op3) #Error because op1 (op2) doesn't have the column "type" ("station")
#> Error in match.names(clabs, names(xi)): names do not match previous names

op11 <- dplyr::mutate(op1, type=NA)
op22 <- dplyr::mutate(op2, station=NA)

union <- rbind(op11, op22, op3)
```

From this, we can make a union function that can work with arbitrary sf objects:

```{r eval=FALSE}
library(plyr)

my_union_sf <- function(a,b) {
	#
	# function doing a real GIS union operation such as in QGIS or ArcGIS
	#
	# a - the first sf
	# b - the second sf
	#
	st_agr(a) = "constant"
	st_agr(b) = "constant"
	op1 <- st_difference(a,st_union(b))
	op2 <- st_difference(b, st_union(a))
	op3 <- st_intersection(b, a)
	union <- rbind.fill(op1, op2, op3)
	return(st_as_sf(union))
}
```

Since this custom sf function is very slow (and I mean: veeeery slow), we explore another possibility provided by the raster library which, however, involves some transforming back and forth to sp Spatial\* objects (SpatialPolygonsDataFrame):

```{r eval=FALSE}
library(sp) # used by 'raster'
library(raster) # provides: raster::union()

my_union_raster <- function(a,b,sf=TRUE) {
	#
	# function doing a real GIS union operation such as in QGIS or ArcGIS
	# on Spatial* objects (from the sp library)
	#
	# a - the first sf or Spatial* object
	# b - the second sf or Spatial* object
	# sf - whehter or not to convert the output to an sf object
	#
	# when an objects is not a Spatial* object, it will be converted first
	#
	if (! class(a)[1] == "SpatialPolygonsDataFrame") {a <- as_Spatial(a)}
	if (! class(b)[1] == "SpatialPolygonsDataFrame") {b <- as_Spatial(b)}
	res <- raster::union(a,b)
	if (sf) {return(as(res,"sf"))} else {return(res)}
}
```

Unfortunately, also this function turns out to be quite slow ...

If a recent version of QGIS is present (version 3.14.16 or newer), we therefor should utilize the function `qgis_run_algorithm` and let the union be done by QGIS. This will increase the performance by many magnitudes! You do not need to know how QGIS works in order to use this function. R takes care of it all. This function has the additional benefit to print out a percentage of the progress, so you can see how long to wait for the next union:

```{r}
# needs QGIS 3.14.16 or newer
# Installation:
# install.packages("remotes")
# remotes::install_github("paleolimbot/qgisprocess")
library(qgisprocess)

my_union <- function(a,b) {
	st_agr(a) = "constant" #to avoid warnings, but see https://github.com/r-spatial/sf/issues/406
	st_agr(b) = "constant"
	result <- qgis_run_algorithm(
		"native:union",
		INPUT = a,
		OVERLAY = b,
		OVERLAY_FIELDS_PREFIX = '')
	# read the resulting union, get rid of the produced "fid_" columns and make sure the geometry column is correctly named:
	result <- sf::read_sf(qgis_output(result, "OUTPUT")) %>% dplyr::select(-contains("fid_")) %>% rename_geometry("geometry")
	# sometimes, the union results in some MULTILINESTRINGS - we must delete those:
	if (st_geometry_type(result,by_geometry=FALSE) == "GEOMETRY") {
		cumi_message("... deleting MULTILINESTRINGs from last union ...")
		result <- result %>% filter(st_geometry_type() %in% c("POLYGON","MULTIPOLYGON"))
	}
	return(result)
}
```

If you can't use QGIS, you will need to rename one of the first two union functions to `my_union` (and rename the QGIS function to something else) and live with a very poor performance, meaning to wait hours and hours for some GIS union processing (I don't even know how long it takes because I always stopped the execution after 1–2 hours).


Sometimes, we need to rename the geometry column of an sf object, since sf itself will give it some weird names:

```{r}
rename_geometry <- function(g, name){
	#
	# rename the geometry columns (sfc) to a user-defined name
	# (taken from: https://gis.stackexchange.com/questions/386584/sf-geometry-column-naming-differences-r)
	#
	# g - sf object to rename the geometry column for
	# name - the name string to be used for the geometry column
	#
	current = attr(g, "sf_column")
	names(g)[names(g)==current] = name
	st_geometry(g)=name
	return(g)
}
```


## CumI-specific functions
The actual assessment using the CumI applies a range of 'matrix operations' where e.g. sensitivity of a given biotope is combined with the magnitude of pressure. This is done using some fixed rules. These rules and the R function to use them are given below.

The first rule combines resilience and resistance of a biotope to derive the resulting biotope sensitivity:

```{r}
print("--- CumI ---: defining CumI objects and functions ...")

# the sensitivity matrix:
cumi_sensi_matrix <- tribble(
	~resistance, ~resilience_verylow, ~resilience_low, ~resilience_moderate, ~resilience_high,
	"very low",  "high",				  "high",			 "moderate",			  "moderate",
	"low",		 "high",				  "moderate",		"moderate",			  "low",
	"moderate",  "moderate",			 "moderate",		"low",					 "very low",
	"high",		"moderate",			 "low",			  "low",					 "very low"
)


# a function to retrieve the sensitivity:
cumi_get_sensi <- function(resist,resil) {
	#
	# function returning the sensitivity given the resilience
	# and the resistance as strings
	#
	# resist - the resistance as string
	# resil - the resilience as string
	#
	resil <- paste("resilience_",gsub(" ", "", resil, fixed = TRUE),sep="")
	result <- subset(cumi_sensi_matrix,resistance==resist)[[resil]]
	if (is.null(result)) {
		return('none')
	} else {
		return(result)
	}
}
```

The second rule combines biotope sensitivity and the physical magnitude of pressure (= MOP) to derive the assumed impact:

```{r}
cumi_impact_matrix <- tribble(
	~sensitivity, ~MOP_high, ~MOP_moderate, ~MOP_low,	~MOP_verylow,
	"high",		 "high",	 "high",		  "m2",		 "m1",
	"moderate",	"high",	 "m3",			 "m1",		 "low",
	"low",		  "m2",		"m1",			 "low",		"very low",
	"very low",	"m1",		"low",			"very low", "very low"
)

	  
cumi_get_impact <- function(MOP,sensi) {
	#
	# function returning the impact given the MOP
	# and the sensitivity as strings
	#
	# MOP - MOP category as string
	# sensi - sensitivity category as string
	#
	if (is.na(MOP)) {return("none")}
	if (is.na(sensi)) {return("none")}
	if (MOP == "loss") {return("loss")}
	MOP <- paste("MOP_",gsub(" ", "", MOP, fixed = TRUE),sep="")
	result <- subset(cumi_impact_matrix,sensitivity==sensi)[[MOP]]
	if (is.null(result)) {
		return('none')
	} else {
		if (identical(result,character(0))) {print(paste(MOP,"and",sensi,"lead to null"))}
		return(result)
	}
}
```

The third rule combines two impacts when these are cumulated in the last step of the assessment:

```{r}
# the cumulation matrix:
cumi_cumulation_matrix <- tribble(
	~imp1,		 ~imp2_high, ~imp2_m3, ~imp2_m2, ~imp2_m1, ~imp2_low, ~imp2_verylow,
	"high",		"loss",	  "loss",	"high",	"high",	"high",	 "high",
	"m3",		  "loss",	  "loss",	"high",	"m3",	  "m3",		"m3",
	"m2",		  "high",	  "high",	"m3",	  "m2",	  "m2",		"m2",
	"m1",		  "high",	  "m3",	  "m2",	  "m2",	  "m1",		"m1",
	"low",		 "high",	  "m3",	  "m2",	  "m1",	  "low",	  "low",
	"very low",  "high",	  "m3",	  "m2",	  "m1",	  "low",	  "very low"
)

# a function to retrieve the cumulative impact:
cumi_get_cumulation <- function(i1,i2) {
	#
	# function returning the cumulative impact
	# given two impacts that act at the same time
	# and at the same place
	#
	# i1 - the first impact category as string
	# i2 - the second impact category as string
	#
	# The following test needs to come first, because we cannot use NA values in the code further below:
	if (is.na(i1)) {i1 == 'none'}
	if (is.na(i2)) {i2 == 'none'}
	if (i1 == 'none') {return(i2)}
	if (i2 == 'none') {return(i1)}
	#
	if (i1 == "loss" || i2 == "loss" ) {return("loss")}
	#
	i2 <- paste("imp2_",gsub(" ", "", i2, fixed = TRUE),sep="")
	result <- subset(cumi_cumulation_matrix,imp1==i1)[[i2]]
	if (is.null(result)) {
		return('none')
	} else {
		return(result)
	}
}
```

Some of the pressures work with a buffering. This means, the pressure is acting on a spatially larger area than the actual footprint (polygon, line or point data) of the pressure source. These pressures are listed here. The intensity of the pressure decreases with increasing distance from the pressure. The buffer distances in the table below represent the maximum distance (in metres) for the specific pressure intensity category, measured from the pressure source. As an example, a buffer distance of 50 for a high intensity means a buffer from 0–50 metres around a pressure source (which can be a point, a line or a polygon). A subsequent moderate intensity up to 100 then is an adjacent buffer 50–100 metres around a pressure source. So, the number in a specific columns is always the radius of the outer border of a zone, not its width.

The table also lists whether there is a buffer zone counting as 'loss' (~buffer\_loss) and whether the pressure footprint itself (in case of polygone data) is treated as loss (~footprint\_as\_loss).

```{r}
#
# buffer models for pressure intensity
#
# in the pressure column:
#	C = under construction
#	O = in operation
#	M = maintenance
#	CAP1, CAP2 = capital
#	OWF = offshore wind farm
#
cumi_buffers <- tribble(
	~pressure,		~description,						~buffer_loss,  ~buffer_high, ~buffer_moderate, ~buffer_low,	~buffer_verylow,  ~footprint_as_loss,
	#--------------|------------------------------|--------------|-------------|-----------------|--------------|------------------|------------------
	"extraction",	"sand and gravel extraction",  0,				 50,			  100,				  250,			  500,					 1,
	"depositing",	"deposit of dredged material", 0,				 50,			  100,				  250,			  500,					 0,
	"dredging M",	"maintenance dredging",		  0,				 50,			  100,				  250,			  500,					 0,
	"dredging CAP", "capital, areas",				  0,				  0,				 0,					 0,				 0,					 1,
	"dredging CAP1","captial, points, <= 5000m3", 25,				 25,				25,					25,				25,					 1,
	"dredging CAP2","capital, points, > 5000m3",  50,				 50,				50,					50,				50,					 1,
	"cable C",		"cable",							  0,				  0,			  550,				  600,			 1000,					 0,
	"cable O",		"cable",							  1.5,				1.5,			  1.5,				  1.5,			  1.5,				  0,
	"pipeline C",	"pipelines",						 0,				  0,			  550,				  600,			 1000,					 0,
	"pipeline O",	"pipelines",						15,				 15,				15,					90,			  315,					 0,
	"platform C",	"platforms",						 0,				  0,			  550,				  600,			 1000,					 0,
	"platform O",	"platforms",						25,				 25,				25,					25,				25,					 0,
	"OWF C",		  "offshore wind farms",			0,				  0,			  550,				  600,			 1000,					 0,
	"OWF O",		  "offshore wind farms",		  30,				 30,				40,					50,			  130,					 0,
	"coastalDef C", "coastal defence",				 0,				 50,			  100,				  250,			  500,					 0,
	"coastalDef O", "coastal defense",				50,				 50,				50,					50,				50,					 0,
	"mariculture",  "mariculture",					150,				150,			  400,				  650,			 1150,					 1,
	"harbour O",	 "harbour",						 200,				  0,				 0,					 0,				 0,					 0
)
```


The following function uses the above buffer models to calculate the concrete spatial extent of the various intensity zones for a given pressure:

```{r}
cumi_buffer_intensity <- function(pressureData,pressureBufferModel) {
	#
	# build an sf object that holds all different intensity zones and a loss zone
	# for a specific pressure
	#
	# pressureData - the sf objects holding the raw pressure data as points, lines or polygons
	# pressureBufferModel - the symbolic name of the buffer model in the tribble 'cumi_buffer'
	# (column ~pressure)
	#
	
	footprint <- filter(cumi_buffers,pressure==pressureBufferModel)[["footprint_as_loss"]]
	loss <- filter(cumi_buffers,pressure==pressureBufferModel)[["buffer_loss"]]
	vl	<- filter(cumi_buffers,pressure==pressureBufferModel)[["buffer_verylow"]]
	l	 <- filter(cumi_buffers,pressure==pressureBufferModel)[["buffer_low"]]
	m	 <- filter(cumi_buffers,pressure==pressureBufferModel)[["buffer_moderate"]]
	h	 <- filter(cumi_buffers,pressure==pressureBufferModel)[["buffer_high"]]
	
	# 'very low' zone:
	if (vl-l > 0) {
		b_verylow <- st_buffer(pressureData,vl)
		b_low <- st_buffer(pressureData,l)
		zone_verylow <- st_sf(st_difference(st_union(b_verylow),st_union(b_low))) %>%
		  st_cast("POLYGON") %>% mutate(intensity="very low") %>% rename_geometry("geometry")
		output <- zone_verylow
	}
	
	# 'low' zone:
	if (l-m > 0) {
		if (! exists("b_low")) {b_low <- st_buffer(myLayer,l)}
		b_moderate <- st_buffer(pressureData,m)
		zone_low <- st_sf(st_difference(st_union(b_low),st_union(b_moderate))) %>%
		  st_cast("POLYGON") %>% mutate(intensity="low") %>% rename_geometry("geometry")
		if (exists("output")) {
		  output <- add_row(output,zone_low)
		} else {
		  output <- zone_low
		}
	}
	
	# 'moderate' zone:
	if (m-h > 0) {
		if (! exists("b_moderate")) {b_moderate <- st_buffer(pressureData,m)}
		if (! exists("b_high")) {b_high <- st_buffer(pressureData,h)}
		zone_moderate <- st_sf(st_difference(st_union(b_moderate),st_union(b_high))) %>%
		  st_cast("POLYGON") %>% mutate(intensity="moderate") %>% rename_geometry("geometry")
		if (exists("output")) {
		  output <- add_row(output,zone_moderate)
		} else {
		  output <- zone_moderate
		}
	}
	
	# 'high' zone:
	if (h-loss > 0) {
		if (! exists("b_high")) {b_high <- st_buffer(pressureData,h)}
		if (! exists("b_loss")) {b_loss <- st_buffer(pressureData,loss)}
		zone_high <- st_sf(st_difference(st_union(b_high),st_union(b_loss))) %>%
		  st_cast("POLYGON") %>% mutate(intensity="high") %>% rename_geometry("geometry")
		if (exists("output")) {
		  output <- add_row(output,zone_high)
		} else {
		  output <- zone_high
		}
	}
	
	# 'loss' zone:
	if (loss > 0) {
		if (! exists("b_loss")) {b_loss <- st_buffer(pressureData,loss)}
		zone_loss <- st_union(b_loss) %>% st_sf() %>% st_cast("POLYGON") %>% mutate(intensity="loss") %>% rename_geometry("geometry")
		if (exists("output")) {
		  output <- add_row(output,zone_loss)
		} else {
		  output <- zone_loss
		}
	}
	
	# footprint zone as 'loss':
	if (footprint & st_geometry_type(pressureData,by_geometry=FALSE) != "POINT") {
		zone_footprint <- st_buffer(pressureData,0) %>% st_union() %>% st_sf() %>%
			st_cast("POLYGON") %>% mutate(intensity="loss") %>% rename_geometry("geometry")
		if (exists("output")) {
		  output <- add_row(output,zone_footprint)
		} else {
		  output <- zone_footprint
		}
	}
	
	return(output)
}
```

In order to make the script a bit more concise, a function combining some standard steps into one go is used. It reads the opened pressure GIS layer, assuming it is having a valid geometry/topology and the correct coordinate system, applies the buffer model, clips the resulting layer at the boudary of the biotope layer, includes it into the final impact layer and calculates the impact (and deletes the now superfluous 'int' column):


```{r}
cumi_process_pressure <- function(pressureData,pressureType,suffix) {
	#
	# apply a buffer model to a GIS layer with pressures,
	# clip at biotope layer boundary and combine with partial impact layer
	#
	# The function uses the global `impact_map` sf layer to add the pressure
	# Therefor, the output of this function should be assigned to `imapct_map` again
	#
	# pressureData - sf layer with pressure data
	# pressureType - layer type from tribble `cumi_buffers`, column ~pressure
	# suffix - suffix to append to the string "impact_" as name for the column to be filled with the calculated impacts
	#
	# mapply() needed in mutate() function since mutate() operates on vectors and the cumi_get_impact() function not.
	# Also, unname() needed in mutate() function since mapply() will return a named object and we only want the vector inside.
	# We need the namespace identifier in mutate() and select() as otherwise the plyr functions are called.
	# Also note, from here on we typically need to repeatedly cast impact_map to MULTIPOLYGON as otherwise
	# we will get an error such as "Error in CPL_geos_op2(op, x, y) : attr classes has wrong size: please file
	# an issue)" which comes from the first st_difference() in my_union_sf()
	#
	intensity_layer <- cumi_buffer_intensity(pressureData,pressureType)
	column <- paste("impact_",suffix,sep="")
	cumi_message("... unioning ...")
	result <- st_cast(impact_map,"MULTIPOLYGON") %>% 
		my_union(intensity_layer) %>% 
		dplyr::mutate( {{ column }} := unname(mapply(cumi_get_impact,intensity,sens))) %>% 
		dplyr::select(-intensity) %>% filter(! is.na(Biotope))
	cumi_message("Done!")
	return(result)
}
```


Last, and not least, we want some regular feedback from the script, since some of the operations (especially the GIS union) are taking some time:


```{r}
get_running_time <- function(n1,n2) {
	#
	# return the difference between to Sys.time() values an minutes,
	# nicely formatted
	#
	# n1, n2 - first and second Sys.time() values
	#
	min <- (as.numeric(n2)-as.numeric(n1))/60
	min2 <- format(min, digits=4, decimal.mark=".")
	hours <- format(min/60, digits=3, decimal.mark=".")
	return(paste(min2,"minutes = ",hours,"hours"))
}

cumi_message <- function(msg) {
	#
	# print some nice, friendly message
	#
	# msg - text of the message to print
	#
	msg <- paste("--- CumI --- (now running for ", get_running_time(n1,Sys.time()),"): ",msg,sep="")
	cat(paste(" ",msg," "," ",sep="\n"))
	flush.console()
}
```

# The assessment

## Setup
Everything should be going on in the same coordinate system. So, we define this variable in order to be able to uniformly transform to this. It is the EPSG code for "ETRS89-extended / LAEA Europe" which is typically used by HELCOM for their maps:

```{r}
cumi_message("setting up the assessment ...")
coordSystem <- 3035

# As the processing of the clipLayer and the bottom trawling pressure take veeery looong to be calculated (approx. 7 hours for bottom trawling on my machine
# and failing to report the percentage of finalization beyond the "10 %" value ...) even with the QGIS union procedure,
# a pre-calculated file is provided, based on the first part of the script up and including the processing of the bottom trawling.
#
# I.e., the pre-calculated layer already contains the biotope data combined with the bottom trawling data,
# and the pre-calculated layer already has the MOP from trawling included.
#
# You can choose to either use the pre-calculated data (set `use_pre_calculated_data` to `TRUE`) for the further process, or re-calculate it here (set it to `FALSE`).
#
use_pre_calculated_data <- FALSE

```


## The assessment area
The spatial extent of the assessment area is determined by the HELCOM Assessment Units. There are four (spatial) levels. Level 2 contains the outline of the complete assessment area of the Baltc See[^3] (called *marine area*), divided into 17 *subbasins*. This dataset is used to clip all other layers if they contains parts that are outside of this boundary.

```{r}
if (! use_pre_calculated_data) {
	cumi_message("preparing assessment area layer ...")
	area_file <- file.path(myDir,"../../Daten/HELCOM-Daten/HOLAS III/_ags_HELCOM_subbasins_2022/HELCOM_subbasins_2022.shp")
	areaLayer <- st_read(area_file) %>% dplyr::select(-c(Area_km2,Shape_Leng,Shape_Le_1,Shape_Area)) %>% st_make_valid()
}
```

To enable assigning data to specific countries, the assessment area is supplemented with country information. The countries are taken from the *EMODnet Human Actiities* data file `Emodnet_HA_OtherManagementsAreas_EEZ_20180629`. As the spatial coverage of the country data sometimes is smaller than the coverage of the assessment area, the country area was extended manually on the terrestrial side so the complete assessment area is within a specific country.

```{r}
# TODO: update available: EMODnet_HA_OtherManagementAreas_EEZ_v11_20210506
# <https://www.emodnet-humanactivities.eu/search-results.php?dataname=Exclusive+Economic+Zone>
if (! use_pre_calculated_data) {
	cumi_message("loading and suplementing country information ...")
	country_file <- file.path(myDir,"Biotopes/countries.shp")
	countryLayer <- st_read(country_file)
	areaCountryLayer <- st_intersection(areaLayer,countryLayer)
}
```


## The biotope map
The biotope map is based on the *Emodnet broad-scale seabed habitat map for Europe* (= EUSeapMap). In the first step, the original map for the Baltic Sea[^1] (dated September 2021) is used. As the Baltic part of the EUSeaMap does not include the Kattegat, part of the corresponding map for the European Atlantic and Arctic region[^2] is merged into the data (as long as it is within the assessment area). For convenience (as the Atlantic/Arctic dataset is huge) a manually clipped version if the latter dataset is used where anything roughly outside the Kattegat area has been removed.

```{r}
if (! use_pre_calculated_data) {
	biotopeBaltic_file <- file.path("/Users/Torsten/Marilim/GIS/EUSeaMap_2021/EUSeaMap 2021 Baltic_Sea GDB/C20211007_EUSeaMap_2021_Baltic_Sea.gdb")
	biotopeBalticLayer <- st_read(biotopeBaltic_file, layer="EUSeaMap_2021_Baltic") %>%
		st_transform(coordSystem) %>%
		st_make_valid() %>%
		# onyl keep the BHT column:
		select(MSFD_BBHT) %>%
		# rename geometry column so it fits to the Kattegat layer below:
		rename_geometry("geom") %>%
		rename(Biotope = MSFD_BBHT)
	# the following file was produced from the original EMODnet geodatabase in QGIS (version 3.26.1) by
	# 1. converting it to geopackage
	# 2. buffering by 0 metres (thus repairing geomerty errors)
	# 3. manually dividing objects around the Kattegat boundary
	# 4. deleting all objects outside the Kattegat
	biotopeKattegat_file <- file.path("/Users/Torsten/Marilim/GIS/EUSeaMap_2021/EUSeaMap 2021 Arctic_Atlantic GDB/EUSeaMap_2021_Kattegat-v2.gpkg")
	biotopeKattegatLayer <- st_read(biotopeKattegat_file, layer="EUSeaMap_2021_Kattegat") %>%
		st_transform(coordSystem) %>%
		st_cast("MULTIPOLYGON") %>%
		st_make_valid() %>%
		# onyl keep the BHT column and rename it to 'Biotope':
		select(MSFD_BBHT) %>%
		rename(Biotope = MSFD_BBHT)
	# now merge the Baltic with the Kattegat
	# (rbind is safe here as there is no spatial overlap and the attributes are the same):
	biotopeBalticLayer <- rbind(biotopeBalticLayer,biotopeKattegatLayer)
	# and add in the area and country information, essentially also clipping
	# everything away that is outside the assessment area:
	# (Note: this may also clip away parts of the assessment area when there is no biotope
	# information there, but as we cannot use those parts without biotope information anyway, this is ok)
	areaCountryBiotopeLayer <- st_intersection(biotopeBalticLayer,areaCountryLayer)
	# only retain the columns we need:
	areaCountryBiotopeLayer <- areaCountryBiotopeLayer %>%
		select(all_of(c("Biotope","level_2","HELCOM_ID","Territory")))
	# last step is to clean the resulting data:
	areaCountryBiotopeLayer <- areaCountryBiotopeLayer %>%
		filter(st_geometry_type(areaCountryBiotopeLayer) %in% c("POLYGON","MULTIPOLYGON")) %>%
		st_cast("MULTIPOLYGON")
}
```

Some taxa inhabiting specific areas lead to a 'high' sensitivity towards the pressures in the later process. The spatial data for these taxa is taken from HELCOM MADS (Biodiversity > Ecosystem components (BSII) > Benthic species). The taxa are the genera *Mytilus, Zostera, Furcellaria, Fucus, Chara*. We include this information into the biotope map in a new column 'sens_spec':


```{r}
cumi_message("including information of sensitive species ...")

species_folder <- file.path(myDir,"../../Daten/HELCOM-Daten/HOLAS II/Benthic species")

# this new column will hold all the species information later:
areaCountryBiotopeLayer <- areaCountryBiotopeLayer %>% mutate(sens_spec = 'none')

for(myfile in c(
		"Chara_distribution.tif",
		"Fucus_distribution_2018.tif",
		"Furcellaria_distribution.tif",
		"Mytilus_distribution.tif",
		"Zostera_marina_distribution_2018.tif"
)) {
	cumi_message("... ")
	cumi_message(myfile)
	# terra # mydata <- rast(file.path(species_folder,myfile))
	mydata <- readGDAL(file.path(species_folder,myfile))
	# convert to vector data:
	# only cells with band1 = 1 have the species, so we discard the rest:
	# terra # mydata_poly <- terra::as.polygons(zos, dissolve=FALSE)
	spdf <- as(mydata,'SpatialPolygonsDataFrame') %>% subset(band1 == 1)
	sf_data <- st_as_sf(spdf)
	myShort <- substring(myfile,1,5)
	myName <- case_when(
		myShort == "Chara" ~ "Chara",
		myShort == "Fucus" ~ "Fucus",
		myShort == "Furce" ~ "Furcellaria",
		myShort == "Mytil" ~ "Mytilus",
		myShort == "Zoste" ~ "Zostera",
		TRUE ~ "undefined"
	)
	# for Zostera, ignore any vegetation below 10m depth:
	library(terra)
	depths <- rast("/Users/Torsten/Marilim/OneDrive/OneDrive - MariLim Gesellschaft für Gewässeruntersuchung mbH/MSRL/Daten/HELCOM-Daten/Depthreliefmap/depth/w001001.adf")
	# terra # tmp_t <- terra::extract(depths,mydata_poly, 'mean')
	tmp_t <- terra::extract(depths,vect(sf_data), 'mean')
	# terra # tmp_t <- cbind(mydata_poly,tmp_t) st_as_sf() %>% filter(w001001 >= -10 | is.na(w001001))
	sf_data <- cbind(sf_data,tmp_t) %>% filter(w001001 < -10)
	# dissolve and add species information:
	sf_data <- sf_data %>% st_union() %>% st_as_sf() %>% st_cast("POLYGON") %>% mutate(spec = myName)
	# now include the data into the biotope map:
	areaCountryBiotopeLayer <- my_union(areaCountryBiotopeLayer,sf_data)
	areaCountryBiotopeLayer$sens_spec[! is.na(areaCountryBiotopeLayer$spec)] <- myName
	areaCountryBiotopeLayer <- areaCountryBiotopeLayer %>% select(-spec)
	# remove all features without biotope, they are outside the assessment area:
	areaCountryBiotopeLayer <- areaCountryBiotopeLayer %>% filter(! is.na(Biotope))
}
```

Note, the name of the taxon in the column 'sens_spec' may have been overridden one or more times when the taxa distribution overlaps spatially. So, do not count on the name of the taxon being the only one responsible for the entry.

Now, we have an initial biotope layer with the corresponding information on subbasin and country. The next step is to include data on the bottom salinity so we have all information needed to assign sensitivity values to the habitat. For this, we assign the bottom salinity from the HELCOM BALANCE project:

```{r}
# we use the original data, just converted from raster to vector form:
salinity_file <- file.path(myDir,"../../Daten/HELCOM-Daten/BALANCE Modelledbottomsalinity/Bottomsalinity-vektorisiert.shp")
salinityLayer <- st_read(salinity_file) %>% st_transform(coordSystem) %>% dplyr::select(-DN) %>% st_buffer(0)

areaCountryBiotopeSalinityLayer <- my_union(areaCountryBiotopeLayer,salinityLayer)
# Now some cleaning:
# 1. delete all polygons without biotope assignment (these are the ones from the salinity layer that lie beyond the biotope map)
# x. only retain the attributes we want:
areaCountryBiotopeSalinityLayer <- areaCountryBiotopeSalinityLayer %>%
	filter(! is.na(Biotope)) %>%
	

```

In the following step, the sensitivities will be assigned based on the biotope, salinity and country information. The current values are a result of the agreed values in the CumI report dated 2021-09-xx, supplemented by values used in the subsequent CumI assessment dated 2021-08-23 (CumI-assessment-2021-08-23T2157.gpkg; unfortunately, not all values used in the last CumI assessment were reported in the CumI report). In case of errornous multiple assignments for the same biotope/salinity combination, the value covering the larger area in the last assessment was taken. If the combination was not used, the same values were used as for the adjacent salinity class. Values for 's_surf' not yet assigned but necessary due to the new biotope map are marked `# assumed` in the following code.


```{r}
tmp <- areaCountryBiotopeSalinityLayer

# new columns 'sens' and 's_surf':
tmp <- tmp %>% mutate(sens = 'none') %>% mutate(s_surf = 'none')

# template for selection of value based on largest area (data from 'CumI-assessment-2021-08-23T2157.gpkg'):
# select sum(area) as area, '"' || Territory || '", "' || Biotope || '", "' || Sal2 || '", "' || s_surf || '",'
# as line from cumi
# group by Biotope,s_surf,Sal2
# order by Territory,biotope,Sal2
#

cumi_Sensitivities <- tribble(
	~Territory, ~Biotope,    ~Sal2,   ~sens,         ~s_surf,
	# --------------------------------------------------------
	"Denmark", "circa hard", "7.5-11", "high",        "high",
	"Denmark", "circa hard", "11-18", "high",         "high",
	"Denmark", "circa hard", "18-30", "high",         "high",
	
	"Denmark", "circa mix", "7.5-11", "high",         "low",
	"Denmark", "circa mix", "11-18", "high",          "low",
	"Denmark", "circa mix", "18-30", "high",          "low",
	"Denmark", "circa mix", ">30", "high",            "low",
	
	"Denmark", "circa mud", "7.5-11", "moderate",     "moderate",
	"Denmark", "circa mud", "11-18", "moderate",      "moderate",
	"Denmark", "circa mud", "18-30", "moderate",      "high",
	"Denmark", "circa mud", ">30", "moderate",        "high",
	
	"Denmark", "circa sand", "7.5-11", "low",         "moderate",
	"Denmark", "circa sand", "11-18", "low",          "moderate",
	"Denmark", "circa sand", "18-30", "low",          "high",
	"Denmark", "circa sand", ">30", "low",            "high",
	
	"Denmark", "infra hard", "7.5-11", "high",        "high",
	"Denmark", "infra hard", "11-18", "high",         "high",
	"Denmark", "infra hard", "18-30", "high",         "high",
	"Denmark", "infra hard", ">30", "high",           "high",
	
	"Denmark", "infra mix", "7.5-11", "high",         "low",
	"Denmark", "infra mix", "11-18", "high",          "low",
	"Denmark", "infra mix", "18-30", "high",          "high",
	"Denmark", "infra mix", ">30", "high",            "high",
	
	"Denmark", "infra mud", "7.5-11", "moderate",     "moderate",
	"Denmark", "infra mud", "11-18", "moderate",      "moderate",
	"Denmark", "infra mud", "18-30", "moderate",      "high",
	"Denmark", "infra mud", ">30", "moderate",        "high",
	
	"Denmark", "infra sand", "7.5-11", "low",         "moderate",
	"Denmark", "infra sand", "11-18", "low",          "moderate", # s_surf assumed
	"Denmark", "infra sand", "18-30", "low",          "high",
	"Denmark", "infra sand", ">30", "low",            "high",
	# --------------------------------------------------------
	"Estonia", "circa hard", "5-7", "high",           "high",
	"Estonia", "circa hard", "7.5-11", "high",        "high",
	
	"Estonia", "circa mix", "5-7", "moderate",        "high",
	"Estonia", "circa mix", "7.5-11", "moderate",     "low",
	
	"Estonia", "circa mud", "5-7", "moderate",        "moderate",
	"Estonia", "circa mud", "7.5-11", "moderate",     "moderate",
	
	"Estonia", "circa sand", "5-7", "moderate",       "moderate",
	"Estonia", "circa sand", "7.5-11", "moderate",    "moderate",
	
	"Estonia", "infra hard", "5-7", "high",           "high",
	"Estonia", "infra hard", "7.5-11", "high",        "high",
	
	"Estonia", "infra mix", "5-7", "moderate",        "moderate", # s_surf assumed
	"Estonia", "infra mix", "7.5-11", "moderate",     "moderate", # s_surf assumed
	
	"Estonia", "infra mud", "5-7", "moderate",        "moderate",
	"Estonia", "infra mud", "7.5-11", "moderate",     "moderate",
	
	"Estonia", "infra sand", "5-7", "moderate",       "moderate",
	"Estonia", "infra sand", "7.5-11", "moderate",    "moderate",
	# --------------------------------------------------------
	"Finland", "circa hard", "<5", "high",            "high",
	"Finland", "circa hard", "5-7", "high",           "high",
	"Finland", "circa hard", "7.5-11", "high",        "high", # s_surf assumed
	
	"Finland", "circa mix", "<5", "moderate",         "moderate",
	"Finland", "circa mix", "5-7", "moderate",        "moderate",
	"Finland", "circa mix", "7.5-11", "moderate",     "moderate",
	
	"Finland", "circa mud", "<5", "moderate",         "moderate",
	"Finland", "circa mud", "5-7", "moderate",        "moderate",
	"Finland", "circa mud", "7.5-11", "moderate",     "moderate",
	
	"Finland", "circa sand", "<5", "moderate",        "moderate",
	"Finland", "circa sand", "5-7", "moderate",       "moderate",
	"Finland", "circa sand", "7.5-11", "moderate",    "moderate", # s_surf assumed
	
	"Finland", "infra hard", "<5", "high",            "high",
	"Finland", "infra hard", "5-7", "high",           "high",
	"Finland", "infra hard", "7.5-11", "high",        "high", # s_surf assumed
	
	"Finland", "infra mix", "<5", "moderate",         "moderate",
	"Finland", "infra mix", "5-7", "moderate",        "moderate",
	"Finland", "infra mix", "7.5-11", "moderate",     "moderate", # s_surf assumed
	
	"Finland", "infra mud", "<5", "moderate",         "moderate",
	"Finland", "infra mud", "5-7", "moderate",        "moderate",
	"Finland", "infra mud", "7.5-11", "moderate",     "moderate",
	
	"Finland", "infra sand", "<5", "moderate",        "moderate",
	"Finland", "infra sand", "5-7", "moderate",       "moderate",
	"Finland", "infra sand", "7.5-11", "moderate",    "moderate", # s_surf assumed
	# --------------------------------------------------------
	"Germany", "circa hard", "5-7", "high",           "high",
	"Germany", "circa hard", "7.5-11", "high",        "high",
	"Germany", "circa hard", "11-18", "high",         "high",
	"Germany", "circa hard", "18-30", "high",         "high",
	
	"Germany", "circa mix", "5-7", "moderate",        "low", # s_surf assumed
	"Germany", "circa mix", "7.5-11", "moderate",     "low",
	"Germany", "circa mix", "11-18", "moderate",      "high",
	"Germany", "circa mix", "18-30", "moderate",      "high",
	
	"Germany", "circa mud", "5-7", "moderate",        "moderate", # s_surf assumed
	"Germany", "circa mud", "7.5-11", "moderate",     "moderate",
	"Germany", "circa mud", "11-18", "moderate",      "high",
	"Germany", "circa mud", "18-30", "moderate",      "high",
	
	"Germany", "circa sand", "5-7", "moderate",       "moderate",
	"Germany", "circa sand", "7.5-11", "moderate",    "moderate",
	"Germany", "circa sand", "11-18", "moderate",     "moderate",
	"Germany", "circa sand", "18-30", "moderate",     "moderate",
	
	"Germany", "infra hard", "5-7", "high",           "high",
	"Germany", "infra hard", "7.5-11", "high",        "high",
	"Germany", "infra hard", "11-18", "high",         "high",
	"Germany", "infra hard", "18-30", "high",         "high",
	
	"Germany", "infra mix", "5-7", "moderate",        "moderate",
	"Germany", "infra mix", "7.5-11", "moderate",     "low",
	"Germany", "infra mix", "11-18", "moderate",      "low",
	"Germany", "infra mix", "18-30", "moderate",      "high",
	
	"Germany", "infra mud", "5-7", "moderate",        "moderate",
	"Germany", "infra mud", "7.5-11", "moderate",     "moderate",
	"Germany", "infra mud", "11-18", "moderate",      "moderate",
	"Germany", "infra mud", "18-30", "moderate",      "high",
	
	"Germany", "infra sand", "5-7", "moderate",       "moderate",
	"Germany", "infra sand", "7.5-11", "moderate",    "moderate",
	"Germany", "infra sand", "11-18", "moderate",     "high",
	"Germany", "infra sand", "18-30", "moderate",     "high",
	# --------------------------------------------------------
	"Latvia", "circa hard", "5-7", "high",            "high",
	"Latvia", "circa hard", "7.5-11", "high",         "high",
	"Latvia", "circa hard", "11-18", "high",          "high", # s_surf assumed
	
	"Latvia", "circa mix", "5-7", "moderate",         "low",
	"Latvia", "circa mix", "7.5-11", "moderate",      "low",
	"Latvia", "circa mix", "11-18", "moderate",       "low",
	
	"Latvia", "circa mud", "<5", "moderate",          "moderate",
	"Latvia", "circa mud", "5-7", "moderate",         "moderate",
	"Latvia", "circa mud", "7.5-11", "moderate",      "moderate",
	"Latvia", "circa mud", "11-18", "moderate",       "moderate",
	
	"Latvia", "circa sand", "<5", "moderate",         "moderate",
	"Latvia", "circa sand", "5-7", "moderate",        "moderate",
	"Latvia", "circa sand", "7.5-11", "moderate",     "moderate",
	"Latvia", "circa sand", "11-18", "moderate",      "moderate", # s_surf assumed
	
	"Latvia", "infra hard", "<5", "high",             "high",
	"Latvia", "infra hard", "5-7", "high",            "high",
	"Latvia", "infra hard", "7.5-11", "high",         "high", # s_surf assumed
	"Latvia", "infra hard", "11-18", "high",          "high", # s_surf assumed
	
	"Latvia", "infra mix", "<5", "moderate",          "moderate", # s_surf assumed
	"Latvia", "infra mix", "5-7", "moderate",         "moderate",
	"Latvia", "infra mix", "7.5-11", "moderate",      "moderate", # s_surf assumed
	"Latvia", "infra mix", "11-18", "moderate",       "moderate", # s_surf assumed
	
	"Latvia", "infra mud", "<5", "moderate",          "moderate",
	"Latvia", "infra mud", "5-7", "moderate",         "mmoderate",
	"Latvia", "infra mud", "7.5-11", "moderate",      "moderate",
	"Latvia", "infra mud", "11-18", "moderate",       "moderate", # s_surf assumed
	
	"Latvia", "infra sand", "<5", "moderate",         "moderate",
	"Latvia", "infra sand", "5-7", "moderate",        "moderate",
	"Latvia", "infra sand", "7.5-11", "moderate",     "moderate", # s_surf assumed
	"Latvia", "infra sand", "11-18", "moderate",      "moderate", # s_surf assumed
	# --------------------------------------------------------
	"Lithuania", "circa hard", "5-7", "high",         "high",
	"Lithuania", "circa hard", "7.5-11", "high",      "high",
	
	"Lithuania", "circa mix", "5-7", "moderate",      "low",
	"Lithuania", "circa mix", "7.5-11", "moderate",   "low",
	"Lithuania", "circa mix", "11-18", "moderate",    "low", # s_surf assumed
	
	"Lithuania", "circa mud", "5-7", "moderate",      "moderate",
	"Lithuania", "circa mud", "7.5-11", "moderate",   "moderate",
	
	"Lithuania", "circa sand", "<5", "moderate",      "moderate", # s_surf assumed
	"Lithuania", "circa sand", "5-7", "moderate",     "moderate",
	"Lithuania", "circa sand", "7.5-11", "moderate",  "moderate",
	
	"Lithuania", "infra hard", "<5", "high",          "high", # both assumed (sens and s_surf)
	"Lithuania", "infra hard", "5-7", "high",         "high", # both assumed
	"Lithuania", "infra hard", "7.5-11", "high",      "high", # both assumed
	
	"Lithuania", "infra mix", "5-7", "moderate",      "moderate",
	"Lithuania", "infra mix", "7.5-11", "moderate",   "moderate", # s_surf assumed
	
	"Lithuania", "infra mud", "5-7", "moderate",      "moderate",
	"Lithuania", "infra mud", "7.5-11", "moderate",   "moderate", # s_surf assumed
	
	"Lithuania", "infra sand", "5-7", "moderate",     "moderate",
	"Lithuania", "infra sand", "7.5-11", "moderate",  "moderate", # s_surf assumed
	# --------------------------------------------------------
	"Poland", "circa hard", "5-7", "high",            "high",
	"Poland", "circa hard", "7.5-11", "high",         "high",
	"Poland", "circa hard", "11-18", "high",          "high", # s_surf assumed
	
	"Poland", "circa mix", "5-7", "moderate",         "moderate", # s_surf assumed
	"Poland", "circa mix", "7.5-11", "moderate",      "moderate",
	"Poland", "circa mix", "11-18", "moderate",       "moderate", # s_surf assumed
	
	"Poland", "circa mud", "5-7", "moderate",         "moderate",
	"Poland", "circa mud", "7.5-11", "moderate",      "moderate",
	"Poland", "circa mud", "11-18", "moderate",       "moderate",
	
	"Poland", "circa sand", "5-7", "moderate",        "moderate",
	"Poland", "circa sand", "7.5-11", "moderate",     "moderate",
	"Poland", "circa sand", "11-18", "moderate",      "moderate",
	
	"Poland", "infra hard", "5-7", "high",            "high",
	"Poland", "infra hard", "7.5-11", "high",         "high",
	"Poland", "infra hard", "11-18", "high",          "high",
	
	"Poland", "infra mix", "<5", "moderate",          "moderate", # sens assumed
	"Poland", "infra mix", "5-7", "moderate",         "moderate",
	"Poland", "infra mix", "7.5-11", "moderate",      "moderate",
	
	"Poland", "infra mud", "<5", "moderate",          "moderate", # sens assumed
	"Poland", "infra mud", "5-7", "moderate",         "moderate",
	"Poland", "infra mud", "7.5-11", "moderate",      "moderate",
	"Poland", "infra mud", "11-18", "moderate",       "moderate",
	
	"Poland", "infra sand", "<5", "moderate",         "moderate", # sens assumed
	"Poland", "infra sand", "5-7", "moderate",        "moderate",
	"Poland", "infra sand", "7.5-11", "moderate",     "moderate",
	"Poland", "infra sand", "11-18", "moderate",      "moderate", # s_surf assumed
	# --------------------------------------------------------
	"Russia", "circa mix", "5-7", "moderate",         "moderate",
	# --------------------------------------------------------
	"Sweden", "circa hard", "<5", "high",             "low",
	"Sweden", "circa hard", "5-7", "high",            "high",
	"Sweden", "circa hard", "7.5-11", "high",         "high",
	"Sweden", "circa hard", "11-18", "high",          "high",
	"Sweden", "circa hard", "18-30", "high",          "high",
	"Sweden", "circa hard", ">30", "high",            "high",
	
	"Sweden", "circa mix", "<5", "moderate",          "low",
	"Sweden", "circa mix", "5-7", "moderate",         "low",
	"Sweden", "circa mix", "7.5-11", "moderate",      "moderate",
	"Sweden", "circa mix", "11-18", "moderate",       "moderate",
	"Sweden", "circa mix", "18-30", "moderate",       "high",
	"Sweden", "circa mix", ">30", "moderate",         "moderate",
	
	"Sweden", "circa mud", "<5", "moderate",          "low",
	"Sweden", "circa mud", "5-7", "moderate",         "moderate",
	"Sweden", "circa mud", "7.5-11", "moderate",      "moderate",
	"Sweden", "circa mud", "11-18", "moderate",       "moderate",
	"Sweden", "circa mud", "18-30", "moderate",       "high",
	"Sweden", "circa mud", ">30", "moderate",         "high",
	
	"Sweden", "circa sand", "<5", "moderate",         "low",
	"Sweden", "circa sand", "5-7", "moderate",        "moderate",
	"Sweden", "circa sand", "7.5-11", "moderate",     "moderate",
	"Sweden", "circa sand", "11-18", "moderate",      "moderate",
	"Sweden", "circa sand", "18-30", "moderate",      "high",
	"Sweden", "circa sand", ">30", "moderate",        "high",
	
	"Sweden", "infra hard", "<5", "high",             "low",
	"Sweden", "infra hard", "5-7", "high",            "moderate",
	"Sweden", "infra hard", "7.5-11", "high",         "high",
	"Sweden", "infra hard", "11-18", "high",          "high",
	"Sweden", "infra hard", "18-30", "high",          "high",
	"Sweden", "infra hard", ">30", "high",            "high",
	
	"Sweden", "infra mix", "<5", "moderate",          "low",
	"Sweden", "infra mix", "5-7", "moderate",         "moderate",
	"Sweden", "infra mix", "7.5-11", "moderate",      "moderate",
	"Sweden", "infra mix", "11-18", "moderate",       "high",
	"Sweden", "infra mix", "18-30", "moderate",       "high",
	"Sweden", "infra mix", ">30", "moderate",         "high",
	
	"Sweden", "infra mud", "<5", "moderate",          "low",
	"Sweden", "infra mud", "5-7", "moderate",         "moderate",
	"Sweden", "infra mud", "7.5-11", "moderate",      "moderate",
	"Sweden", "infra mud", "11-18", "moderate",       "high",
	"Sweden", "infra mud", "18-30", "moderate",       "high",
	"Sweden", "infra mud", ">30", "moderate",         "high",
	
	"Sweden", "infra sand", "<5", "moderate",         "low",
	"Sweden", "infra sand", "5-7", "moderate",        "moderate",
	"Sweden", "infra sand", "7.5-11", "moderate",     "moderate",
	"Sweden", "infra sand", "11-18", "moderate",      "moderate",
	"Sweden", "infra sand", "18-30", "moderate",      "moderate", # s_surf assumed
	"Sweden", "infra sand", ">30", "moderate",        "high"
)                                                           


for(i in 1:nrow(cumi_Sensitivities)) {
	terr       <- cumi_Sensitivities[[i, 1]]
	bio        <- cumi_Sensitivities[[i, 2]]
	sal        <- cumi_Sensitivities[[i, 3]]
	sensi      <- cumi_Sensitivities[[i, 4]]
	sensi_surf <- cumi_Sensitivities[[i, 4]]
	tmp$sens[tmp$Territory == terr & tmp$Biotope == bio & tmp$Sal2 == sal] <- sensi
	tmp$s_surf[tmp$Territory == terr & tmp$Biotope == bio & tmp$Sal2 == sal] <- sensi_surf
}


areaCountryBiotopeSalinityLayer <- tmp
```


Next, we want to set the sensitivity to 'high' for all areas that are reported to have certain sensitivie species. Thus, the layer is now combined with the extent of some benthic taxa leading to a high sensitivity (data layer from HELCOM MADS: Biodiversity > Ecosystem components (BSII) > Benthic species). The taxa are the genera *Mytilus, Zostera, Furcellaria, Fucus, Chara*.

```{r}
# ...

# as a last step write the layer to a file:
st_write(areaCountryBiotopeLayer,"Biotopes/biotopes-pre_calculated.gpkg")
```


The (pre-calculated) biotope layer now has these attribute columns:

- Biotope = HELCOM broadscale habitat
- sens = general pressure-independant sensitivity
- s_surf = sensitivity against surface abrasion due to bottom trawling
- sens_spec = whether the sensitivity was raised to 'high' due to sensitive species
- level_2 = HELCOM subbasins 2018 (assessment units)
- Territory = country name
- Sal = bottom salinity class (from HELCOM BALANCE project)
- Sal2 = bottom salinity value range (from HELCOM BALANCE project)

```{r}
cumi_message("loading biotope layer ...")
biotope_file <- "Data/Biotopes/biotopes-pre_calculated.gpkg"
# this file is a mix of polygon and multipolygon, so we cast everything to multipolygon first,
# in order to prevent errors in later spatial operations
if (! use_pre_calculated_data) {
	biotopeLayer <- st_read(biotope_file) %>% st_cast("MULTIPOLYGON") %>% st_make_valid()
}
```


All pressure layers will be clipped at the outline of the biotope map, making the pressure layers lie completely within the biotope coverage (and not e.g. on land). For this, we build a clip layer from the biotope layer:

```{r}
if (! use_pre_calculated_data) {
	cumi_message("... making clipLayer ... st_union() ...")
	clipLayer <- dplyr::select(biotopeLayer,-c(Biotope,sens,s_surf,sens_spec)) %>% st_cast("MULTIPOLYGON") %>% st_cast("POLYGON") %>% st_union()
}
```

## Pressure data and impact calculation
The initial impact map is just the biotope layer. This impact map gets combined (in principle via a GIS union operation) with each processed pressure layer. With each new pressure, one new column is added named 'impact_nx' where n is a number corresponding to the numbers in the following secions and x is either 'c' for 'under construction' or 'o' for 'in operation' or it is missing for those pressures which cannot be divided into these categories.

The assessment period of the test runs was 2011–2016, the period for the current HOLAS III assessment done here is 2016–2021:

```{r}
if (! use_pre_calculated_data) {
	cumi_message("preparing impact layer ...")
	# initial impact layer is just the biotope map:
	impact_map <- biotopeLayer
}
```

### 1. Bottom trawling fishery

```{r}
cumi_message("processing trawling fishery ...")
```

The fishery data were provided by ICES and then put into HELCOM Maps and Data Service. This version of the script uses a preprocessed version of these raw data, where:

1. all years have been combined into one GIS layer
2. the raw SAR data have been smoothed from c-squares into a 1x1 km grid using a mean SAR value per 1x1 km grid cell weighted by the area of the involved c-squares
3. the MOP has been calculated (column 'MOP_1'; see script below)
4. the data have been combined with the above pre-calculated biotope map (including the changes in the sensitivities for DK and SE)

*The next version of the script will also contain the necessary steps in R to make the preprocessing.*

The SAR values are treated directly as intensity and frequency is ignored, thus the SAR values are directly translated to MOP categories.

```{r}
if (use_pre_calculated_data) {
	cumi_message("... using pre_calculated data ...")
	fishing_file_pre <- "Data/Fishing/HELCOM_1x1km_Baltic_Sea_surf_pre_calculated.shp"
	if (! file.exists(fishing_file_pre)) {
		cumi_message("... cannot find file with pre_processed data - skipping bottom trawling fishery ...")
	} else {
		impact_map <- st_read(fishing_file_pre) %>% st_make_valid()
	}
} else {
	cumi_message("... calculating fishery impact - this will take a lot of time, so see you tomorrow ...")
	fishing_file <- "Data/Fishing/HELCOM_1x1km_Baltic_Sea_surf.shp"
	fishing_x <- st_read(fishing_file) %>% st_intersection(clipLayer)
	
	# treat SAR values lower than 0.05 as zero intensity:
	for (myColumn in c('SURFSAR_11','SURFSAR_12','SURFSAR_13','SURFSAR_14','SURFSAR_15','SURFSAR_16')) {
		fishing_x[[myColumn]] <- ifelse( fishing_x[[myColumn]]>=0.05, fishing_x[[myColumn]] , 0 )
	}
	
	# convert SAR into MOP:
	fishing_x <- fishing_x %>% mutate(sar_avg = (SURFSAR_11 + SURFSAR_12 + SURFSAR_13 + SURFSAR_14 + SURFSAR_15 + SURFSAR_16)/6) %>%
		mutate(MOP = case_when(
		sar_avg == 0							~ 'none',
		sar_avg  > 0	 & sar_avg < 0.33 ~ 'very low',
		sar_avg >= 0.33 & sar_avg < 0.66 ~ 'low',
		sar_avg >= 0.66 & sar_avg < 2	 ~ 'moderate',
		sar_avg >= 2							~ 'high',
		TRUE									  ~ 'undefined'
	))
	# we can now delete the columns we do not need in future
	# and we can remove all polygons with no MOP
	# and dissolve the MOP layer:
	fishing_x <- fishing_x %>%
		dplyr::select(-c(ET_ID,H_sub_code,H_sub_name,location,SURFSAR_11,SURFSAR_12,SURFSAR_13,SURFSAR_14,SURFSAR_15,SURFSAR_16,sar_avg)) %>%
		dplyr::filter(! MOP=='none') %>%
		group_by(MOP) %>% 
		summarize(geometry = st_union(geometry))
	
	# the my_union() in the following line is what takes 99.9% of the time in this pressure,
	# you might want to use ArcGIS for this particular 'union' task below as it is even significantly faster than QGIS
	# (24–45 seconds on my machine compared to approx. 7 hours with R !!!).
	impact_map %>% st_cast("MULTIPOLYGON") %>% my_union(fishing_x)
}
impact_map <- impact_map %>% st_cast("MULTIPOLYGON") %>% dplyr::mutate(impact_1 = unname(mapply(cumi_get_impact,MOP,s_surf))) %>% dplyr::select(-MOP)

```

### 2. Mariculture

```{r}
cumi_message("processing of mariculture ...")
```

Data layer from HELCOM: [Pressures > Baltic Sea Pressure and Impact Index > Human activities > Finfish mariculture](http://metadata.helcom.fi/geonetwork/srv/eng/catalog.search#/metadata/3cfa469a-6a78-4913-b82f-57fd0e7f4dc0), last accessed 2021-08-17.


These are point data. Some of the points are classified as "on land" and are ignored.

```{r}
cumi_message("... finfish ...")
mari_1_file <- "Data/Finfish_mariculture/Finfish_mariculture.shp"
mari_1 <- st_read(mari_1_file) %>% filter(! str_detect(AREA,'land'))

# In this case, MOP is the same as intensity as frequency is not applicable:
impact_map <- cumi_process_pressure(mari_1,"mariculture","2A")

```


Data layer from HELCOM: [Pressures > Baltic Sea Pressure and Impact Index > Human activities > Shellfish mariculture points](http://metadata.helcom.fi/geonetwork/srv/eng/catalog.search#/metadata/21efdecc-2fd7-4bfb-9832-68c995291bf7), last accessed 2021-08-17.

These are point data. All sites are taken into account.

```{r}
cumi_message("... shellfish (points) ...")
mari_2_file <- "Data/Shellfish_mariculture_points/Shellfish_mariculture_points.shp"
mari_2 <- st_read(mari_2_file)

# In this case, MOP is the same as intensity as frequency is not applicable:
impact_map <- cumi_process_pressure(mari_2,"mariculture","2B")

```

Data layer from HELCOM: [Pressures > Baltic Sea Pressure and Impact Index > Human activities > Shellfish mariculture areas](http://metadata.helcom.fi/geonetwork/srv/eng/catalog.search#/metadata/8fbf946a-18d2-4b24-98ad-1327ba2820a8), last accessed 2021-08-18.

These are polygon data. All sites are taken into account.

```{r}
cumi_message("... shellfish (areas) ...")
mari_3_file <- "Data/Shellfish_mariculture_areas/Shellfish_mariculture_areas.shp"
mari_3 <- st_read(mari_3_file)

# In this case, MOP is the same as intensity as frequency is not applicable:
impact_map <- cumi_process_pressure(mari_3,"mariculture","2C")

```

### 3. Extraction and disposal of sediments

```{r}
cumi_message("processing extraction and disposal of sediments ...")
```

Data layer from HELCOM: [Pressures > Baltic Sea Pressure and Impact Index > Human activities > Extraction of sand and gravel](http://metadata.helcom.fi/geonetwork/srv/eng/catalog.search#/metadata/683224c3-2fb9-4f2f-b748-bf5ad712d708), last accessed 2021-08-16.


The data are represented as polygons. Since the extraction depth and the spatial extent of the extraction within the polygon is unknown, the complete polygon area is currently treated as loss. All listed sites are assumed active or at least disturbed as the expire dates (attribute column 'expire_yea') are either not specified or not before the start of the assessment period.

We still ignore inactive sites in the script stopping before the assessment period, as a place holder for future settings, although this has no effect in the current assessment.

Frequency cannot be evaluated from this dataset as it is unclear whether the data are complete and values for the extraction amount of zero just are confidential data, missing data or a real non-pressure in a specific year.

```{r}
cumi_message("... extraction of sand and gravel ...")
extraction_file <- "Data/Extraction_of_sand_and_gravel/Extraction_of_sand_and_gravel.shp"
extraction_x <- st_read(extraction_file) %>% filter(expire_yea == 0 | expire_yea > 2010)

# In this case, MOP is the same as intensity as frequency is currently ignored:
impact_map <- cumi_process_pressure(extraction_x,"extraction","3A")

```


Data layer from HELCOM: [Pressures > Baltic Sea Pressure and Impact Index > Human activities > Deposit of dredged material sites areas 2011-2016](http://metadata.helcom.fi/geonetwork/srv/eng/catalog.search#/metadata/0eebe008-aed9-461a-8c85-e7b32bdab822), last accessed 2021-08-19.


These are polygon data. All sites are included in the calculation. No loss is included for the footprint as it is unknown to what extent the actual area is being used and typically only a part of the designated area is actively used.


```{r}
cumi_message("... deposit of dredged material (areas) ...")
deposit_1_file <- "Data/deposit_areas_11_16/deposit_areas_11_16.shp"
deposit_1 <- st_read(deposit_1_file)

# In this case, MOP is the same as intensity as frequency is currently ignored:
impact_map <- cumi_process_pressure(deposit_1,"depositing","3B")

```



Data layer from HELCOM: [Pressures > Baltic Sea Pressure and Impact Index > Human activities > Deposit of dredged material sites points 2011-2016](http://metadata.helcom.fi/geonetwork/srv/eng/catalog.search#/metadata/34bf84a1-1f04-40c7-99dd-9b9aff4523ea), last accessed 2021-08-19.


These are point data. All sites are included in the calculation. No loss is included for the footprint as the size of the footprint is unknown.


```{r}
cumi_message("... deposit of dredged material (points) ...")
deposit_2_file <- "Data/deposit_points_11_16/deposit_points_11_16.shp"
deposit_2 <- st_read(deposit_2_file)

# In this case, MOP is the same as intensity as frequency is currently ignored:
impact_map <- cumi_process_pressure(deposit_2,"depositing","3C")

```



Data layer from HELCOM: [Pressures > Baltic Sea Pressure and Impact Index > Human activities > Dredging areas 2011-2016](http://metadata.helcom.fi/geonetwork/srv/eng/catalog.search#/metadata/2a0fbdfd-9aef-4d2e-9129-2d1cc3b4943b), last accessed 2021-08-19.

The data layer contains polygon data. The attribute column "DREDGING_A" makes a distinction between maintenance and capital dredging (but there is no specifications as to how these types are distinguished). Further, the dredging type can be 'environmental', 'x' or empty. As a good definition is missing, only sites marked specifically as capital dredging are treated as such. All other sites are treated as maintenance dredging.

```{r}
cumi_message("... capital dredging (areas) ...")
dredge_a_file <- "Data/Dredging_areas/Dredging_areas.shp"
dredge_1 <- st_read(dredge_a_file) %>% st_zm() %>% filter(DREDGING_A=="capital")

# In this case, MOP is the same as intensity as frequency is currently ignored:
impact_map <- cumi_process_pressure(dredge_1,"dredging CAP","3D")


cumi_message("... maintenance dredging (areas) ...")
dredge_2 <- st_read(dredge_a_file) %>% st_zm() %>% filter(DREDGING_A != "capital")

# In this case, MOP is the same as intensity as frequency is currently ignored:
impact_map <- cumi_process_pressure(dredge_2,"dredging M","3E")

```



Data layer from HELCOM: [Pressures > Baltic Sea Pressure and Impact Index > Human activities > Dredging points 2011-2016](http://metadata.helcom.fi/geonetwork/srv/eng/catalog.search#/metadata/bb6622b7-e5df-4637-8ebe-c2736e705a70), last accessed 2021-08-19.

The data layer contains point data. The attribute column "TYPE" makes a distinction between maintenance and capital dredging (but there is no specifications as to how these types are distinguished). Further, this attribute column contains many values that are not covered by the metadata specification. As a good definition is missing, only sites marked specifically as 'capital' or 'Capital' dredging in the "TYPE" attribute are treated as such. All other sites are treated as maintenance dredging.

The dredged amount is reported in the data as weight in tonnes. The CumI follows the recommendation of HGELCOM EN DREDS and uses an amount in terms of the volume (5,000 m^3^) as threshold between two different buffer models (see `cumi_buffers`). As the volume is not reported, a transformation of the data is needed. The density of sediments varies roughly between 1.1 and 2.5 g/cm^3^. Since the type of the dredged material is unknown, we here use an average density of 1.8 g/cm^3^.

Further, the dredged amount is not reported in all instances. When the amount is not known, it is assumed to be below 5000 m^3^.


```{r}
cumi_message("... capital dredging (points) ...")
dredge_p_file <- "Data/Dredg_points/Dredg_points.shp"
dredge_3 <- st_read(dredge_p_file) %>% filter(Type %in% c("capital","Capital"))

# the 'Amount_ton' column is a character type with commas, so produce a proper 'volume' column:
dredge_3 <- dredge_3 %>% mutate(volume = as.numeric(sub(",",".",Amount_ton))/1.8)

# In this case, MOP is the same as intensity as frequency is currently ignored:
# above 5000m3:
impact_map <- cumi_process_pressure(filter(dredge_3,volume>5000),"dredging CAP2","3F")
# below or equal to 5000m3:
impact_map <- cumi_process_pressure(filter(dredge_3,volume<=5000 | is.na(Amount_ton)),"dredging CAP1","3G")



cumi_message("... maintenance dredging (points) ...")
dredge_4 <- st_read(dredge_p_file) %>% filter(! Type %in% c("capital","Capital"))

# In this case, MOP is the same as intensity as frequency is currently ignored:
impact_map <- cumi_process_pressure(dredge_4,"dredging M","3H")

```


### 4. Pipelines and cables

```{r}
cumi_message("processing pipelines and cables ...")
```

Data layer from HELCOM: [Pressures > Baltic Sea Pressure and Impact Index > Human activities > Pipelines](http://metadata.helcom.fi/geonetwork/srv/eng/catalog.search#/metadata/5260249e-5850-431a-b130-3a096abac852), last accessed 2021-08-13.


These are polyline data. There are no pipelines under construction in the dataset (attribute column 'Status'), thus only operational pipelines are included in the current assessment.

```{r}
cumi_message("... pipelines in operation (there are none under construction) ...")
pipeline_file <- "Data/Pipelines/Pipelines.shp"
pipeline_o <- st_read(pipeline_file) %>% filter(Status %in% (c('Operational','Unknown')))

# In this case, MOP is the same as intensity as frequency does not apply
impact_map <- cumi_process_pressure(pipeline_o,"pipeline O","4A")

```


Data layer from HELCOM: [Pressures > Baltic Sea Pressure and Impact Index > Human activities > Cables](http://metadata.helcom.fi/geonetwork/srv/eng/catalog.search#/metadata/c0e73e71-cafb-4422-a3a3-115687fd5c49), last accessed 2021-08-09.

These are polyline data. The data is divided according to the status being 'Under construction' and 'Operational'.

```{r}
cumi_message("... cables under construction ...")
# remove z-coord and take the features with status="Under construction":
cable_file <- "Data/Cables/Cables.shp"
cable_c <- st_read(cable_file) %>% st_zm() %>% filter(Status == 'Under construction')


# In this case, MOP is the same as intensity as frequency does not apply:
impact_map <- cumi_process_pressure(cable_c,"cable C","4B")



cumi_message("... cables in operation ...")
# remove z-coord and take the features with status="Operational":
cable_o <- st_read(cable_file) %>% st_zm() %>% filter(Status == 'Operational')

# In this case, MOP is the same as intensity as frequency does not apply:
impact_map <- cumi_process_pressure(cable_o,"cable O","4C")
```



### 5. Platforms and wind farms

```{r}
cumi_message("processing platforms and wind farms ...")
```

Data layer from HELCOM: [Pressures > Baltic Sea Pressure and Impact Index > Human activities > Oil platforms](http://metadata.helcom.fi/geonetwork/srv/eng/catalog.search#/metadata/fddc27ec-b6ae-407b-9dd8-f31a42d75412), last accessed 2021-08-19.

These are point data. As we do not know from the data which kind of fundament the platforms have, we cannot determine whether or not to treat the footprint area as loss. Currently, we do not treat the the footprint as loss since platforms typically only have pylones and not the entire area of the platform is equivalent to lost habitat area. Further, as not explicitly stated in the metadata, the platforms as assumed to be "in operation".

```{r}
cumi_message("... oil platforms ...")
oil_file <- "Data/Oil_platforms/Oil_platforms.shp"
oil_x <- st_read(oil_file)

# In this case, MOP is the same as intensity as frequency does not apply:
impact_map <- cumi_process_pressure(oil_x,"platform O","5A")
```



Data layer from HELCOM: [Pressures > Baltic Sea Pressure and Impact Index > Human activities > Wind farms](http://metadata.helcom.fi/geonetwork/srv/eng/catalog.search#/metadata/80de3bc3-e3ec-474e-8ae8-4b29c205eb0a), last accessed 2021-08-13.


These are point data. The 'Status' attribute lists some turbines 'Under construction' and some as 'Generating power'. The latter are taken as 'in operation'. Turbines with status 'Transformer' are not strictly turbines but transformer station. As there are only three of them in the dataset, they are also interpreted as being 'in operation' and treated as regular turbines. It can be considered to treat them differently in the future. According to ICES WKBEDLOSS, a radius of 15 m could be used for "offshore transformer stations or modules" (OTS/OTM).

As we do not know from the data which kind of fundament the turbines have, we cannot determine whether or not to treat the footprint area as loss. Currently, we do not treat the the footprint as loss.

```{r}
cumi_message("... OWF under construction ...")
owf_file <- "Data/Wind_turbines/wind_turbines.shp"
owf_c <- st_read(owf_file) %>% filter(Status == "Under construction")

# In this case, MOP is the same as intensity as frequency does not apply
impact_map <- cumi_process_pressure(owf_c,"OWF C","5B")


cumi_message("... OWF in operation ...")
owf_o <- st_read(owf_file) %>% filter(Status %in% (c('Generating power','Transformer')))
# In this case, MOP is the same as intensity as frequency does not apply
impact_map <- cumi_process_pressure(owf_o,"OWF O","5C")

```


### 6. Coastal protection

```{r}
cumi_message("processing coastal protection ...")
```

Data layer from HELCOM: [Pressures > Baltic Sea Pressure and Impact Index > Human activities > Coastal defense](http://metadata.helcom.fi/geonetwork/srv/eng/catalog.search#/metadata/2d47c5ea-4590-465f-a462-60ef59d3d7d3), last accessed 2021-08-12.

These are polyline data and the interesting attributes in the data are (description taken from HECLOM metadata page on this dataset):

- Const\_year: Year of construction; for some structure in Estonia the construction year is not known and this is marked as no data (ND)
- Estimated: Estimated date of completion if under construction (Estonia) or the year of environmental permit if year of construction is lacking (Finland)
- Out\_of\_use: Year when costal defence structure has been taken out of use


The data has an attribute 'Estimated' containg some years from the assessment period. It is not clear whether this means the objects were constructed earlier and finalised in the assessment period. Thus, only the objects having 'Const_year="Under construction"' are currently used.

```{r}
cumi_message("... coastal protection under construction ...")
# take the features with Const_year="Under construction":
coastalDef_file <- "Data/Coastal_defense/Coastal_defense.shp"
coastalDef_c <- st_read(coastalDef_file) %>% st_transform(coordSystem) %>% filter(Const_year == 'Under construction')

# In this case, MOP is the same as intensity as frequency does not apply:
# (there is only one construction event)
impact_map <- cumi_process_pressure(coastalDef_c,"coastalDef C","6A")



cumi_message("... coastal protection in operation ...")
# take the features where Const_year is null or is a 4-digit year or is 'ND':
coastalDef_o <- st_read(coastalDef_file) %>% st_transform(coordSystem) %>% 
		filter(Const_year > 0 || is.na(Const_year) || Const_year == 'ND')

# In this case, MOP is the same as intensity as frequency does not apply:
impact_map <- cumi_process_pressure(coastalDef_o,"coastalDef O","6B")
```


Data layer from HELCOM: [Pressures > Baltic Sea Pressure and Impact Index > Harbours](http://metadata.helcom.fi/geonetwork/srv/eng/catalog.search#/metadata/e2a3a104-a7aa-49c9-bc2c-47845b3a322f), last accessed 2021-08-20.

This dataset provides harbours as polygons. All harbours are included in the assesment. The dataset also contains point data. These are derived from the polygon data for the estimation of port visits and is not dealt with here.

```{r}
cumi_message("... harbours (areas) ...")
harbour_file = "Data/Harbours/Harbour_polygons.shp"
harbour_o <- st_read(harbour_file)

# In this case, MOP is the same as intensity as frequency does not apply:
impact_map <- cumi_process_pressure(harbour_o,"harbour O","6C")
```


### 7. Shipping

```{r}
cumi_message("processing shipping ...")
```

Data layer from HELCOM: [Pressures > Baltic Sea Pressure and Impact Index > Shipping density 2011-2015](http://metadata.helcom.fi/geonetwork/srv/eng/catalog.search#/metadata/1fd5298f-d3be-4c5f-bb05-3dc66a8eea6b), last accessed 2021-08-20.

The dataset contains polygon data. This script uses a pre-processed version of the HELCOM dataset. *The next version of this script will include the pre-processing prodedure in R*. These step were involved in order to arrive at the data layer used here:

1. use the layer "2011-2015_all_ship_types_MEAN/2011-2015_all_ship_types_MEAN.tif" from the above HELCOM dataset
2. vectorise the data and assign coordinate system EPSG:3035 (the raster value is put into an attribute column named 'density')
3. remove all polygons with raster value (density) of 0
4. apply zonal statisitcs (in QGIS: Tools > Raster analysis > Zonal statistics) with the mean of the depth (depth taken from HELCOM layer: “depth relief map” (raster data)) to get an average depth per density polygon (new attribute column named 'depth')
5. remove all polygons having a depth of 0 or higher (this defines the shoreline and the land)
6. remove all polygons having no depth value (due to missing overlap between depth data and shipping data)
7. remove all polygons having a depth value over 25 m (noot inclusing 25 m; there is no impact assumed in these depths)
8. make a new attribute 'depthzone' and classify depth values into the following classes:


```{QGIS eval=FALSE}
# attribue column 'depthzone':
CASE
 when "depth"<0 and "depth">=-10 then 1
 when "depth"<-10 and "depth">=-15 then 2
 when "depth"<-15 and "depth">=-20 then 3
 when "depth"<-20 and "depth">=-25 then 4
END
```

9. translate the density depending on the depthzone into a new attribute column ‘intensity’:


```{QGIS eval=FALSE}
# Weighted with depth:
# dephtzone 1: eqiuv. to 100 % => density value is taken directly
# depthzone 2: equiv. to  50 % => density value divided by 2
# depthzone 3: equiv. to  25 % => density value divided by 4
# depthzone 4: equiv. to  10 % => density value divided by 10
# depthzone 5: equiv. to	0 % => polygon is removed (everything over 25 m)

# new attribute column 'intensity':
CASE
 when "depthzone"=1 then "density"
 when "depthzone"=2 then "density"/2.0 
 when "depthzone"=3 then "density"/4.0 
 when "depthzone"=4 then "density"/10.0 
END
```

10. reclassify the intensity into the four MOP classes (we must ignore frequency at this stage as the data do not contain information on the shipping frequency). After the above steps, intensity values from 0 to 32166 remain. These are divided pragmatically into the uniform CumI scale:

```{QGIS eval=FALSE}
# new attribute column 'MOP':
CASE
when "intensity" >=	  0 and "intensity" <	8041 then 'very low'
when "intensity" >=  8041 and "intensity" <  16083 then 'low'
when "intensity" >= 16083 and "intensity" <  24124 then 'moderate'
when "intensity" >= 24124 and "intensity" <= 32166 then 'high'
END
```

11. dissolve the polygons by MOP only to reduce file size and risk of artifacts.



For now, we work with the pre-calculated data in our dataset:


```{r}
shipping_file <- "Data/Shipping (AIS-density)/shipping-pre-calculated.shp"
shipping_x <- st_read(shipping_file) %>% st_make_valid()
# we only have left to combine with the biotope layer
# (following the same approach as in cumi_process_pressure()):
#
# you may want to take out the union from here and perform this individual action in ArcGIS,
# as this will cut down the processing time from approx. 8 hours to under a minute ...
#
impact_map <- st_cast(impact_map,"MULTIPOLYGON") %>% 
	my_union(shipping_x) %>% 
	dplyr::mutate(impact_7 = unname(mapply(cumi_get_impact,MOP,sens))) %>% 
	dplyr::select(-c(MOP)) %>%
	rename_geometry("geometry") %>%
	filter(! is.na(Biotope))
```



## Calculate cumulative impact
cumi_message("Cumulating all impacts ...")


Now, all individual impacts are calculated and integrated into the biotope map. So, we can now do the cumulation step by taking every single polygon, looking at all individual impacts for that polygon and then do a pair-wise combination:


```{r}
#
# the following code is explicit and thus slow (approx. 1 hour on my machine), will be speed-optimized later
#
# make list of all impact columns to loop over:
impactColumns <- grep("impact_[1-9].?",names(impact_map),value=TRUE)

# initialize a new column 'cumi' for the cumulative impact:
impact_map <- mutate(impact_map,cumi = NA)

initialColumn <- impactColumns[1]
columnCount <- length(impactColumns)

# loop over each polygon/multipolygon in the map:
print(paste("0 of",nrow(impact_map)))
for (myRowIndex in 1:nrow(impact_map)) {
	rowData <- impact_map[myRowIndex, ]
	if (myRowIndex %% 2000 == 0) {print(paste(myRowIndex,"of",nrow(impact_map))); flush.console()}
	# foreach pair of impact columns, do the cumulation:
	for (myColIndex in 1:(columnCount-1)) {
		if (myColIndex == 1) {i1 <- rowData[[impactColumns[1]]]} else {i1 <- ik}
		i2 <- rowData[[impactColumns[myColIndex+1]]]
		ik <- cumi_get_cumulation(i1,i2)
	}
	impact_map$cumi[myRowIndex] <- ik
}
```

As the last step, cumulative disturbance and loss are separated. The CumI does only evaluated disturbance. The loss layer can be used for e.g. MSFD criterion D6C4.

```{r}
impact_map_loss <- impact_map %>% filter(cumi == 'loss')
impact_map_disturbance <- impact_map %>% filter(! cumi == 'loss')

```



```{r}
n2 <- Sys.time()
cumi_message("Finished assesment!")
print(n2)
print(paste("Total assessment processing time:",get_running_time(n1,n2)))

st_write(impact_map_disturbance,paste("Data/Results/CumI-assessment-",format(Sys.time(),"%Y-%m-%dT%H%M"),".shp",sep= ""))
st_write(impact_map_loss,paste("Data/Results/physical_functional-loss-",format(Sys.time(),"%Y-%m-%dT%H%M"),".shp",sep= ""))
```

The resulting CumI-assessment file has a number of columns now. This is what they mean:

- Biotope = HELCOM broadscale habitat
- sens = general pressure-independant sensitivity
- s_surf = sensitivity against surface abrasion due to bottom trawling
- s_subsurf = sensitivity against subsurface penetration due to bottom trawling (not used in this assessment)
- sens_spec = whether the sensitivity was raised to 'high' due to sensitive species
- level_2 = HELCOM subbasins 2018 (assessment units)
- Territory = country name
- Sal = bottom salinity class (from HELCOM BALANCE project)
- Sal2 = bottom salinity value range (from HELCOM BALANCE project)
- impact_xx = CumI impact category for the component specified by 'xx':
	- 1: Bottom trawling fishery (surface abrasion), rastered data
	- 2A: Finfish mariculture, point data
	- 2B: Shellfish mariculture, point data
	- 2C: Shellfish mariculture, polygon data
	- 3A: Extraction of sand and gravel, polygon data
	- 3B: Deposit of dredged material, polygon data
	- 3C: Deposit of dredged material, point data
	- 3D: Capital dredging, polygon data
	- 3E: Maintenance dredging, polygon data
	- 3F: Capital dredging above 5000m3, point data
	- 3G: Capital dredging below or equal 5000m3, point data
	- 3H: Maintenance dredging, point data
	- 4A: Pipelines in operation, polyline data
	- 4B: Cables under construction, polyline data
	- 4C: Cables in operation, polyline data
	- 5A: Oil platforms, point data
	- 5B: OWF under construction, point data
	- 5C: OWF in operation, point data
	- 6A: Coastal protection under construction, polyline data
	- 6B: Coastal protection in operation, polyline data
	- 6C: Harbours, polygon data
	- 7: Shipping, polygon data
- cumi: the final cumulative impact category
	
	

# Outlook
This version of the script is an initial version. It implements the basic features of the CumI that are needed in order to do a CumI assessment with the current HELCOM dataset. In the near future, new dataset will be available for HOLAS III. This will be the latest point where the script needs changes in order to work with the new or updated data (e.g. integrating pressure frequency for more pressures or a more differentiated approach to derive MOP).

Apart from this, the following updates are planned for the next version:

- some visualizations will be implemented on the resulting impact map, such as graphs on the aerial extent of the various impact levels over the whole assessment area or certain subdivisions of that area
- the pre-processing of the bottom trawling data and the shipping data will be implemented
- the pre-processing of the biotope map
- a distinction between 'no data' and 'no impact' will be implemented
- provide a switch to keep the MOP attribute per pressure in the impact map
- provide a switch to keep the partial impact maps after combining with an individual pressure (in order to easily continue after errors with a particular pressure)
- provide all GIS data as one Geopackage file instaed of the mess with shapefiles

[^1]: <https://www.emodnet-seabedhabitats.eu/files/C20211007_EUSeaMap_2021_Baltic_Sea.zip>
[^2]: <https://www.emodnet-seabedhabitats.eu/files/C20211008_EUSeaMap_2021_Arctic_Atlantic.zip>
[^3]: <https://metadata.helcom.fi/geonetwork/srv/eng/catalog.search#/metadata/d4b6296c-fd19-462c-94d2-4c81b9313d77>
