---
title: Assessment of the cumulative impact from physical pressures on the Baltic Sea using the CumI indicator
author: Torsten Berg, MariLim
date: 2021-08-05
output: NULL
---

# How to use this document
This is an R markdown document. The R code within this document can be executed using the R `library(knitr)`:

```{r help-eval-code, eval=FALSE}
library(knitr)
# purl() is the same as knit(..., tangle=TRUE)
source(purl("CumI-assessment.Rmd"))
```

The documentation can be produced together with executing the R code using:

```{r help-make-doc, eval=FALSE}
library(rmarkdown)
library(knitr)
render("CumI-assessment.Rmd")
```

# R packages to use
The R code uses the following libraries which should be installed first (if not present):

```{r}
n1 <- Sys.time()
print(paste("--- CumI ---: starting at",n1,sep=" "))
print("--- CumI ---: loading libraries ...")
library(dplyr)
# library(naniar)
library(stringr) # using str_detect
library(tibble)
library(sf)

```

# Some R functions

```{r include=FALSE}
print("--- CumI ---: defining some R functions ...")
```

## General GIS-related functions

R has no function corresponding to a true union in GIS. `st_union` in the sf library is not equivalent. Since we need lots of real union operations here, we need a custom function. The following code ist from [stackowerflow](https://stackoverflow.com/questions/54710574/how-to-do-a-full-union-with-the-r-package-sf) and illustrates the process. It is the basis of our function:

```{r eval=FALSE}
a1 <- st_polygon(list(rbind(c(0, 10), c(45, 10), c(45, 90), c(0, 90), c(0, 10))))
a2 <- st_polygon(list(rbind(c(45, 10), c(90,10), c(90, 90), c(45, 90), c(45, 10))))
b1 <- st_polygon(list(rbind(c(15, 5), c(75, 5), c(75, 50), c(15, 50), c(15, 5))))

a <- st_sf(station=c(1, 2), geometry=st_sfc(a1, a2))
b <- st_sf(type="A",   geometry=st_sfc(b1))

st_agr(a) = "constant" #to avoid warnings, but see https://github.com/r-spatial/sf/issues/406
st_agr(b) = "constant"

#Operations
plot(st_geometry(st_union(a,b)))

op1 <- st_difference(a,st_union(b)) #notice the use of st_union()
plot(st_geometry(op1), border="red", add=TRUE)

op2 <- st_difference(b, st_union(a)) #notice the order of b and a and st_union()
plot(st_geometry(op2), border="green", add=TRUE)

op3 <- st_intersection(b, a) #notice the order of b and a
plot(st_geometry(op3), border="blue", add=TRUE)

# union <- rbind(op1, op2, op3) #Error because op1 (op2) doesn't have the column "type" ("station")
#> Error in match.names(clabs, names(xi)): names do not match previous names

op11 <- dplyr::mutate(op1, type=NA)
op22 <- dplyr::mutate(op2, station=NA)

union <- rbind(op11, op22, op3)
```

From this, we can make a union function that can work with arbitrary sf objects:

```{r eval=FALSE}
library(plyr)

my_union_sf <- function(a,b) {
   #
   # function doing a real GIS union operation such as in QGIS or ArcGIS
   #
   # a - the first sf
   # b - the second sf
   #
   st_agr(a) = "constant"
   st_agr(b) = "constant"
   op1 <- st_difference(a,st_union(b))
   op2 <- st_difference(b, st_union(a))
   op3 <- st_intersection(b, a)
   union <- rbind.fill(op1, op2, op3)
   return(st_as_sf(union))
}
```

Since this custom sf function is very slow (and I mean: veeeery slow), we explore another possibility provided by the raster library which, however, involves some trnasforming back and forth to sp Spatial\* objects (SpatialPolygonsDataFrame):

```{r eval=FALSE}
library(sp) # used by 'raster'
library(raster) # provides: raster::union()

my_union_raster <- function(a,b,sf=TRUE) {
   #
   # function doing a real GIS union operation such as in QGIS or ArcGIS
   # on Spatial* objects (from the sp library)
   #
   # a - the first sf or Spatial* object
   # b - the second sf or Spatial* object
   # sf - whehter or not to convert the output to an sf object
   #
   # when an objects is not a Spatial* object, it will be converted first
   #
   if (! class(a)[1] == "SpatialPolygonsDataFrame") {a <- as_Spatial(a)}
   if (! class(b)[1] == "SpatialPolygonsDataFrame") {b <- as_Spatial(b)}
   res <- raster::union(a,b)
   if (sf) {return(as(res,"sf"))} else {return(res)}
}
```

Unfortunately, also this function turns out to be quite slow ...

If a recent version of QGIS is present (version 3.14.16 or newer), we therefor should utilize the function `qgis_run_algorithm` and let the union be done by QGIS. This will increase the performance by many magnitudes! You do not need to know how QGIS works in order to use this function. R takes care of it all. This function has the additional benefit to print out a percentage of the progress, so you can see how long to wait for the next union:

```{r}
# needs QGIS 3.14.16
library(qgisprocess)

my_union <- function(a,b) {
   st_agr(a) = "constant" #to avoid warnings, but see https://github.com/r-spatial/sf/issues/406
   st_agr(b) = "constant"
   result <- qgis_run_algorithm(
      "native:union",
	   INPUT = a,
	   OVERLAY = b,
	   OVERLAY_FIELDS_PREFIX = '')
	# read the resulting union, get rid of the produced "fid_" columns and make sure the geometry column is correctly named:
   result <- sf::read_sf(qgis_output(result, "OUTPUT")) %>% dplyr::select(-contains("fid_")) %>% rename_geometry("geometry")
   # sometimes, the union results in some MULTILINESTRINGS - we must delete those:
   if (st_geometry_type(result,by_geometry=FALSE) == "GEOMETRY") {
   	cumi_message("... deleting MULTILINESTRINGs from last union ...")
   	result <- result %>% filter(st_geometry_type() %in% c("POLYGON","MULTIPOLYGON"))
   }
   return(result)
}
```

If you can't use QGIS, you will need to rename one of the first two union functions to `my_union` (and rename the QGIS function to something else) and live with a very poor performance, meaning to wait hours and hours for some GIS union processing (I don't even know how long it takes because I always stopped the execution after 1–2 hours).


Sometimes, we need to rename the geometry column of an sf object, since sf itself will give them some weird names:

```{r}
rename_geometry <- function(g, name){
	#
	# rename the geometry columns (sfc) to a user-defined name
	# (taken from: https://gis.stackexchange.com/questions/386584/sf-geometry-column-naming-differences-r)
	#
	# g - sf object to rename the geometry column for
	# name - the name string to be used for the geometry column
	#
	current = attr(g, "sf_column")
	names(g)[names(g)==current] = name
	st_geometry(g)=name
	return(g)
}
```


## CumI-specific functions
The actual assessment using the CumI applies a range of 'matrix operations' where e.g. sensitivity of a given biotope is combined with the magnitude of pressure. This is done using some fixed rules. These rules and the R function to use them are given below.

The first rule combines resilience and resistance of a biotope to derive the resulting biotope sensitivity:

```{r}
print("--- CumI ---: defining CumI objects and functions ...")

# the sensitivity matrix:
cumi_sensi_matrix <- tribble(
   ~resistance, ~resilience_verylow, ~resilience_low, ~resilience_moderate, ~resilience_high,
   "very low",  "high",              "high",          "moderate",           "moderate",
   "low",       "high",              "moderate",      "moderate",           "low",
   "moderate",  "moderate",          "moderate",      "low",                "very low",
   "high",      "moderate",          "low",           "low",                "very low"
)


# a function to retrieve the sensitivity:
cumi_get_sensi <- function(resist,resil) {
   #
   # function returning the sensitivity given the resilience
   # and the resistance as strings
   #
   # resist - the resistance as string
   # resil - the resilience as string
   #
	resil <- paste("resilience_",gsub(" ", "", resil, fixed = TRUE),sep="")
	result <- subset(cumi_sensi_matrix,resistance==resist)[[resil]]
	if (is.null(result)) {
		return('none')
	} else {
		return(result)
	}
}
```

The second rule combines biotope sensitivity and the physical magnitude of pressure (= MOP) to derive the assumed impact:

```{r}
cumi_impact_matrix <- tribble(
   ~sensitivity, ~MOP_high, ~MOP_moderate, ~MOP_low,   ~MOP_verylow,
   "high",       "high",    "high",        "m2",       "m1",
   "moderate",   "high",    "m3",          "m1",       "low",
   "low",        "m2",      "m1",          "low",      "very low",
   "very low",   "m1",      "low",         "very low", "very low"
)

     
cumi_get_impact <- function(MOP,sensi) {
   #
   # function returning the impact given the MOP
   # and the sensitivity as strings
   #
   # MOP - MOP category as string
   # sensi - sensitivity category as string
   #
   if (is.na(MOP)) {return("none")}
   if (is.na(sensi)) {return("none")}
   if (MOP == "loss") {return("loss")}
   MOP <- paste("MOP_",gsub(" ", "", MOP, fixed = TRUE),sep="")
	result <- subset(cumi_impact_matrix,sensitivity==sensi)[[MOP]]
	if (is.null(result)) {
		return('none')
	} else {
		if (identical(result,character(0))) {print(paste(MOP,"and",sensi,"lead to null"))}
		return(result)
	}
}
```

The third rule combines two impacts when these are cumulated in the last step of the assessment:

```{r}
# the cumulation matrix:
cumi_cumulation_matrix <- tribble(
	~imp1,       ~imp2_high, ~imp2_m3, ~imp2_m2, ~imp2_m1, ~imp2_low, ~imp2_verylow,
	"high",      "loss",     "loss",   "high",   "high",   "high",    "high",
	"m3",        "loss",     "loss",   "high",   "m3",     "m3",      "m3",
	"m2",        "high",     "high",   "m3",     "m2",     "m2",      "m2",
	"m1",        "high",     "m3",     "m2",     "m2",     "m1",      "m1",
	"low",       "high",     "m3",     "m2",     "m1",     "low",     "low",
	"very low",  "high",     "m3",     "m2",     "m1",     "low",     "very low"
)

# a function to retrieve the cumulative impact:
cumi_get_cumulation <- function(i1,i2) {
	#
	# function returning the cumulative impact
	# given two impacts that act at the same time
	# and at the same place
	#
	# i1 - the first impact category as string
	# i2 - the second impact category as string
	#
	# in the cumulation "very low" acts just as "none",
	# as if only one impacts would be present, not leading to a higher impact:
	# (this test needs to come first, because we cannot use NA values in the code further below)
	if (is.na(i1) || i1 == 'none') {i1 <- "very low"}
	if (is.na(i2) || i2 == 'none') {i2 <- "very low"}
	#
	if (i1 == "loss" || i2 == "loss" ) {return("loss")}
	if (i1 == "none" && i2 == "none" ) {return("none")}
	#
	i2 <- paste("imp2_",gsub(" ", "", i2, fixed = TRUE),sep="")
	result <- subset(cumi_cumulation_matrix,imp1==i1)[[i2]]
	if (is.null(result)) {
		return('none')
	} else {
		return(result)
	}
}
```

Some of the pressures work with a buffering. This means, the pressure is acting on a spatially larger area than the actual footprint (polygon, line or point data) of the pressure source. These pressures are listed here. The intensity of the pressure decreases with increasing distance from the pressure. The buffer distances in the table below represent the maximum distance (in metres) for the specific pressure intensity category, measured from the pressure source. As an example, a buffer distance of 50 for a high intensity means a buffer from 0–50 metres around a pressure source (which can be a point, a line or a polygon). A subsequent moderate intensity up to 100 then is an adjacent buffer 50–100 metres around a pressure source. So, the number in a specific columns is always the radius of the outer border of a zone, not its width.

The table also lists whether there is a buffer zone counting as 'loss' (~buffer_loss) and whether the pressure footprint itself (in case of polygone data) is treated as loss (~footprint\_as\_loss).

```{r}
#
# buffer models for pressure intensity
#
# in the pressure column:
#   C = under construction
#   O = in operation
#   M = maintenance
#   CAP1, CAP2 = capital
#   OWF = offshore wind farm
#
cumi_buffers <- tribble(
   ~pressure,      ~description,                  ~buffer_loss,  ~buffer_high, ~buffer_moderate, ~buffer_low,   ~buffer_verylow,  ~footprint_as_loss,
   #--------------|------------------------------|--------------|-------------|-----------------|--------------|------------------|------------------
   "extraction",   "sand and gravel extraction",  0,             50,           100,              250,           500,                1,
   "depositing",   "deposit of dredged material", 0,             50,           100,              250,           500,                0,
   "dredging M",   "maintenance dredging",        0,             50,           100,              250,           500,                0,
   "dredging CAP", "capital, areas",              0,              0,             0,                0,             0,                1,
   "dredging CAP1","captial, points, <= 5000m3", 25,             25,            25,               25,            25,                1,
   "dredging CAP2","capital, points, > 5000m3",  50,             50,            50,               50,            50,                1,
   "cable C",      "cable",                       0,              0,           550,              600,          1000,                0,
   "cable O",      "cable",                       1.5,            1.5,           1.5,              1.5,           1.5,              0,
   "pipeline C",   "pipelines",                   0,              0,           550,              600,          1000,                0,
   "pipeline O",   "pipelines",                  15,             15,            15,               90,           315,                0,
   "platform C",   "platforms",                   0,              0,           550,              600,          1000,                0,
   "platform O",   "platforms",                  25,             25,            25,               25,            25,                0,
   "OWF C",        "offshore wind farms",         0,              0,           550,              600,          1000,                0,
   "OWF O",        "offshore wind farms",        30,             30,            40,               50,           130,                0,
   "coastalDef C", "coastal defence",             0,             50,           100,              250,           500,                0,
   "coastalDef O", "coastal defense",            50,             50,            50,               50,            50,                0,
   "mariculture",  "mariculture",               150,            150,           400,              650,          1150,                1,
   "harbour O",    "harbour",                   200,              0,             0,                0,             0,                0
)
```


The following function uses the above buffer models to calculate the concrete spatial extent of the various intensity zones for a given pressure:

```{r}
cumi_buffer_intensity <- function(pressureData,pressureBufferModel) {
	#
	# build an sf object that holds all different intensity zones and a loss zone
	# for a specific pressure
	#
	# pressureData - the sf objects holding the raw pressure data as points, lines or polygons
	# pressureBufferModel - the symbolic name of the buffer model in the tribble 'cumi_buffer'
	#   (column ~pressure)
	#
	
	footprint <- filter(cumi_buffers,pressure==pressureBufferModel)[["footprint_as_loss"]]
	loss <- filter(cumi_buffers,pressure==pressureBufferModel)[["buffer_loss"]]
	vl   <- filter(cumi_buffers,pressure==pressureBufferModel)[["buffer_verylow"]]
	l    <- filter(cumi_buffers,pressure==pressureBufferModel)[["buffer_low"]]
	m    <- filter(cumi_buffers,pressure==pressureBufferModel)[["buffer_moderate"]]
	h    <- filter(cumi_buffers,pressure==pressureBufferModel)[["buffer_high"]]
	
	# 'very low' zone:
	if (vl-l > 0) {
	   b_verylow <- st_buffer(pressureData,vl)
	   b_low <- st_buffer(pressureData,l)
	   zone_verylow <- st_sf(st_difference(st_union(b_verylow),st_union(b_low))) %>%
		  st_cast("POLYGON") %>% mutate(intensity="very low") %>% rename_geometry("geometry")
	   output <- zone_verylow
	}
	
	# 'low' zone:
	if (l-m > 0) {
	   if (! exists("b_low")) {b_low <- st_buffer(myLayer,l)}
	   b_moderate <- st_buffer(pressureData,m)
	   zone_low <- st_sf(st_difference(st_union(b_low),st_union(b_moderate))) %>%
		  st_cast("POLYGON") %>% mutate(intensity="low") %>% rename_geometry("geometry")
	   if (exists("output")) {
		  output <- add_row(output,zone_low)
	   } else {
		  output <- zone_low
	   }
	}
	
	# 'moderate' zone:
	if (m-h > 0) {
	   if (! exists("b_moderate")) {b_moderate <- st_buffer(pressureData,m)}
	   if (! exists("b_high")) {b_high <- st_buffer(pressureData,h)}
	   zone_moderate <- st_sf(st_difference(st_union(b_moderate),st_union(b_high))) %>%
		  st_cast("POLYGON") %>% mutate(intensity="moderate") %>% rename_geometry("geometry")
	   if (exists("output")) {
		  output <- add_row(output,zone_moderate)
	   } else {
		  output <- zone_moderate
	   }
	}
	
	# 'high' zone:
	if (h-loss > 0) {
	   if (! exists("b_high")) {b_high <- st_buffer(pressureData,h)}
	   if (! exists("b_loss")) {b_loss <- st_buffer(pressureData,loss)}
	   zone_high <- st_sf(st_difference(st_union(b_high),st_union(b_loss))) %>%
		  st_cast("POLYGON") %>% mutate(intensity="high") %>% rename_geometry("geometry")
	   if (exists("output")) {
		  output <- add_row(output,zone_high)
	   } else {
		  output <- zone_high
	   }
	}
	
	# 'loss' zone:
	if (loss > 0) {
	   if (! exists("b_loss")) {b_loss <- st_buffer(pressureData,loss)}
	   zone_loss <- st_union(b_loss) %>% st_sf() %>% st_cast("POLYGON") %>% mutate(intensity="loss") %>% rename_geometry("geometry")
	   if (exists("output")) {
		  output <- add_row(output,zone_loss)
	   } else {
		  output <- zone_loss
	   }
	}
	
	# footprint zone as 'loss':
	if (footprint & st_geometry_type(pressureData,by_geometry=FALSE) != "POINT") {
	   zone_footprint <- st_buffer(pressureData,0) %>% st_union() %>% st_sf() %>%
	   	st_cast("POLYGON") %>% mutate(intensity="loss") %>% rename_geometry("geometry")
	   if (exists("output")) {
		  output <- add_row(output,zone_footprint)
	   } else {
		  output <- zone_footprint
	   }
	}
	
	return(output)
}
```

In order to make the script a bit more concise, a function combining some standard steps into one go is used. It reads the opened pressure GIS layer, assuming it is having a valid geometry/topology and the correct coordinate system, applies the buffer model, clips the resulting layer at the boudary of the biotope layer, includes it into the final impact layer and calculates the impact (and deletes the now superfluous 'int' column):


```{r}
cumi_process_pressure <- function(pressureData,pressureType,suffix) {
   #
   # apply a buffer model to a GIS layer with pressures,
   # clip at biotope layer boundary and combine with partial impact layer
   #
   # The function uses the global `impact_map` sf layer to add the pressure
   # Therefor, the output of this function should be assigned to `imapct_map` again
   #
   # pressureData - sf layer with pressure data
   # pressureType - layer type from tribble `cumi_buffers`, column ~pressure
   # suffix - suffix to append to the string "impact_" as name for the column to be filled with the calculated impacts
   #
   # mapply() needed in mutate() function since mutate() operates on vectors and the cumi_get_impact() function not.
   # Also, unname() needed in mutate() function since mapply() will return a named object and we only the vector inside.
   # We need the namespace identifier in mutate() and select() as otherwise the plyr functions are called.
   # Also note, from here on we typically need to repeatedly cast impact_map to MULTIPOLYGON as otherwise
   #    we will get an error such as "Error in CPL_geos_op2(op, x, y) : attr classes has wrong size: please file
   #    an issue)" which comes from the first st_difference() in my_union_sf()
   #
   intensity_layer <- cumi_buffer_intensity(pressureData,pressureType)
   column <- paste("impact_",suffix,sep="")
   cumi_message("... unioning ...")
   result <- st_cast(impact_map,"MULTIPOLYGON") %>% 
      my_union(intensity_layer) %>% 
      dplyr::mutate( {{ column }} := unname(mapply(cumi_get_impact,intensity,sens))) %>% 
      dplyr::select(-intensity) %>% filter(! is.na(Biotope))
   cumi_message("Done!")
   return(result)
}
```


Last, and not least, we want some regular feedback from the script, since some of the operations (especially the GIS union) are taking some time:


```{r}
get_running_time <- function(n1,n2) {
	#
	# return the difference between to Sys.time() values an minutes,
	# nicely formatted
	#
	# n1, n2 - first and second Sys.time() values
	#
	n <- format((as.numeric(n2)-as.numeric(n1))/60, digits=1,decimal.mark=".")
	return(paste(n,"minutes"))
}

cumi_message <- function(msg) {
   #
   # print some nice, friendly message
   #
   # msg - text of the message to print
   #
   msg <- paste("--- CumI --- (", get_running_time(n1,Sys.time()),"): ",msg,sep="")
   cat(paste(" ",msg," "," ",sep="\n"))
   flush.console()
}
```

# The assessment

## Setup
Everything should be going on in the same coordinate system. So, we define this variable in order to be able to uniformly transform to this. It is the EPSG code for "ETRS89-extended / LAEA Europe":

```{r}
cumi_message("setting up the assessment ...")
coordSystem <- 3035
```

For the assessment for work with this script, all data file need to be present on your computer. The data are GIS files from various sources and they need to have specific attribute table columns to work directly with this script. A folder "Data" comes together with this script and enables you to run the current assessment without changing the script, as long as the script is in the same directory as the 'Data' folder:

```{r}
# go to the folder where I have the script and the 'Data' folder:
# --> YOU CAN CHANGES THIS LINE FOR YOUR SETUP ON YOUR OWN MACHINE <--
setwd("/Users/Torsten/Marilim/OneDrive/OneDrive - MariLim Gesellschaft für Gewässeruntersuchung mbH/MSRL/CumI-R/")
```

## The biotope map
The current biotope map is a combination of all layers in the HELCOM database under [Biodiversity > Ecosystem components (BSII) > Broadscale habitats](https://maps.helcom.fi/website/mapservice/). These are 8 different habitat types. These were combined with the extent of some benthic species leading to a high sensitivity (Biodiversity > Ecosystem components (BSII) > Benthic species). The sensitivity is already included in this layer. The following steps were involved in this:

- assign sensitivities to biotopes
- apply "high" spatial sensitivity to regions with Mytilus, Zostera, Furcellaria, Fucus, Chara
- assign assessment area to the biotopes by intersection with HELCOM map "HELCOM subbasins 2018"
- assign country to the polygons by intersection with EMOTnet data "Emodnet_HA_OtherManagementsAreas_EEZ_20180629.shp"
- assign bottom salinity from HELCOM BALANCE data "BALANCE Modelledbottomsalinity/Bottomsalinity-vektorisiert.shp"

<!--
the emodnet data where extended into the layer countries.shp by drawing additional polygons over land. this makes sure that all poygons from the HELCOM data are included and not clipped away since the emodnet shoreline is very rough

biotopes.shp > buffer (0) + helcom_subbasins_2018 > buffer(0) = intersect > biotopes+assess

Emodnet_HA_OtherManagementsAreas_EEZ_20180629.shp > manual extension = countries.shp

biotopes+assess > buffer(0) + countries > buffer(0) = intersect > biotopes+assess+countries

biotopes+assess+countries > buffer(0) + Bottomsalinity-vektorisiert > buffer(0) > coord(3035)  = union > biotopes-pre_calculated

delete all polygons without biotope assignment (these are the ones from the salinity layer that lie beyond the biotope map)
filter(biotopes-pre_calculated,! is.na(Biotope))

delete some columns:
select(-c(HELCOM_ID,Area_km2,DN))

correct an error in Sal2:
biotopes-pre_calculated$Sal2[biotopes-pre_calculated$Sal2 == ">5"] <- "<5"
-->

The pre-calculated biotope layer has these attribute columns:

- Biotope = HELCOM broadscale habitat
- sens = general pressure-independant sensitivity
- s_surf = sensitivity against surface abrasion due to bottom trawling
- s_subsurf = sensitivity against subsurface penetration due to bottom trawling (not used in this assessment)
- sens_spec = whether the sensitivity was raised to 'high' due to sensitive species
- level_2 = HELCOM subbasins 2018 (assessment units)
- Territory = country name
- Sal = bottom salinity class (from HELCOM BALANCE project)
- Sal2 = bottom salinity value range (from HELCOM BALANCE project)

```{r}
cumi_message("preparing biotope layer ...")
biotope_file <- "Data/Biotopes/biotopes-pre_calculated.shp"
# this file is a mix of polygon and multipolygon, so we cast everything to multipolygon first,
# in order to prevent errors in later spatial operations
##biotopeLayer <- st_read(biotope_file) %>% st_cast("MULTIPOLYGON") %>% dplyr::select(-s_subsurf) %>% st_make_valid()
```

Starting from the pre-defined sensitivities, two countries have requested changes to these. Those changes are implemented in the following step (only for those polygons where the sensitivity not was raised to 'high' due to presence of sensitive species):

```{r eval=FALSE}
# changes for Denmark:
biotopeLayer$sens[biotopeLayer$sens_spec == 0 & biotopeLayer$Territory == "Denmark" & biotopeLayer$Biotope == "circa mix"] <- "high"
biotopeLayer$sens[biotopeLayer$sens_spec == 0 & biotopeLayer$Territory == "Denmark" & biotopeLayer$Biotope == "infra mix"] <- "high"
biotopeLayer$sens[biotopeLayer$sens_spec == 0 & biotopeLayer$Territory == "Denmark" & biotopeLayer$Biotope == "infra sand"] <- "low"
biotopeLayer$sens[biotopeLayer$sens_spec == 0 & biotopeLayer$Territory == "Denmark" & biotopeLayer$Biotope == "circa sand"] <- "low"
# changes for Sweden:
biotopeLayer$s_surf[biotopeLayer$sens_spec == 0 & biotopeLayer$Territory == "Sweden" & biotopeLayer$Sal2 == ">5"] <- "low"

```

All pressure layers will be clipped at the outline of the biotope map, making the pressure layers lie completely within the biotope coverage (and not e.g. on land). For this, we build a clip layer from the biotope layer:

```{r}
cumi_message("... making clipLayer ... st_union() ...")
##clipLayer <- dplyr::select(biotopeLayer,-c(Biotope,sens,s_surf,sens_spec)) %>% st_cast("MULTIPOLYGON") %>% st_cast("POLYGON") %>% st_union()
```

## Pressure data and impact calculation
The initial impact map is just the biotope layer. This impact map gets combined (in principe via a GIS union operation) with each processed pressure layer. With each new pressure, one new column is added named 'impact_nx' where n is a number corresponding to the numbers in the following secions and x is either 'c' for 'under construction' or 'o' for 'in operation' or it is empty for those pressures which cannot be divided into these categories.

The assessment period is: 2011–2016.

```{r eval=FALSE}
cumi_message("preparing impact layer ...")
# initial impact layer is just the biotope map:
impact_map <- biotopeLayer
```

### 1. Bottom trawling fishery

```{r}
cumi_message("processing trawling fishery ...")
```

The fishery data were provided by ICES and then put into HELCOM Maps and Data Service. This version of the script uses a preprocessed version of these raw data, where all years have been combined into one GIS layer, the pressure has been smoothed from c-squares into an 1x1 km grid, the MOP has been calculated (column 'MOP_1') and the data have been combined with the above pre-calculated biotope map (including the changes in the sensitivities for DK and SE). *The next version of the script will also contain the necessary steps in R to make the preprocessing.*

The SAR values are treated directly as intensity and frequency is ignored, thus the SAR values are directly translated to MOP categories.

```{r}
#
# As this is the first pressure and it takes veeery looong to be calculated (approx. 7 hours on my machine and failing to report the percentage of finalization beyond the "10 %" value ...) even with the QGIS union procedure,
# we here provide a pre-calculated file, based on the first part of the script up to here. I.e., the pre-calculated layer
# already contains the biotope data combined with the bottom trawling data, and the pre-calculated layer already has
# the impact from trawling included.
# You can choose to either use the pre-calculated one (TRUE) for the further process, or re-calculate (FALSE) it here.
#
get_pre_calculated_data <- TRUE
#
# You might even want to use ArcGIS for this particular 'union' task below as it is even significantly faster than QGIS (24–45 seconds on my machine!!).
#
if (get_pre_calculated_data) {
	cumi_message("... using pre_calculated data ...")
	fishing_file_pre <- "Data/Fishing/HELCOM_1x1km_Baltic_Sea_surf_pre_calculated.shp"
	if (! file.exists(fishing_file_pre)) {
		cumi_message("... cannot find file with pre_processed data - skipping bottom trawling fishery ...")
	} else {
		impact_map <- st_read(fishing_file_pre) %>% st_make_valid()
	}
} else {
	cumi_message("... calculating fishery impact - this will take a lot of time ...")
	fishing_file <- "Data/Fishing/HELCOM_1x1km_Baltic_Sea_surf.shp"
	fishing_x <- st_read(fishing_file) %>% st_intersection(clipLayer)
	
	# treat SAR values lower than 0.05 as zero intensity:
	for (myColumn in c('SURFSAR_11','SURFSAR_12','SURFSAR_13','SURFSAR_14','SURFSAR_15','SURFSAR_16')) {
	   fishing_x[[myColumn]] <- ifelse( fishing_x[[myColumn]]>=0.05, fishing_x[[myColumn]] , 0 )
	}
	
	# convert SAR into MOP:
	fishing_x <- fishing_x %>% mutate(sar_avg = (SURFSAR_11 + SURFSAR_12 + SURFSAR_13 + SURFSAR_14 + SURFSAR_15 + SURFSAR_16)/6) %>%
	   mutate(MOP = case_when(
	   sar_avg == 0                     ~ 'none',
	   sar_avg  > 0    & sar_avg < 0.33 ~ 'very low',
	   sar_avg >= 0.33 & sar_avg < 0.66 ~ 'low',
	   sar_avg >= 0.66 & sar_avg < 2    ~ 'moderate',
	   sar_avg >= 2                     ~ 'high',
	   TRUE                             ~ 'undefined'
	))
	# we can now delete the columns we do not need in future
	# and we can remove all polygons with no MOP
	# and dissolve the MOP layer:
	fishing_x <- fishing_x %>%
		dplyr::select(-c(ET_ID,H_sub_code,H_sub_name,location,SURFSAR_11,SURFSAR_12,SURFSAR_13,SURFSAR_14,SURFSAR_15,SURFSAR_16,sar_avg)) %>%
		dplyr::filter(! MOP=='none') %>%
		group_by(MOP) %>% 
		summarize(geometry = st_union(geometry))
	
	# the my_union() in the following line is what takes 99.9% of the time in this pressure:
	impact_map %>% st_cast("MULTIPOLYGON") %>% my_union(fishing_x)
}
impact_map <- impact_map %>% st_cast("MULTIPOLYGON") %>% dplyr::mutate(impact_1 = unname(mapply(cumi_get_impact,MOP,s_surf))) %>% dplyr::select(-MOP)

```

### 2. Mariculture

```{r}
cumi_message("processing of mariculture ...")
```

Data layer from HELCOM: [Pressures > Baltic Sea Pressure and Impact Index > Human activities > Finfish mariculture](http://metadata.helcom.fi/geonetwork/srv/eng/resources.get?uuid=3cfa469a-6a78-4913-b82f-57fd0e7f4dc0&fname=Finfish_mariculture.zip&access=public), last accessed 2021-08-17.


These are point data. Some of the points are classified as "on land" and are ignored.

```{r}
cumi_message("... finfish ...")
mari_1_file <- "Data/Finfish_mariculture/Finfish_mariculture.shp"
mari_1 <- st_read(mari_1_file) %>% filter(! str_detect(AREA,'land'))

# In this case, MOP is the same as intensity as frequency is not applicable:
impact_map <- cumi_process_pressure(mari_1,"mariculture","2A")

```


Data layer from HELCOM: [Pressures > Baltic Sea Pressure and Impact Index > Human activities > Shellfish mariculture points](http://metadata.helcom.fi/geonetwork/srv/eng/resources.get?uuid=21efdecc-2fd7-4bfb-9832-68c995291bf7&fname=Shellfish_mariculture_points.zip&access=public), last accessed 2021-08-17.

These are point data. All sites are taken into account.

```{r}
cumi_message("... shellfish (points) ...")
mari_2_file <- "Data/Shellfish_mariculture_points/Shellfish_mariculture_points.shp"
mari_2 <- st_read(mari_2_file)

# In this case, MOP is the same as intensity as frequency is not applicable:
impact_map <- cumi_process_pressure(mari_2,"mariculture","2B")

```

Data layer from HELCOM: [Pressures > Baltic Sea Pressure and Impact Index > Human activities > Shellfish mariculture areas](http://metadata.helcom.fi/geonetwork/srv/eng/resources.get?uuid=8fbf946a-18d2-4b24-98ad-1327ba2820a8&fname=Shellfish_mariculture_areas.zip&access=public), last accessed 2021-08-18.

These are polygon data. All sites are taken into account.

```{r}
cumi_message("... shellfish (areas) ...")
mari_3_file <- "Data/Shellfish_mariculture_areas/Shellfish_mariculture_areas.shp"
mari_3 <- st_read(mari_3_file)

# In this case, MOP is the same as intensity as frequency is not applicable:
impact_map <- cumi_process_pressure(mari_3,"mariculture","2C")

```

### 3. Extraction and disposal of sediments

```{r}
cumi_message("processing extraction and disposal of sediments ...")
```

Data layer from HELCOM: [Pressures > Baltic Sea Pressure and Impact Index > Human activities > Extraction of sand and gravel](http://metadata.helcom.fi/geonetwork/srv/eng/resources.get?uuid=683224c3-2fb9-4f2f-b748-bf5ad712d708&fname=Extraction_of_sand_and_gravel.zip&access=public), last accessed 2021-08-16.


The data are represented as polygons. Since the extraction depth and the spatial extent of the extraction within the polygon is unknown, the complete polygon area is currently treated as loss. All listed sites are assumed active or at least disturbed as the expire dates (attribute column 'expire_yea') are either not specified or not before the start of the assessment period.

We still ignore inactive sites in the script stopping before the assessment period, as a place holder for future settings, although this has no effect in the current assessment.

Frequency cannot be evaluated from this dataset as it is unclear whether the data are complete and values for the extraction amount of zero just are confidential data, missing data or a real non-pressure in a specific year.

```{r}
cumi_message("... extraction of sand and gravel ...")
extraction_file <- "Data/Extraction_of_sand_and_gravel/Extraction_of_sand_and_gravel.shp"
extraction_x <- st_read(extraction_file) %>% filter(expire_yea == 0 | expire_yea > 2010)

# In this case, MOP is the same as intensity as frequency is currently ignored:
impact_map <- cumi_process_pressure(extraction_x,"extraction","3A")

```


Data layer from HELCOM: [Pressures > Baltic Sea Pressure and Impact Index > Human activities > Deposit of dredged material sites areas 2011-2016](http://metadata.helcom.fi/geonetwork/srv/eng/catalog.search#/metadata/0eebe008-aed9-461a-8c85-e7b32bdab822), last accessed 2021-08-19.


These are polygon data. All sites are included in the calculation. No loss is included for the footprint as it is unknown to what extent the actual area is being used and typically only a part of the designated area is actively used.


```{r}
cumi_message("... deposit of dredged material (areas) ...")
deposit_1_file <- "Data/deposit_areas_11_16/deposit_areas_11_16.shp"
deposit_1 <- st_read(deposit_1_file)

# In this case, MOP is the same as intensity as frequency is currently ignored:
impact_map <- cumi_process_pressure(deposit_1,"depositing","3B")

```



Data layer from HELCOM: [Pressures > Baltic Sea Pressure and Impact Index > Human activities > Deposit of dredged material sites points 2011-2016](http://metadata.helcom.fi/geonetwork/srv/eng/catalog.search#/metadata/34bf84a1-1f04-40c7-99dd-9b9aff4523ea), last accessed 2021-08-19.


These are point data. All sites are included in the calculation. No loss is included for the footprint as the size of the footprint is unknown.


```{r}
cumi_message("... deposit of dredged material (points) ...")
deposit_2_file <- "Data/deposit_points_11_16/deposit_points_11_16.shp"
deposit_2 <- st_read(deposit_2_file)

# In this case, MOP is the same as intensity as frequency is currently ignored:
impact_map <- cumi_process_pressure(deposit_2,"depositing","3C")

```



Data layer from HELCOM: [Pressures > Baltic Sea Pressure and Impact Index > Human activities > Dredging areas 2011-2016](http://metadata.helcom.fi/geonetwork/srv/eng/catalog.search#/metadata/2a0fbdfd-9aef-4d2e-9129-2d1cc3b4943b), last accessed 2021-08-19.

The data layer contains polygon data. The attribute column "DREDGING_A" makes a distinction between maintenance and capital dredging (but there is no specifications as to how these types are distinguished). Further, the dredging type can be 'environmental', 'x' or empty. As a good definition is missing, only sites marked specifically as capital dredging are treated as such. All other sites are treated as maintenance dredging.

```{r}
cumi_message("... capital dredging (areas) ...")
dredge_a_file <- "Data/Dredging_areas/Dredging_areas.shp"
dredge_1 <- st_read(dredge_a_file) %>% st_zm() %>% filter(DREDGING_A=="capital")

# In this case, MOP is the same as intensity as frequency is currently ignored:
impact_map <- cumi_process_pressure(dredge_1,"dredging CAP","3D")


cumi_message("... maintenance dredging (areas) ...")
dredge_2 <- st_read(dredge_a_file) %>% st_zm() %>% filter(DREDGING_A != "capital")

# In this case, MOP is the same as intensity as frequency is currently ignored:
impact_map <- cumi_process_pressure(dredge_2,"dredging M","3E")

```



Data layer from HELCOM: [Pressures > Baltic Sea Pressure and Impact Index > Human activities > Dredging points 2011-2016](http://metadata.helcom.fi/geonetwork/srv/eng/catalog.search#/metadata/bb6622b7-e5df-4637-8ebe-c2736e705a70), last accessed 2021-08-19.

The data layer contains point data. The attribute column "TYPE" makes a distinction between maintenance and capital dredging (but there is no specifications as to how these types are distinguished). Further, this attribute column contains many values that are not covered by the metadata specification. As a good definition is missing, only sites marked specifically as 'capital' or 'Capital' dredging in the "TYPE" attribute are treated as such. All other sites are treated as maintenance dredging.

The dredged amount is reported in the data as weight in tonnes. The CumI follows the recommendation of HGELCOM EN DREDS and uses an amount in terms of the volume (5,000 m^3^) as threshold between two different buffer models (see `cumi_buffers`). As the volume is not reported, a transformation of the data is needed. The density of sediments varies roughly between 1.1 and 2.5 g/cm^3^. Since the type of the dredged material is unknown, we here use an average density of 1.8 g/cm^3^.

Further, the dredged amount is not reported in all instances. When the amount is not known, it is assumed to be below 5000 m^3^.


```{r}
cumi_message("... capital dredging (points) ...")
dredge_p_file <- "Data/Dredg_points/Dredg_points.shp"
dredge_3 <- st_read(dredge_p_file) %>% filter(Type %in% c("capital","Capital"))

# the 'Amount_ton' column is a character type with commas, so produce a proper 'volume' column:
dredge_3 <- dredge_3 %>% mutate(volume = as.numeric(sub(",",".",Amount_ton))/1.8)

# In this case, MOP is the same as intensity as frequency is currently ignored:
# above 5000m3:
impact_map <- cumi_process_pressure(filter(dredge_3,volume>5000),"dredging CAP2","3F")
# below or equal to 5000m3:
impact_map <- cumi_process_pressure(filter(dredge_3,volume<=5000 | is.na(Amount_ton)),"dredging CAP1","3G")



cumi_message("... maintenance dredging (points) ...")
dredge_4 <- st_read(dredge_p_file) %>% filter(! Type %in% c("capital","Capital"))

# In this case, MOP is the same as intensity as frequency is currently ignored:
impact_map <- cumi_process_pressure(dredge_4,"dredging M","3H")

```


### 4. Pipelines and cables

```{r}
cumi_message("processing pipelines and cables ...")
```

Data layer from HELCOM: [Pressures > Baltic Sea Pressure and Impact Index > Human activities > Pipelines](http://metadata.helcom.fi/geonetwork/srv/eng/catalog.search#/metadata/5260249e-5850-431a-b130-3a096abac852), last accessed 2021-08-13.


There are no pipelines under construction in the dataset (attribute column 'Status'), thus only operational pipelines are included in the current assessment.

```{r}
cumi_message("... pipelines in operation (there are none under construction) ...")
pipeline_file <- "Data/Pipelines/Pipelines.shp"
pipeline_o <- st_read(pipeline_file) %>% filter(Status %in% (c('Operational','Unknown')))

# In this case, MOP is the same as intensity as frequency does not apply
impact_map <- cumi_process_pressure(pipeline_o,"pipeline O","4A")

```


Data layer from HELCOM: [Pressures > Baltic Sea Pressure and Impact Index > Human activities > Cables](http://metadata.helcom.fi/geonetwork/srv/eng/catalog.search#/metadata/c0e73e71-cafb-4422-a3a3-115687fd5c49), last accessed 2021-08-09.

```{r}
cumi_message("... cables under construction ...")
# remove z-coord and take the features with status="Under construction":
cable_file <- "Data/Cables/Cables.shp"
cable_c <- st_read(cable_file) %>% st_zm() %>% filter(Status == 'Under construction')


# In this case, MOP is the same as intensity as frequency does not apply:
# (we need the namespace identifier in rename as otherwise plyr::rename is called)
impact_map <- cumi_process_pressure(cable_c,"cable C","4B")



cumi_message("... cables in operation ...")
# remove z-coord and take the features with status="Operational":
cable_o <- st_read(cable_file) %>% st_zm() %>% filter(Status == 'Operational')

# In this case, MOP is the same as intensity as frequency does not apply:
impact_map <- cumi_process_pressure(cable_o,"cable O","4C")
```



### 5. Platforms and wind farms

```{r}
cumi_message("processing platforms and wind farms ...")
```

Data layer from HELCOM: [Pressures > Baltic Sea Pressure and Impact Index > Human activities > Oil platforms](http://metadata.helcom.fi/geonetwork/srv/eng/catalog.search#/metadata/fddc27ec-b6ae-407b-9dd8-f31a42d75412), last accessed 2021-08-19.

As we do not know from the data which kind of fundament the platforms have, we cannot determine whether or not to treat the footprint area as loss. Currently, we do not treat the the footprint as loss since platforms typically only have pylones and not the entire area of the platform is equivalent to lost habitat area. Further, as not explicitly stated in the metadata, the platforms as assumed to be "in operation".

```{r}
cumi_message("... oil platforms ...")
oil_file <- "Data/Oil_platforms/Oil_platforms.shp"
oil_x <- st_read(oil_file)

# In this case, MOP is the same as intensity as frequency does not apply:
impact_map <- cumi_process_pressure(oil_x,"platform O","5A")
```



Data layer from HELCOM: [Pressures > Baltic Sea Pressure and Impact Index > Human activities > Wind farms](http://metadata.helcom.fi/geonetwork/srv/eng/catalog.search#/metadata/80de3bc3-e3ec-474e-8ae8-4b29c205eb0a), last accessed 2021-08-13.


The 'Status' attribute lists some turbines 'Under construction' and some as 'Generating power'. The latter are taken as 'in operation'. Turbines with status 'Transformer' are not strictly turbines but transformer station. As there are only three of them in the dataset, they are also interpreted as being 'in operation' and treated as regular turbines. It can be considered to treat them differently in the future. According to ICES WKBEDLOSS, a radius of 15 m could be used for "offshore transformer stations or modules" (OTS/OTM).

As we do not know from the data which kind of fundament the turbines have, we cannot determine whether or not to treat the footprint area as loss. Currently, we do not treat the the footprint as loss.

```{r}
cumi_message("... OWF under construction ...")
owf_file <- "Data/Wind_turbines/wind_turbines.shp"
owf_c <- st_read(owf_file) %>% filter(Status == "Under construction")

# In this case, MOP is the same as intensity as frequency does not apply
impact_map <- cumi_process_pressure(owf_c,"OWF C","5B")


cumi_message("... OWF in operation ...")
owf_o <- st_read(owf_file) %>% filter(Status %in% (c('Generating power','Transformer')))
# In this case, MOP is the same as intensity as frequency does not apply
impact_map <- cumi_process_pressure(owf_o,"OWF O","5C")

```


### 6. Coastal protection

```{r}
cumi_message("processing coastal protection ...")
```

Data layer from HELCOM: [Pressures > Baltic Sea Pressure and Impact Index > Human activities > Coastal defense](http://metadata.helcom.fi/geonetwork/srv/eng/resources.get?uuid=2d47c5ea-4590-465f-a462-60ef59d3d7d3&fname=Coastal_defense.zip&access=public), last accessed 2021-08-12.

These are the interesting attributes in the data (description taken from HECLOM metadata page on this dataset):

- Const\_year: Year of construction; for some structure in Estonia the construction year is not known and this is marked as no data (ND)
- Estimated: Estimated date of completion if under construction (Estonia) or the year of environmental permit if year of construction is lacking (Finland)
- Out\_of\_use: Year when costal defence structure has been taken out of use


The data has an attribute 'Estimated' containg some years from the assessment period. It is not clear whether this means the objects were constructed earlier and finalised in the assessment period. Thus, only the objects having 'Const_year="Under construction"' are currently used.

```{r}
cumi_message("... coastal protection under construction ...")
# take the features with Const_year="Under construction":
coastalDef_file <- "Data/Coastal_defense/Coastal_defense.shp"
coastalDef_c <- st_read(coastalDef_file) %>% st_transform(coordSystem) %>% filter(Const_year == 'Under construction')

# In this case, MOP is the same as intensity as frequency does not apply:
# (there is only one construction event)
impact_map <- cumi_process_pressure(coastalDef_c,"coastalDef C","6A")



cumi_message("... coastal protection in operation ...")
# take the features where Const_year is null or is a 4-digit year or is 'ND':
coastalDef_o <- st_read(coastalDef_file) %>% st_transform(coordSystem) %>% 
	   filter(Const_year > 0 || is.na(Const_year) || Const_year == 'ND')

# In this case, MOP is the same as intensity as frequency does not apply:
impact_map <- cumi_process_pressure(coastalDef_o,"coastalDef O","6B")
```


Data layer from HELCOM: [Pressures > Baltic Sea Pressure and Impact Index > Harbours](http://metadata.helcom.fi/geonetwork/srv/eng/catalog.search#/metadata/e2a3a104-a7aa-49c9-bc2c-47845b3a322f), last accessed 2021-08-20.

This dataset provides harbours as polygons. All harbours are included in the assesment. The dataset also contains point data. These are derived from the polygon data for the estimation of port visits and is not dealt with here.

```{r}
cumi_message("... harbours (areas) ...")
harbour_file = "Data/Harbours/Harbour_polygons.shp"
harbour_o <- st_read(harbour_file)

# In this case, MOP is the same as intensity as frequency does not apply:
impact_map <- cumi_process_pressure(harbour_o,"harbour O","6C")
```


### 7. Shipping

```{r}
cumi_message("processing shipping ...")
```

Data layer from HELCOM: [Pressures > Baltic Sea Pressure and Impact Index > Shipping density 2011-2015](http://metadata.helcom.fi/geonetwork/srv/eng/catalog.search#/metadata/1fd5298f-d3be-4c5f-bb05-3dc66a8eea6b), last accessed 2021-08-20.

This script uses a pre-processed version of the HELCOM dataset. *The next version of this script will include the pre-processing prodedure in R*. These step were involved in order to arrive at the data layer used here:

1. use the layer "2011-2015_all_ship_types_MEAN/2011-2015_all_ship_types_MEAN.tif" from the above HELCOM dataset
2. vectorise the data and assign coordinate system EPSG:3035 (the raster value is put into an attribute column named 'density')
3. remove all polygons with raster value (density) of 0
4. apply zonal statisitcs (in QGIS: Tools > Raster analysis > Zonal statistics) with the mean of the depth (depth taken from HELCOM layer: “depth relief map” (raster data)) to get an average depth per density polygon (new attribute column named 'depth')
5. remove all polygons having a depth of 0 or higher (this defines the shoreline and the land)
6. remove all polygons having no depth value (due to missing overlap between depth data and shipping data)
7. remove all polygons having a depth value over 25 m (noot inclusing 25 m; there is no impact assumed in these depths)
8. make a new attribute 'depthzone' and classify depth values into the following classes:


```{QGIS eval=FALSE}
# attribue column 'depthzone':
CASE
 when "depth"<0 and "depth">=-10 then 1
 when "depth"<-10 and "depth">=-15 then 2
 when "depth"<-15 and "depth">=-20 then 3
 when "depth"<-20 and "depth">=-25 then 4
END
```

9. translate the density depending on the depthzone into a new attribute column ‘intensity’:


```{QGIS eval=FALSE}
# Weighted with depth:
# dephtzone 1: eqiuv. to 100 %  => density value is taken directly
# depthzone 2: equiv. to 50 % => density value divided by 2
# depthzone 3: equiv. to 25 % => density value divided by 4
# depthzone 4: equiv. to 10 % => density value divided by 10
# depthzone 5: equiv. to 0 % => polygon is removed (everything over 25 m)

# new attribute column 'intensity':
CASE
 when "depthzone"=1 then "density"
 when "depthzone"=2 then  "density"/2.0 
 when "depthzone"=3 then  "density"/4.0 
 when "depthzone"=4 then  "density"/10.0 
END
```

10. reclassify the intensity into the four MOP classes (we must ignore frequency at this stage as the data do not contain information on the shipping frequency). After the above steps, intensity values from 0 to 32166 remain. These are divided pragmatically into the uniform CumI scale:

```{QGIS eval=FALSE}
# new attribute column 'MOP':
CASE
when "intensity" >=0 and "intensity" < 8041 then 'very low'
when "intensity" >=8041 and "intensity" < 16083 then 'low'
when "intensity" >=16083 and "intensity" < 24124 then 'moderate'
when "intensity" >= 24124 and "intensity" <= 32166 then 'high'
END
```

11. dissolve the polygons by MOP only to reduce file size and risk of artifacts.



For now, we word with the pre-calculated data in our dataset:


```{r}
shipping_file <- "Data/Shipping (AIS-density)/shipping-pre-calculated-new.shp"
shipping_x <- st_read(shipping_file) %>% st_make_valid()
# we only have the clipping left and can then directly combine with the biotope layer:
##shipping_x <- shipping_x %>% st_intersection(clipLayer)
impact_map <- st_cast(impact_map,"MULTIPOLYGON") %>% 
   my_union(shipping_x) %>% 
   dplyr::mutate(impact_7 = unname(mapply(cumi_get_impact,MOP,sens))) %>% 
   dplyr::select(-c(MOP)) %>%
   rename_geometry("geometry") %>%
   filter(! is.na(Biotope))
```



## Calculate cumulative impact
cumi_message("Cumulating all impacts ...")


Now, all impacts are calculated and integrated into the biotope map. So, we cann now do the cumulation step by taking every single polygon, looking at all individual impacts for that polygon and then do a pair-wise combination:


```{r}
#
# the following code is explicit and thus slow (approx. 1 hour on my machine), will be speed-optimized later
#
# make list of all impact columns to loop over:
impactColumns <- grep("impact_[1-9].?",names(impact_map),value=TRUE)

# initialize a new column 'impact_cu' for the cumulative impact:
impact_map <- mutate(impact_map,impact_cumi = NA)

initialColumn <- impactColumns[1]
columnCount <- length(impactColumns)

# loop over each polygon/multipolygon in the map:
print(paste("0 of",nrow(impact_map)))
for (myRowIndex in 1:nrow(impact_map)) {
	rowData <- impact_map[myRowIndex, ]
	if (myRowIndex %% 2000 == 0) {print(paste(myRowIndex,"of",nrow(impact_map))); flush.console()}
	# foreach pair of impact columns, do the cumulation:
	for (myColIndex in 1:(columnCount-1)) {
		if (myColIndex == 1) {i1 <- rowData[[impactColumns[1]]]} else {i1 <- ik}
		i2 <- rowData[[impactColumns[myColIndex+1]]]
		ik <- cumi_get_cumulation(i1,i2)
	}
	impact_map$impact_cu[myRowIndex] <- ik
}
```


```{r}
impac_map_loss <- impact_map %>% filter(c_impact == 'loss')

```



```{r}
n2 <- Sys.time()
cumi_message("Finished assesment!")
print(n2)
print(paste("Total assessment processing time:",get_running_time(n1,n2))
```

# Outlook
This version of the script is an initial version. It implements the basic features of the CumI that are needed in order to do a CumI assessment with the current HELCOM dataset. In the near future, new dataset will be available. This will be the point where the script needs changes in order to work with the new or updated data (e.g. integrating pressure frequency for more pressures).

Apart from thsi, the following updates are planned for the next version:

- some visualizations will be implemented on the resulting impact map, such as graphs on the aerial extent of the various impact levels over the whole assessment area or certain subdivisions of that area
- the pre-processing of the bottom trawling data and the shipping data will be implemented
- the pre-processing of the biotope map
- a distinction between 'no data' and 'no impact' will be implemented

# Random notes and testing code

```{r eval=FALSE}
#
# just some testing code ...
#
impact1 <- "/Users/Torsten/Marilim/OneDrive/OneDrive - MariLim Gesellschaft für Gewässeruntersuchung mbH/MSRL/Daten/QGIS-Modelle/QGIS aktuell/MSRL III/CumI-Berechnung HELCOM 2020-02/1_biotopes.shp"

impact2 <- "/Users/Torsten/Marilim/OneDrive/OneDrive - MariLim Gesellschaft für Gewässeruntersuchung mbH/MSRL/Daten/QGIS-Modelle/QGIS aktuell/MSRL III/CumI-Berechnung HELCOM 2020-02/2_biotopes.shp"

i1 <- st_read(impact1)
i2 <- st_read(impact2)

i_1_2 <- my_union(i1,i2)

# get rid of the fid_ columns:
impact_map <- impact_map %>% select(-contains("fid_"))

# get rid of MULTILINESTRINGS:
filter(mySF,st_geometry_type(mySF) %in% c("POLYGON","MULTIPOLYGON"))

```