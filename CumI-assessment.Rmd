---
title: Assessment of the cumulative impact from physical pressures on benthic biotopes in the Baltic Sea using the CumI indicator
author: Torsten Berg, MariLim
date: 2022-11-11
output: html_document
editor_options: 
  chunk_output_type: console
---

# How to use this document
This is an R markdown document. The R code within this document can be executed using the R `library(knitr)`:

```{r help-eval-code, eval=FALSE}
library(knitr)
# purl() is the same as knit(..., tangle=TRUE)
source(purl("CumI-assessment.Rmd"))
```

The documentation can be produced together with executing the R code using:

```{r help-make-doc, eval=FALSE}
library(rmarkdown)
library(knitr)
render("CumI-assessment.Rmd")
```

If you do not want to evaluate the R code, but just render the document, use `knitr::opts_chunk$set(eval=FALSE)` before rendering.

# General setup

For the assessment for work with this script, all data files need to be present on your computer. The data are GIS files from various sources and they need to have specific file names and attribute table columns to work directly with this script. A folder "Data-2022" comes together with this script and enables you to run the current assessment without changing the script, as long as the script is in the same directory as the 'Data-2022' folder and the data folder is filled with the necessary data folders and files.

Set the directory of the data folder in the following code chunk.

```{r setup}
# --> YOU SHOULD CHANGES THIS LINE FOR YOUR SETUP ON YOUR OWN MACHINE <--
myDir <- "/Users/Torsten/Marilim/OneDrive/OneDrive - MariLim Gesellschaft für Gewässeruntersuchung mbH/MSRL/CumI-R/Data-2022"
```

# R packages to use
The R code uses the following libraries which should be installed first (if not present):

```{r}
n1 <- Sys.time()
print(paste("--- CumI ---: starting at",n1,sep=" "))
print("--- CumI ---: loading libraries ...")
library(dplyr)
# library(naniar)
library(stringr) # using str_detect() and word()
library(tibble)
library(sf)
library(terra) # for species raster data
# library(knitr) # already done above if needed
```

# Some R functions

```{r include=FALSE}
print("--- CumI ---: defining some R functions ...")
```

## General GIS-related functions

R has no function corresponding to a true union in GIS. `st_union` in the sf library is not equivalent. Since we need lots of real union operations here, we need a custom function. The following code ist from [stackowerflow](https://stackoverflow.com/questions/54710574/how-to-do-a-full-union-with-the-r-package-sf) and illustrates the process. It is the basis of our function:

```{r eval=FALSE}
a1 <- st_polygon(list(rbind(c(0, 10), c(45, 10), c(45, 90), c(0, 90), c(0, 10))))
a2 <- st_polygon(list(rbind(c(45, 10), c(90,10), c(90, 90), c(45, 90), c(45, 10))))
b1 <- st_polygon(list(rbind(c(15, 5), c(75, 5), c(75, 50), c(15, 50), c(15, 5))))

a <- st_sf(station=c(1, 2), geometry=st_sfc(a1, a2))
b <- st_sf(type="A",	geometry=st_sfc(b1))

st_agr(a) = "constant" #to avoid warnings, but see https://github.com/r-spatial/sf/issues/406
st_agr(b) = "constant"

#Operations
plot(st_geometry(st_union(a,b)))

op1 <- st_difference(a,st_union(b)) #notice the use of st_union()
plot(st_geometry(op1), border="red", add=TRUE)

op2 <- st_difference(b, st_union(a)) #notice the order of b and a and st_union()
plot(st_geometry(op2), border="green", add=TRUE)

op3 <- st_intersection(b, a) #notice the order of b and a
plot(st_geometry(op3), border="blue", add=TRUE)

# union <- rbind(op1, op2, op3) #Error because op1 (op2) doesn't have the column "type" ("station")
#> Error in match.names(clabs, names(xi)): names do not match previous names

op11 <- dplyr::mutate(op1, type=NA)
op22 <- dplyr::mutate(op2, station=NA)

union <- rbind(op11, op22, op3)
```

From this, we can make a union function that can work with arbitrary sf objects:

```{r eval=FALSE}
library(plyr)

my_union_sf <- function(a,b) {
	#
	# function doing a real GIS union operation such as in QGIS or ArcGIS
	#
	# a - the first sf
	# b - the second sf
	#
	st_agr(a) = "constant"
	st_agr(b) = "constant"
	op1 <- st_difference(a,st_union(b))
	op2 <- st_difference(b, st_union(a))
	op3 <- st_intersection(b, a)
	union <- rbind.fill(op1, op2, op3)
	return(st_as_sf(union))
}
```

Since this custom sf function is very slow (and I mean: veeeery slow), we explore another possibility provided by the raster library which, however, involves some transforming back and forth to sp Spatial\* objects (SpatialPolygonsDataFrame):

```{r eval=FALSE}
library(sp) # used by 'raster'
library(raster) # provides: raster::union()

my_union_raster <- function(a,b,sf=TRUE) {
	#
	# function doing a real GIS union operation such as in QGIS or ArcGIS
	# on Spatial* objects (from the sp library)
	#
	# a - the first sf or Spatial* object
	# b - the second sf or Spatial* object
	# sf - whehter or not to convert the output to an sf object
	#
	# when an objects is not a Spatial* object, it will be converted first
	#
	if (! class(a)[1] == "SpatialPolygonsDataFrame") {a <- as_Spatial(a)}
	if (! class(b)[1] == "SpatialPolygonsDataFrame") {b <- as_Spatial(b)}
	res <- raster::union(a,b)
	if (sf) {return(as(res,"sf"))} else {return(res)}
}
```

Unfortunately, also this function turns out to be quite slow ...

If a recent version of QGIS is present (version 3.14.16 or newer), we therefor should utilize the function `qgis_run_algorithm` and let the union be done by QGIS. This will increase the performance by many magnitudes! You do not need to know how QGIS works in order to use this function. R takes care of it all. This function has the additional benefit to print out a percentage of the progress, so you can see how long to wait for the next union:

```{r}
# needs QGIS 3.14.16 or newer
# Installation:
# install.packages("remotes")
# remotes::install_github("paleolimbot/qgisprocess")
library(qgisprocess)

my_union <- function(a,b) {
	st_agr(a) = "constant" #to avoid warnings, but see https://github.com/r-spatial/sf/issues/406
	st_agr(b) = "constant"
	result <- qgis_run_algorithm(
		"native:union",
		INPUT = a,
		OVERLAY = b,
		OVERLAY_FIELDS_PREFIX = '')
	# read the resulting union, get rid of the produced "fid_" columns and make sure the geometry column is correctly named:
	result <- sf::read_sf(qgis_output(result, "OUTPUT")) %>% dplyr::select(-contains("fid_")) %>% rename_geometry("geometry")
	# sometimes, the union results in some MULTILINESTRINGS - we must delete those:
	if (st_geometry_type(result,by_geometry=FALSE) == "GEOMETRY") {
		cumi_message("... deleting MULTILINESTRINGs from last union ...")
		result <- result %>% filter(st_geometry_type() %in% c("POLYGON","MULTIPOLYGON"))
	}
	return(result)
}
```

After an initial and not comprehensive test, it seems that the union function in the new terra package is even faster than using a QGIS process for smaller files:

```{r eval=FALSE}
my_union <- function(a,b) {
	if (! class(a)[1] == "spatVector") {a <- vect(a)}
	if (! class(b)[1] == "spatVector") {b <- vect(b)}
	result <- terra::union(a,b)
	return(st_to_sf(result))
}
```

If you can't use QGIS or terra, you will need to rename one of the first two union functions to `my_union` (and rename the QGIS/terra function to something else) and live with a very poor performance, meaning to wait hours and hours for some GIS union processing (I don't even know how long it takes because I always stopped the execution after 1–2 hours).


Sometimes, we need to rename the geometry column of an sf object, since sf itself will give it some weird names:

```{r}
rename_geometry <- function(g, name){
	#
	# rename the geometry columns (sfc) to a user-defined name
	# (taken from: https://gis.stackexchange.com/questions/386584/sf-geometry-column-naming-differences-r)
	#
	# g - sf object to rename the geometry column for
	# name - the name string to be used for the geometry column
	#
	current = attr(g, "sf_column")
	names(g)[names(g)==current] = name
	st_geometry(g)=name
	return(g)
}
```


## CumI-specific functions
The actual assessment using the CumI applies a range of 'matrix operations' where e.g. sensitivity of a given biotope is combined with the magnitude of pressure. This is done using some fixed rules. These rules and the R function to use them are given below.

The first rule combines resilience and resistance of a biotope to derive the resulting biotope sensitivity:

```{r}
print("--- CumI ---: defining CumI objects and functions ...")

# the sensitivity matrix:
cumi_sensi_matrix <- tribble(
    ~resistance, ~resilience_verylow, ~resilience_low, ~resilience_moderate, ~resilience_high,
    "very low",  "high",              "high",          "moderate",           "moderate",
    "low",       "high",              "moderate",      "moderate",           "low",
    "moderate",  "moderate",          "moderate",      "low",                "very low",
    "high",      "moderate",          "low",           "low",                "very low"
)


# a function to retrieve the sensitivity:
cumi_get_sensi <- function(resist,resil) {
	#
	# function returning the sensitivity given the resilience
	# and the resistance as strings
	#
	# resist - the resistance as string
	# resil - the resilience as string
	#
	resil <- paste("resilience_",gsub(" ", "", resil, fixed = TRUE),sep="")
	result <- subset(cumi_sensi_matrix,resistance==resist)[[resil]]
	if (is.null(result)) {
		return('none')
	} else {
		return(result)
	}
}
```


The second rule combines intensity and frequency to derive the magnitude of impact (MOP) of a pressure:

```{r}
# the MOP matrix:
cumi_MOP_matrix <- tribble(
    ~intensity, ~frequency_persistent, ~frequency_frequent, ~frequency_regular, ~frequency_occasional,
    "high",     "high",                "high",              "moderate",          "moderate",
    "moderate", "high",                "moderate",          "moderate",          "low",
    "low",      "moderate",            "moderate",          "low",               "very low",
    "very low", "moderate",            "low",               "very low",          "very low"
)


# a function to retrieve the MOP:
cumi_get_MOP <- function(inten,freq) {
	#
	# function returning the MOP given the pressure intensity
	# and the frequency as strings
	#
	# inten - the intensity as string
	# freq  - the frequency as string
	#
	freq <- paste("frequency_",freq,sep="")
	result <- subset(cumi_MOP_matrix,intensity==inten)[[freq]]
	if (is.null(result)) {
		return('none')
	} else {
		return(result)
	}
}
```


The third rule combines biotope sensitivity and the physical magnitude of pressure (= MOP) to derive the assumed impact:

```{r}
cumi_impact_matrix <- tribble(
	~sensitivity, ~MOP_high, ~MOP_moderate, ~MOP_low,	~MOP_verylow,
	"high",		 "high",	 "high",		  "m2",		 "m1",
	"moderate",	"high",	 "m3",			 "m1",		 "low",
	"low",		  "m2",		"m1",			 "low",		"very low",
	"very low",	"m1",		"low",			"very low", "very low"
)

	  
cumi_get_impact <- function(MOP,sensi) {
	#
	# function returning the impact given the MOP
	# and the sensitivity as strings
	#
	# MOP - MOP category as string
	# sensi - sensitivity category as string
	#
	if (is.na(MOP)) {return("none")}
	if (is.na(sensi)) {return("none")}
	if (MOP == "loss") {return("loss")}
	MOP <- paste("MOP_",gsub(" ", "", MOP, fixed = TRUE),sep="")
	result <- subset(cumi_impact_matrix,sensitivity==sensi)[[MOP]]
	if (is.null(result)) {
		return('none')
	} else {
		if (identical(result,character(0))) {print(paste(MOP,"and",sensi,"lead to null"))}
		return(result)
	}
}
```

The fourth rule combines two impacts when these are cumulated in the last step of the assessment:

```{r}
# the cumulation matrix:
cumi_cumulation_matrix <- tribble(
	~imp1,		 ~imp2_high, ~imp2_m3, ~imp2_m2, ~imp2_m1, ~imp2_low, ~imp2_verylow,
	"high",		"loss",	  "loss",	"high",	"high",	"high",	 "high",
	"m3",		  "loss",	  "loss",	"high",	"m3",	  "m3",		"m3",
	"m2",		  "high",	  "high",	"m3",	  "m2",	  "m2",		"m2",
	"m1",		  "high",	  "m3",	  "m2",	  "m2",	  "m1",		"m1",
	"low",		 "high",	  "m3",	  "m2",	  "m1",	  "low",	  "low",
	"very low",  "high",	  "m3",	  "m2",	  "m1",	  "low",	  "very low"
)

# a function to retrieve the cumulative impact:
cumi_get_cumulation <- function(i1,i2) {
	#
	# function returning the cumulative impact
	# given two impacts that act at the same time
	# and at the same place
	#
	# i1 - the first impact category as string
	# i2 - the second impact category as string
	#
	# The following test needs to come first, because we cannot use NA values in the code further below:
	if (is.na(i1)) {i1 == 'none'}
	if (is.na(i2)) {i2 == 'none'}
	if (i1 == 'none') {return(i2)}
	if (i2 == 'none') {return(i1)}
	#
	if (i1 == "loss" || i2 == "loss" ) {return("loss")}
	#
	i2 <- paste("imp2_",gsub(" ", "", i2, fixed = TRUE),sep="")
	result <- subset(cumi_cumulation_matrix,imp1==i1)[[i2]]
	if (is.null(result)) {
		return('none')
	} else {
		return(result)
	}
}
```

Some of the pressures work with a buffering. This means, the pressure is acting on a spatially larger area than the actual footprint (polygon, line or point data) of the pressure source. These pressures are listed here. The intensity of the pressure decreases with increasing distance from the pressure. The buffer distances in the table below represent the maximum distance (in metres) for the specific pressure intensity category, measured from the pressure source. As an example, a buffer distance of 50 for a high intensity means a buffer from 0–50 metres around a pressure source (which can be a point, a line or a polygon). A subsequent moderate intensity up to 100 then is an adjacent buffer 50–100 metres around a pressure source. So, the number in a specific columns is always the radius of the outer border of a zone, not its width.

The table also lists whether there is a buffer zone counting as 'loss' (~buffer\_loss) and whether the pressure footprint itself (in case of polygone data) is treated as loss (~footprint\_as\_loss).

```{r}
#
# buffer models for pressure intensity
#
# in the pressure column:
#	C = under construction
#	O = in operation
#	M = maintenance
#	CAP1, CAP2 = capital
#	OWF = offshore wind farm
#
cumi_buffers <- tribble(
	~pressure,		~description,                  ~buffer_loss,  ~buffer_high, ~buffer_moderate, ~buffer_low,	~buffer_verylow,  ~footprint_as_loss,
	#--------------|------------------------------|--------------|-------------|-----------------|--------------|------------------|------------------
	"extraction",	"sand and gravel extraction",  0,				 50,			  100,				  250,			  500,					 1,
	"depositing",	"deposit of dredged material", 0,				 50,			  100,				  250,			  500,					 0,
	"dredging M",	"maintenance dredging",        0,				 50,			  100,				  250,			  500,					 0,
	"dredging CAP", "capital, areas",              0,				  0,			    0,				    0,			    0,					 1,
	"dredging CAP1","captial, points, <= 5000m3", 25,				 25,			   25,				   25,			   25,					 1,
	"dredging CAP2","capital, points, > 5000m3",  50,				 50,			   50,				   50,			   50,					 1,
	"cable C",		"cable",                       0,				  0,			  550,				  600,			 1000,					 0,
	"cable O",		"cable",                       1.5,				1.5,			    1.5,			    1.5,		    1.5,				 0,
	"pipeline C",	"pipelines",                   0,				  0,			  550,				  600,			 1000,					 1,
	"pipeline O",	"pipelines",                  15,				 15,			   15,				   90,			  315,					 0,
	"platform C",	"platforms",                   0,				  0,			  550,				  600,			 1000,					 0,
	"platform O",	"platforms",                  25,				 25,			   25,				   25,			   25,					 0,
	"OWF C",		"offshore wind farms",         0,				  0,			  550,				  600,			 1000,					 0,
	"OWF O",		"offshore wind farms",        30,				 30,			   40,			       50,			  130,					 0,
	"OWF O mono",	"offshore wind farms",        30,				 30,			   40,			       50,			  130,					 1,
	"coastalDef C", "coastal defence",             0,				 50,			  100,				  250,			  500,					 0,
	"coastalDef O", "coastal defense",            50,				 50,			   50,				   50,			   50,					 0,
	"mariculture",  "mariculture",               150,				150,			  400,				  650,			 1150,					 1,
	"harbour O",	"harbour",                   200,				  0,			    0,				    0,			    0,					 0
)
```


The following function uses the above buffer models to calculate the concrete spatial extent of the various intensity zones for a given pressure:

```{r}
cumi_buffer_intensity <- function(pressureData,pressureBufferModel) {
	#
	# build an sf object that holds all different intensity zones and a loss zone
	# for a specific pressure
	#
	# pressureData - the sf objects holding the raw pressure data as points, lines or polygons
	# pressureBufferModel - the symbolic name of the buffer model in the tribble 'cumi_buffer'
	# (column ~pressure)
	#
	
	footprint <- filter(cumi_buffers,pressure==pressureBufferModel)[["footprint_as_loss"]]
	loss <- filter(cumi_buffers,pressure==pressureBufferModel)[["buffer_loss"]]
	vl	<- filter(cumi_buffers,pressure==pressureBufferModel)[["buffer_verylow"]]
	l	 <- filter(cumi_buffers,pressure==pressureBufferModel)[["buffer_low"]]
	m	 <- filter(cumi_buffers,pressure==pressureBufferModel)[["buffer_moderate"]]
	h	 <- filter(cumi_buffers,pressure==pressureBufferModel)[["buffer_high"]]
	
	# 'very low' zone:
	if (vl-l > 0) {
		b_verylow <- st_buffer(pressureData,vl)
		b_low <- st_buffer(pressureData,l)
		zone_verylow <- st_sf(st_difference(st_union(b_verylow),st_union(b_low))) %>%
		  st_cast("POLYGON") %>% mutate(intensity="very low") %>% rename_geometry("geometry")
		output <- zone_verylow
	}
	
	# 'low' zone:
	if (l-m > 0) {
		if (! exists("b_low")) {b_low <- st_buffer(myLayer,l)}
		b_moderate <- st_buffer(pressureData,m)
		zone_low <- st_sf(st_difference(st_union(b_low),st_union(b_moderate))) %>%
		  st_cast("POLYGON") %>% mutate(intensity="low") %>% rename_geometry("geometry")
		if (exists("output")) {
		  output <- add_row(output,zone_low)
		} else {
		  output <- zone_low
		}
	}
	
	# 'moderate' zone:
	if (m-h > 0) {
		if (! exists("b_moderate")) {b_moderate <- st_buffer(pressureData,m)}
		if (! exists("b_high")) {b_high <- st_buffer(pressureData,h)}
		zone_moderate <- st_sf(st_difference(st_union(b_moderate),st_union(b_high))) %>%
		  st_cast("POLYGON") %>% mutate(intensity="moderate") %>% rename_geometry("geometry")
		if (exists("output")) {
		  output <- add_row(output,zone_moderate)
		} else {
		  output <- zone_moderate
		}
	}
	
	# 'high' zone:
	if (h-loss > 0) {
		if (! exists("b_high")) {b_high <- st_buffer(pressureData,h)}
		if (! exists("b_loss")) {b_loss <- st_buffer(pressureData,loss)}
		zone_high <- st_sf(st_difference(st_union(b_high),st_union(b_loss))) %>%
		  st_cast("POLYGON") %>% mutate(intensity="high") %>% rename_geometry("geometry")
		if (exists("output")) {
		  output <- add_row(output,zone_high)
		} else {
		  output <- zone_high
		}
	}
	
	# 'loss' zone:
	if (loss > 0) {
		if (! exists("b_loss")) {b_loss <- st_buffer(pressureData,loss)}
		zone_loss <- st_union(b_loss) %>% st_sf() %>% st_cast("POLYGON") %>% mutate(intensity="loss") %>% rename_geometry("geometry")
		if (exists("output")) {
		  output <- add_row(output,zone_loss)
		} else {
		  output <- zone_loss
		}
	}
	
	# footprint zone as 'loss':
	if (footprint & st_geometry_type(pressureData,by_geometry=FALSE) != "POINT") {
		zone_footprint <- st_buffer(pressureData,0) %>% st_union() %>% st_sf() %>%
			st_cast("POLYGON") %>% mutate(intensity="loss") %>% rename_geometry("geometry")
		if (exists("output")) {
		  output <- add_row(output,zone_footprint)
		} else {
		  output <- zone_footprint
		}
	}
	
	return(output)
}
```

In order to make the script a bit more concise, a function combining some standard steps into one go is used. It reads the opened pressure GIS layer, assuming it is having a valid geometry/topology and the correct coordinate system, applies the buffer model, clips the resulting layer at the boundary of the biotope layer, includes it into the final impact layer and calculates the impact (and deletes the now superfluous 'int' column):


```{r}
cumi_process_pressure <- function(pressureData,pressureType,suffix) {
	#
	# apply a buffer model to a GIS layer with pressures,
	# clip at biotope layer boundary and combine with partial impact layer
	#
	# pressureData - sf layer with pressure data
	# pressureType - layer type from tribble `cumi_buffers`, column ~pressure
	# suffix - suffix to append to the string "impact_" as name for the column to be filled with the calculated impacts
	#
	# This function for now treats intensity as MOP, as we do not have frequceny data  yet
	#
	# The function uses the global `impact_map` sf layer to add the pressure
	# Therefor, the output of this function should be assigned to `imapct_map` again
	#
	# Note 1: mapply() needed in mutate() function since mutate() operates on vectors and the cumi_get_impact() function not.
	# Also, unname() needed in mutate() function since mapply() will return a named object and we only want the vector inside.
	# We need the namespace identifier in mutate() and select() as otherwise the plyr functions are called.
	#
	# Note 2: from here on we typically need to repeatedly cast impact_map to MULTIPOLYGON as otherwise
	# we will get an error such as "Error in CPL_geos_op2(op, x, y) : attr classes has wrong size: please file
	# an issue)" which comes from the first st_difference() in my_union_sf()
	#
	# Note 3: when storing pressure maps, we use the global configuration variable store_pressure_maps
	# and the corresponding file already being initiated during processing
	# of fishery pressure data; see below in the section for setting up the assessment.
	# (This is not optimal modular programming, but it do for now)
	#
	intensity_layer <- cumi_buffer_intensity(pressureData,pressureType)
	if (store_pressure_maps) {
		st_write(rename(intensity_layer,MOP = intensity), pressure_maps_file, layer=paste("mop_",suffix,sep=""))
	}
	if (do_cumi) {
		column <- paste("impact_",suffix,sep="")
		cumi_message("... unioning ...")
		result <- st_cast(impact_map,"MULTIPOLYGON") %>% 
			my_union(intensity_layer) %>% 
			dplyr::mutate( {{ column }} := unname(mapply(cumi_get_impact,intensity,sens))) %>% 
			dplyr::select(-intensity) %>% filter(! is.na(Biotope))
		cumi_message("Done!")
		return(result)
	} else {
		return(intensity_layer)
	}
}
```


Last, and not least, we want some regular feedback from the script, since some of the operations (especially the GIS union) are taking some time:


```{r}
get_running_time <- function(n1,n2) {
	#
	# return the difference between to Sys.time() values an minutes,
	# nicely formatted
	#
	# n1, n2 - first and second Sys.time() values
	#
	min <- (as.numeric(n2)-as.numeric(n1))/60
	min2 <- format(min, digits=4, decimal.mark=".")
	hours <- format(min/60, digits=3, decimal.mark=".")
	return(paste(min2,"minutes = ",hours,"hours"))
}

cumi_message <- function(msg) {
	#
	# print some nice, friendly message
	#
	# msg - text of the message to print
	#
	msg <- paste("--- CumI --- (now running for ", get_running_time(n1,Sys.time()),"): ",msg,sep="")
	cat(paste(" ",msg," "," ",sep="\n"))
	flush.console()
}
```

# The assessment

## Setup
Everything should be going on in the same coordinate system. So, we define this variable in order to be able to uniformly transform to this. It is the EPSG code for "ETRS89-extended / LAEA Europe" which is typically used by HELCOM for their maps. Further, we define here the list of years for which the assessment is done.

Then, a variable is set which determined whether this script uses some pre-calculated files which otherwise would need a huge amount of comupting time to assemble.

```{r}
cumi_message("setting up the assessment ...")
coordSystem <- 3035
```

We then define the assessment years to use:

```{r}
assessmentYears <- c("2016","2017","2018","2019","2020","2021")
```

As the processing of the clipLayer and the bottom trawling pressure take veeery looong (approx. 7 hours for bottom trawling on my machine and failing to report the percentage of finalization beyond the "10 %" value ...) even with the QGIS union procedure, a pre-calculated file is provided, based on the first part of the script up and including the processing of the bottom trawling. I.e., the pre-calculated layer already contains the biotope data combined with the bottom trawling data, and the pre-calculated layer already has the MOP from trawling included.

```{r}
# You can choose to either use the pre-calculated data (set `use_pre_calculated_data` to `TRUE`) for the further process, or re-calculate it here (set it to `FALSE`).
#
use_pre_calculated_data <- FALSE
```

The pressure maps that are produced by e.g. buffering or by intersecting intensity and frequency, are not stored by default. With the following setting you can let them be stored in a separate Geopackage file. Note: these layers are consequently not clipped to the biotope map as the CumI is when doing the assessment. Further note: setting `store_pressure_maps` to TRUE only gives the desired result for all layers when setting `use_pre_calculated_data` to FALSE at the same time:

```{r}
store_pressure_maps <- TRUE
```

Normally, you want the CuMI assessment to be done. But if you only want the pressure maps and not the actual CumI calculations (which will be much quicker in terms of processing time), i.e. not the overlay with biotoptes and sensitivity and the cumulation, then you can turn it off here:

```{r}
do_cumi <- FALSE
```

The data use the CumI categories "very low", "low", "moderate" and "high" for various steps. We put them into a vector here so we can use them later as an R 'factor':

```{r}
cumi_categories <- c("very low","low","moderate","high")
```


## The assessment area
The spatial extent of the assessment area is determined by the HELCOM Assessment Units. There are four (spatial) levels. Level 2 contains the outline of the complete assessment area of the Baltc See[^3] (called *marine area*), divided into 17 *subbasins*. This data set is used to clip all other layers if they contains parts that are outside of this boundary.

```{r}
if (! use_pre_calculated_data) {
	cumi_message("preparing assessment area layer ...")
	area_file <- file.path(myDir,"Base/HELCOM_subbasins_2022.shp")
	areaLayer <- st_read(area_file) %>% dplyr::select(-c(Area_km2,Shape_Leng,Shape_Le_1,Shape_Area)) %>% st_make_valid()
}
if (! do_cumi && store_pressure_maps) {
	# we want an alternative clip layer for the stored pressure maps if we are not using the combined biotope map.
	# Let us then use the assessment area:
	cumi_message("... making clipLayer for stored pressure maps ... st_union() ...")
	clipLayer <- areaLayer %>% st_cast("MULTIPOLYGON") %>% st_cast("POLYGON") %>% st_union()
}
```

To enable assigning data to specific countries, the assessment area is supplemented with country information. The countries are taken from the *EMODnet Human Activities* data file `Emodnet_HA_OtherManagementsAreas_EEZ_20180629`. As the spatial coverage of the country data sometimes is smaller than the coverage of the assessment area, the country area was extended manually on the terrestrial side so the complete assessment area is within a specific country.

```{r}
# TODO: update available: EMODnet_HA_OtherManagementAreas_EEZ_v11_20210506
# <https://www.emodnet-humanactivities.eu/search-results.php?dataname=Exclusive+Economic+Zone>
if (! use_pre_calculated_data && do_cumi) {
	cumi_message("loading and suplementing country information ...")
	country_file <- file.path(myDir,"Base/countries.shp")
	countryLayer <- st_read(country_file)
	areaCountryLayer <- st_intersection(areaLayer,countryLayer)
}
```


## The biotope map
The biotope map is based on the *EMODnet broad-scale seabed habitat map for Europe* (= EUSeapMap), dated September 2021.

### Biotope, country and assessment area data
In the first step, the original map for the Baltic Sea[^1] (dated September 2021) is used. As the Baltic part of the EUSeaMap does not include the Kattegat, part of the corresponding map for the European Atlantic and Arctic region[^2] is merged into the data (as long as it is within the assessment area). For convenience (as the Atlantic/Arctic data set is huge) a manually clipped version if the latter data set is used where anything roughly outside the Kattegat area has been removed.

```{r}
if (! use_pre_calculated_data && do_cumi) {
	cumi_message("starting with EMODnet biotopes ...")
	biotopeBaltic_file <- file.path(myDir,"Biotopes/EUSeaMap 2021 Baltic_Sea GDB/C20211007_EUSeaMap_2021_Baltic_Sea.gdb")
	biotopeBalticLayer <- st_read(biotopeBaltic_file, layer="EUSeaMap_2021_Baltic") %>%
		st_transform(coordSystem) %>%
		st_make_valid() %>%
		# only keep the BHT column:
		select(MSFD_BBHT) %>%
		# rename geometry column so it fits to the Kattegat layer below:
		rename_geometry("geom") %>%
		rename(Biotope = MSFD_BBHT)
	# the following file was produced from the original EMODnet geodatabase in QGIS (version 3.26.1) by
	# 1. converting it to geopackage
	# 2. buffering by 0 metres (thus repairing geomerty errors)
	# 3. manually dividing objects around the Kattegat boundary
	# 4. deleting all objects outside the Kattegat
	biotopeKattegat_file <- file.path(myDir,"Biotopes/EUSeaMap_2021_Kattegat-v2.gpkg")
	biotopeKattegatLayer <- st_read(biotopeKattegat_file, layer="EUSeaMap_2021_Kattegat") %>%
		st_transform(coordSystem) %>%
		st_cast("MULTIPOLYGON") %>%
		st_make_valid() %>%
		# onyl keep the BHT column and rename it to 'Biotope':
		select(MSFD_BBHT) %>%
		rename(Biotope = MSFD_BBHT)
	# now merge the Baltic with the Kattegat
	# (rbind is safe here as there is no spatial overlap and the attributes are the same):
	biotopeBalticLayer <- rbind(biotopeBalticLayer,biotopeKattegatLayer)
	# and add in the area and country information, essentially also clipping
	# everything away that is outside the assessment area:
	# (Note: this may also clip away parts of the assessment area when there is no biotope
	# information there, but as we cannot use those parts without biotope information anyway, this is ok)
	cumi_message("integrating area and country information ...")
	areaCountryBiotopeLayer <- st_intersection(biotopeBalticLayer,areaCountryLayer)
	# only retain the columns we need:
	areaCountryBiotopeLayer <- areaCountryBiotopeLayer %>%
		select(all_of(c("Biotope","level_2","HELCOM_ID","Territory")))
	# last step is to clean the resulting data:
	areaCountryBiotopeLayer <- areaCountryBiotopeLayer %>%
		filter(st_geometry_type(areaCountryBiotopeLayer) %in% c("POLYGON","MULTIPOLYGON")) %>%
		st_cast("MULTIPOLYGON")
}
```

### Species data
Some taxa inhabiting specific areas lead to a 'high' sensitivity towards the pressures in the later process. The spatial data for these taxa is taken from HELCOM MADS (Biodiversity > Ecosystem components (BSII) > Benthic species). The taxa are the genera *Mytilus, Zostera, Furcellaria, Fucus, Chara*. We include this information into the biotope map in a new column 'sens_spec':


```{r}
if (! use_pre_calculated_data && do_cumi) {
	cumi_message("including information on sensitive species ...")

	species_folder <- file.path(myDir,"Biotopes/Benthic species")

	# this new column will hold all the species information later:
	areaCountryBiotopeLayer <- areaCountryBiotopeLayer %>% mutate(sens_spec = 'none')

	for(myfile in c(
		"Chara_distribution.tif",
		"Fucus_distribution_2018.tif",
		"Furcellaria_distribution.tif",
		"Mytilus_distribution.tif",
		"Zostera_marina_distribution_2018.tif"
	)) {
		myShort <- substring(myfile,1,5)
		cumi_message(paste("... ", myfile, sep=""))
		mydata <- rast(file.path(species_folder,myfile))
		# convert to vector data:
		mydata_poly <- terra::as.polygons(mydata, dissolve=FALSE)
		# only cells with band1 = 1 have the species, so we discard the rest:
		names(mydata_poly)[1] <- "present"
		mydata_poly <- subset(mydata_poly,mydata_poly$present == 1)
		myName <- case_when(
			myShort == "Chara" ~ "Chara",
			myShort == "Fucus" ~ "Fucus",
			myShort == "Furce" ~ "Furcellaria",
			myShort == "Mytil" ~ "Mytilus",
			myShort == "Zoste" ~ "Zostera",
			TRUE ~ "undefined"
		)
		# for Zostera, ignore any vegetation below 10m depth:
		if (myShort == "Zoste") {
			depths <- rast(file.path(myDir,"Base/depth/w001001.adf"))
			tmp <- terra::extract(depths,mydata_poly, 'mean')
			sf_data <- cbind(mydata_poly,tmp) %>% st_as_sf() %>% filter(w001001 >= -10 | is.na(w001001))
		} else  {
			sf_data <- st_as_sf(mydata_poly)
		}
		# dissolve and add species information:
		sf_data <- sf_data %>% st_union() %>% st_as_sf() %>% st_cast("POLYGON") %>% mutate(spec = myName)
		# now include the data into the biotope map:
		areaCountryBiotopeLayer <- my_union(areaCountryBiotopeLayer,sf_data)
		areaCountryBiotopeLayer$sens_spec[! is.na(areaCountryBiotopeLayer$spec)] <- myName
		areaCountryBiotopeLayer <- areaCountryBiotopeLayer %>% select(-spec)
		# remove all features without biotope, they are outside the assessment area:
		areaCountryBiotopeLayer <- areaCountryBiotopeLayer %>% filter(! is.na(Biotope))
	}
}
```

Note, the name of the taxon in the column 'sens_spec' may have been overridden one or more times when the taxa distribution overlaps spatially. So, do not count on the name of the taxon being the only one responsible for the entry.

### Salinity data
Now, we have an initial biotope layer with the corresponding information on subbasin and country. The next step is to include data on the bottom salinity so we have all information needed to assign sensitivity values to the habitat. For this, we assign the bottom salinity from the HELCOM BALANCE project:

```{r}
if (! use_pre_calculated_data && do_cumi) {
		cumi_message("integrating salinity data ...")
	salinity_file <- file.path(myDir,"Salinity/BALANCE_BOTTOM_SALINITY.tif")
	salinityLayer <- rast(salinity_file)
	# convert to vector data:
	salinityLayer <- terra::as.polygons(salinityLayer, dissolve=TRUE)
	names(salinityLayer)[1] <- "category"
	salinityLayer <- st_as_sf(salinityLayer) %>% mutate(Sal = 'none') %>% mutate(Sal2 = 'none')
	
	for (i in 1:nrow(salinityLayer)) {
		cat <- salinityLayer$category[i]
		salinityLayer$Sal[i] <- case_when(
			cat == "1" ~ "Oligohaline I",
			cat == "2" ~ "Oligohaline II",
			cat == "3" ~ "Mesohaline I",
			cat == "4" ~ "Mesohaline II",
			cat == "5" ~ "Polyhaline",
			cat == "6" ~ "Euhaline"
		)
		salinityLayer$Sal2[i] <- case_when(
			cat == "1" ~ "< 5",
			cat == "2" ~ "5-7.5",
			cat == "3" ~ "7.5-11",
			cat == "4" ~ "11-18",
			cat == "5" ~ "18-30",
			cat == "6" ~ "> 30"
		)
	}
	
	salinityLayer <- select(salinityLayer,-category)
	
	# (this following is done with ArcGIS ... otherwise it takes too long:)
	areaCountryBiotopeSalinityLayer <- my_union(areaCountryBiotopeLayer,salinityLayer)
	# Now some cleaning:
	# 1. make sure it is valid
	# 2. delete all polygons without biotope assignment (these are the ones from the salinity layer that lie beyond the biotope map)
	# 3. only retain the attributes we want:
	areaCountryBiotopeSalinityLayer <- areaCountryBiotopeSalinityLayer %>%
		st_make_valid() %>%
		filter(! is.na(Biotope)) %>%
		select(-starts_with("FID")) %>%
		st_cast("MULTIPOLYGON")
}
```

There is a limitation in the salinity data set. It does not cover the entire assessment area. E.g., the "Limfjord", the innermost part of "Eckernförder Bucht" and the innermost part of the "Gulf of Finland" are without salinity assignment together with a number of smaller fjords. As can be seen from the code below, these areas will be tentatively be assigned a "moderate" sensitivity.

### Sensitivity assingment
In the following step, the sensitivities will be assigned based on the biotope, salinity and country information. The current values are a result of the agreed values in the CumI report dated 2021-09-07, supplemented by values used in the corresponding CumI assessment dated 2021-08-23 (CumI-assessment-2021-08-23T2157.gpkg; unfortunately, not all values used in the last CumI assessment were reported in the CumI report). In case of erroneous multiple assignments for the same biotope/salinity combination, the value covering the larger area in the last assessment was taken. Sensitivity values of country/biotope/salinity combinations not yet assigned but necessary due to the new biotope map and updated salinity map were preferably taken from the adjacent salinity class within the same countr/biotope combination and marked as `# assumed` in the following code. These should be reviewed by the member states.


```{r}
if (! use_pre_calculated_data && do_cumi) {
	cumi_message("assign sensitivities ...")
	tmp <- areaCountryBiotopeSalinityLayer
	
	# new columns 'sens' and 's_surf':
	tmp <- tmp %>% mutate(sens = 'none') %>% mutate(s_surf = 'none')
	
	# template for selection of value based on largest area (data from 'CumI-assessment-2021-08-23T2157.gpkg'):
	# select sum(area) as area, '"' || Territory || '", "' || Biotope || '", "' || Sal2 || '", "' || s_surf || '",'
	# as line from cumi
	# group by Biotope,s_surf,Sal2
	# order by Territory,biotope,Sal2
	#
	
	cumi_Sensitivities <- tribble(
		~Territory, ~Biotope,    ~Sal2,   ~sens,         ~s_surf,
		# --------------------------------------------------------
		"Denmark", "circa hard", "7.5-11", "high",        "high",
		"Denmark", "circa hard", "11-18",  "high",        "high",
		"Denmark", "circa hard", "18-30",  "high",        "high",
		"Denmark", "circa hard", "> 30",   "high",        "high", # both values assumed
		
		"Denmark", "circa mix", "7.5-11",  "high",        "low",
		"Denmark", "circa mix", "11-18",   "high",        "low",
		"Denmark", "circa mix", "18-30",   "high",        "low",
		"Denmark", "circa mix", "> 30",    "high",        "low",
		
		"Denmark", "circa mud", "7.5-11",  "moderate",    "moderate",
		"Denmark", "circa mud", "11-18",   "moderate",    "moderate",
		"Denmark", "circa mud", "18-30",   "moderate",    "high",
		"Denmark", "circa mud", "> 30",    "moderate",    "high",
		
		"Denmark", "circa sand", "7.5-11", "low",         "moderate",
		"Denmark", "circa sand", "11-18",  "low",         "moderate",
		"Denmark", "circa sand", "18-30",  "low",         "high",
		"Denmark", "circa sand", "> 30",   "low",          "high",
		
		"Denmark", "infra hard", "7.5-11", "high",        "high",
		"Denmark", "infra hard", "11-18",  "high",        "high",
		"Denmark", "infra hard", "18-30",  "high",        "high",
		"Denmark", "infra hard", "> 30",   "high",         "high",
		
		"Denmark", "infra mix", "7.5-11", "high",         "low",
		"Denmark", "infra mix", "11-18",  "high",         "low",
		"Denmark", "infra mix", "18-30",  "high",         "high",
		"Denmark", "infra mix", "> 30",   "high",         "high",
		
		"Denmark", "infra mud", "7.5-11", "moderate",     "moderate",
		"Denmark", "infra mud", "11-18",  "moderate",     "moderate",
		"Denmark", "infra mud", "18-30",  "moderate",     "high",
		"Denmark", "infra mud", "> 30",   "moderate",     "high",
		
		"Denmark", "infra sand", "7.5-11", "low",         "moderate",
		"Denmark", "infra sand", "11-18",  "low",         "moderate", # s_surf assumed
		"Denmark", "infra sand", "18-30",  "low",         "high",
		"Denmark", "infra sand", "> 30",   "low",         "high",
		# --------------------------------------------------------
		"Estonia", "circa hard", "5-7.5",  "high",        "high",
		"Estonia", "circa hard", "7.5-11", "high",        "high",
		
		"Estonia", "circa mix", "5-7.5",  "moderate",     "high",
		"Estonia", "circa mix", "7.5-11", "moderate",     "low",
		
		"Estonia", "circa mud", "5-7.5",  "moderate",     "moderate",
		"Estonia", "circa mud", "7.5-11", "moderate",     "moderate",
		
		"Estonia", "circa sand", "5-7.5",  "moderate",    "moderate",
		"Estonia", "circa sand", "7.5-11", "moderate",    "moderate",
		
		"Estonia", "infra hard", "5-7.5",  "high",        "high",
		"Estonia", "infra hard", "7.5-11", "high",        "high",
		
		"Estonia", "infra mix", "5-7.5",  "moderate",     "moderate", # s_surf assumed
		"Estonia", "infra mix", "7.5-11", "moderate",     "moderate", # s_surf assumed
		
		"Estonia", "infra mud", "5-7.5",  "moderate",     "moderate",
		"Estonia", "infra mud", "7.5-11", "moderate",     "moderate",
		
		"Estonia", "infra sand", "5-7.5",  "moderate",    "moderate",
		"Estonia", "infra sand", "7.5-11", "moderate",    "moderate",
		# --------------------------------------------------------
		"Finland", "circa hard", "< 5",    "high",        "high",
		"Finland", "circa hard", "5-7.5",  "high",        "high",
		"Finland", "circa hard", "7.5-11", "high",        "high", # s_surf assumed
		
		"Finland", "circa mix", "< 5",    "moderate",     "moderate",
		"Finland", "circa mix", "5-7.5",  "moderate",     "moderate",
		"Finland", "circa mix", "7.5-11", "moderate",     "moderate",
		
		"Finland", "circa mud", "< 5",    "moderate",     "moderate",
		"Finland", "circa mud", "5-7.5",  "moderate",     "moderate",
		"Finland", "circa mud", "7.5-11", "moderate",     "moderate",
		
		"Finland", "circa sand", "< 5",    "moderate",    "moderate",
		"Finland", "circa sand", "5-7.5",  "moderate",    "moderate",
		"Finland", "circa sand", "7.5-11", "moderate",    "moderate", # s_surf assumed
		
		"Finland", "infra hard", "< 5",    "high",        "high",
		"Finland", "infra hard", "5-7.5",  "high",        "high",
		"Finland", "infra hard", "7.5-11", "high",        "high", # s_surf assumed
	
		"Finland", "infra mix", "< 5",    "moderate",     "moderate",
		"Finland", "infra mix", "5-7.5",  "moderate",     "moderate",
		"Finland", "infra mix", "7.5-11", "moderate",     "moderate", # s_surf assumed
		
		"Finland", "infra mud", "< 5",    "moderate",     "moderate",
		"Finland", "infra mud", "5-7.5",  "moderate",     "moderate",
		"Finland", "infra mud", "7.5-11", "moderate",     "moderate",
		
		"Finland", "infra sand", "< 5",    "moderate",    "moderate",
		"Finland", "infra sand", "5-7.5",  "moderate",    "moderate",
		"Finland", "infra sand", "7.5-11", "moderate",    "moderate", # s_surf assumed
		# --------------------------------------------------------
		"Germany", "circa hard", "5-7.5",  "high",        "high",
		"Germany", "circa hard", "7.5-11", "high",        "high",
		"Germany", "circa hard", "11-18",  "high",        "high",
		"Germany", "circa hard", "18-30",  "high",        "high",
		
		"Germany", "circa mix", "5-7.5",  "moderate",     "low", # s_surf assumed
		"Germany", "circa mix", "7.5-11", "moderate",     "low",
		"Germany", "circa mix", "11-18",  "moderate",     "high",
		"Germany", "circa mix", "18-30",  "moderate",     "high",
		
		"Germany", "circa mud", "5-7.5",  "moderate",     "moderate", # s_surf assumed
		"Germany", "circa mud", "7.5-11", "moderate",     "moderate",
		"Germany", "circa mud", "11-18",  "moderate",     "high",
		"Germany", "circa mud", "18-30",  "moderate",     "high",
		
		"Germany", "circa sand", "5-7.5",  "moderate",    "moderate",
		"Germany", "circa sand", "7.5-11", "moderate",    "moderate",
		"Germany", "circa sand", "11-18",  "moderate",    "moderate",
		"Germany", "circa sand", "18-30",  "moderate",    "moderate",
		
		"Germany", "infra hard", "5-7.5",  "high",        "high",
		"Germany", "infra hard", "7.5-11", "high",        "high",
		"Germany", "infra hard", "11-18",  "high",        "high",
		"Germany", "infra hard", "18-30",  "high",        "high",
		
		"Germany", "infra mix", "5-7.5",  "moderate",     "moderate",
		"Germany", "infra mix", "7.5-11", "moderate",     "low",
		"Germany", "infra mix", "11-18",  "moderate",     "low",
		"Germany", "infra mix", "18-30",  "moderate",     "high",
		
		"Germany", "infra mud", "5-7.5",  "moderate",     "moderate",
		"Germany", "infra mud", "7.5-11", "moderate",     "moderate",
		"Germany", "infra mud", "11-18",  "moderate",     "moderate",
		"Germany", "infra mud", "18-30",  "moderate",     "high",
		
		"Germany", "infra sand", "5-7.5",  "moderate",    "moderate",
		"Germany", "infra sand", "7.5-11", "moderate",    "moderate",
		"Germany", "infra sand", "11-18",  "moderate",    "high",
		"Germany", "infra sand", "18-30",  "moderate",    "high",
		# --------------------------------------------------------
		"Latvia", "circa hard", "< 5",    "high",         "high", # both values assumed
		"Latvia", "circa hard", "5-7.5",  "high",         "high",
		"Latvia", "circa hard", "7.5-11", "high",         "high",
		"Latvia", "circa hard", "11-18",  "high",         "high", # s_surf assumed
		
		"Latvia", "circa mix", "5-7.5",  "moderate",      "low",
		"Latvia", "circa mix", "7.5-11", "moderate",      "low",
		"Latvia", "circa mix", "11-18",  "moderate",      "low",
		
		"Latvia", "circa mud", "< 5",    "moderate",      "moderate",
		"Latvia", "circa mud", "5-7.5",  "moderate",      "moderate",
		"Latvia", "circa mud", "7.5-11", "moderate",      "moderate",
		"Latvia", "circa mud", "11-18",  "moderate",      "moderate",
		
		"Latvia", "circa sand", "< 5",    "moderate",     "moderate",
		"Latvia", "circa sand", "5-7.5",  "moderate",     "moderate",
		"Latvia", "circa sand", "7.5-11", "moderate",     "moderate",
		"Latvia", "circa sand", "11-18",  "moderate",     "moderate", # s_surf assumed
		
		"Latvia", "infra hard", "< 5",    "high",         "high",
		"Latvia", "infra hard", "5-7.5",  "high",         "high",
		"Latvia", "infra hard", "7.5-11", "high",         "high", # s_surf assumed
		"Latvia", "infra hard", "11-18",  "high",         "high", # s_surf assumed
		
		"Latvia", "infra mix", "< 5",    "moderate",      "moderate", # s_surf assumed
		"Latvia", "infra mix", "5-7.5",  "moderate",      "moderate",
		"Latvia", "infra mix", "7.5-11", "moderate",      "moderate", # s_surf assumed
		"Latvia", "infra mix", "11-18",  "moderate",      "moderate", # s_surf assumed
		
		"Latvia", "infra mud", "< 5",    "moderate",      "moderate",
		"Latvia", "infra mud", "5-7.5",  "moderate",      "moderate",
		"Latvia", "infra mud", "7.5-11", "moderate",      "moderate",
		"Latvia", "infra mud", "11-18",  "moderate",      "moderate", # s_surf assumed
		
		"Latvia", "infra sand", "< 5",    "moderate",     "moderate",
		"Latvia", "infra sand", "5-7.5",  "moderate",     "moderate",
		"Latvia", "infra sand", "7.5-11", "moderate",     "moderate", # s_surf assumed
		"Latvia", "infra sand", "11-18",  "moderate",     "moderate", # s_surf assumed
		# --------------------------------------------------------
		"Lithuania", "circa hard", "5-7.5",  "high",      "high",
		"Lithuania", "circa hard", "7.5-11", "high",      "high",
		
		"Lithuania", "circa mix", "5-7.5",  "moderate",   "low",
		"Lithuania", "circa mix", "7.5-11", "moderate",   "low",
		"Lithuania", "circa mix", "11-18",  "moderate",   "low", # s_surf assumed
		
		"Lithuania", "circa mud", "5-7.5",  "moderate",   "moderate",
		"Lithuania", "circa mud", "7.5-11", "moderate",   "moderate",
		
		"Lithuania", "circa sand", "< 5",    "moderate",  "moderate", # s_surf assumed
		"Lithuania", "circa sand", "5-7.5",  "moderate",  "moderate",
		"Lithuania", "circa sand", "7.5-11", "moderate",  "moderate",
		
		"Lithuania", "infra hard", "< 5",    "high",      "high", # both assumed (sens and s_surf)
		"Lithuania", "infra hard", "5-7.5",  "high",      "high", # both assumed
		"Lithuania", "infra hard", "7.5-11", "high",      "high", # both assumed
		
		"Lithuania", "infra mix", "5-7.5",  "moderate",   "moderate",
		"Lithuania", "infra mix", "7.5-11", "moderate",   "moderate", # s_surf assumed
		
		"Lithuania", "infra mud", "5-7.5", "moderate",   "moderate",
		"Lithuania", "infra mud", "7.5-11", "moderate",   "moderate", # s_surf assumed
		
		"Lithuania", "infra sand", "5-7.5",  "moderate",  "moderate",
		"Lithuania", "infra sand", "7.5-11", "moderate",  "moderate", # s_surf assumed
		# --------------------------------------------------------
		"Poland", "circa hard", "5-7.5",  "high",         "high",
		"Poland", "circa hard", "7.5-11", "high",         "high",
		"Poland", "circa hard", "11-18",  "high",         "high", # s_surf assumed
		
		"Poland", "circa mix", "5-7.5",  "moderate",      "moderate", # s_surf assumed
		"Poland", "circa mix", "7.5-11", "moderate",      "moderate",
		"Poland", "circa mix", "11-18",  "moderate",      "moderate", # s_surf assumed
		
		"Poland", "circa mud", "< 5",    "moderate",      "moderate", # both values assumed
		"Poland", "circa mud", "5-7.5",  "moderate",      "moderate",
		"Poland", "circa mud", "7.5-11", "moderate",      "moderate",
		"Poland", "circa mud", "11-18",  "moderate",      "moderate",
		
		"Poland", "circa sand", "< 5",    "moderate",     "moderate", # both values assumed
		"Poland", "circa sand", "5-7.5",  "moderate",     "moderate",
		"Poland", "circa sand", "7.5-11", "moderate",     "moderate",
		"Poland", "circa sand", "11-18",  "moderate",     "moderate",
		
		"Poland", "infra hard", "5-7.5",  "high",         "high",
		"Poland", "infra hard", "7.5-11", "high",         "high",
		"Poland", "infra hard", "11-18",  "high",         "high",

		"Poland", "infra mix", "< 5",    "moderate",      "moderate", # sens assumed
		"Poland", "infra mix", "5-7.5",  "moderate",      "moderate",
		"Poland", "infra mix", "7.5-11", "moderate",      "moderate",
		
		"Poland", "infra mud", "< 5",    "moderate",      "moderate", # sens assumed
		"Poland", "infra mud", "5-7.5",  "moderate",      "moderate",
		"Poland", "infra mud", "7.5-11", "moderate",      "moderate",
		"Poland", "infra mud", "11-18",  "moderate",      "moderate",
		
		"Poland", "infra sand", "< 5",    "moderate",     "moderate", # sens assumed
		"Poland", "infra sand", "5-7.5",  "moderate",     "moderate",
		"Poland", "infra sand", "7.5-11", "moderate",     "moderate",
		"Poland", "infra sand", "11-18",  "moderate",     "moderate", # s_surf assumed
		# --------------------------------------------------------
		"Russia", "circa hard", "< 5",    "moderate",     "moderate", # both values assumed
		"Russia", "circa hard", "5-7.5",  "moderate",     "moderate", # both values assumed
		"Russia", "circa hard", "7.5-11", "moderate",     "moderate", # both values assumed
		"Russia", "circa hard", "11-18",  "moderate",     "moderate", # both values assumed
		
		"Russia", "circa mix", "< 5",    "moderate",      "moderate", # both values assumed
		"Russia", "circa mix", "5-7.5",  "moderate",      "moderate",
		"Russia", "circa mix", "7.5-11", "moderate",      "moderate", # both values assumed
		"Russia", "circa mix", "11-18",  "moderate",      "moderate", # both values assumed
		
		"Russia", "circa mud", "< 5",    "moderate",      "moderate", # both values assumed
		"Russia", "circa mud", "5-7.5",  "moderate",      "moderate", # both values assumed
		"Russia", "circa mud", "7.5-11", "moderate",      "moderate", # both values assumed
		"Russia", "circa mud", "11-18",  "moderate",      "moderate", # both values assumed
		
		"Russia", "circa sand", "< 5",    "moderate",     "moderate", # both values assumed
		"Russia", "circa sand", "5-7.5",  "moderate",     "moderate", # both values assumed
		"Russia", "circa sand", "7.5-11", "moderate",     "moderate", # both values assumed
		"Russia", "circa sand", "11-18",  "moderate",     "moderate", # both values assumed
		
		"Russia", "infra hard", "< 5",    "moderate",     "moderate", # both values assumed
		"Russia", "infra hard", "5-7.5",  "moderate",     "moderate", # both values assumed
		"Russia", "infra hard", "7.5-11", "moderate",     "moderate", # both values assumed
		"Russia", "infra hard", "11-18",  "moderate",     "moderate", # both values assumed
		
		"Russia", "infra mix", "< 5",    "moderate",      "moderate", # both values assumed
		"Russia", "infra mix", "5-7.5",  "moderate",      "moderate", # both values assumed
		"Russia", "infra mix", "7.5-11", "moderate",      "moderate", # both values assumed
		"Russia", "infra mix", "11-18",  "moderate",      "moderate", # both values assumed
		
		"Russia", "infra mud", "< 5",    "moderate",      "moderate", # both values assumed
		"Russia", "infra mud", "5-7.5",  "moderate",      "moderate", # both values assumed
		"Russia", "infra mud", "7.5-11", "moderate",      "moderate", # both values assumed
		"Russia", "infra mud", "11-18",  "moderate",      "moderate", # both values assumed
		
		"Russia", "infra sand", "< 5",    "moderate",     "moderate", # both values assumed
		"Russia", "infra sand", "5-7.5",  "moderate",     "moderate", # both values assumed
		"Russia", "infra sand", "7.5-11", "moderate",     "moderate", # both values assumed
		"Russia", "infra sand", "11-18",  "moderate",     "moderate", # both values assumed
		# --------------------------------------------------------
		"Sweden", "circa hard", "< 5",    "high",         "low",
		"Sweden", "circa hard", "5-7.5",  "high",         "high",
		"Sweden", "circa hard", "7.5-11", "high",         "high",
		"Sweden", "circa hard", "11-18",  "high",         "high",
		"Sweden", "circa hard", "18-30",  "high",         "high",
		"Sweden", "circa hard", "> 30",   "high",         "high",
		
		"Sweden", "circa mix", "< 5",    "moderate",      "low",
		"Sweden", "circa mix", "5-7.5",  "moderate",      "low",
		"Sweden", "circa mix", "7.5-11", "moderate",      "moderate",
		"Sweden", "circa mix", "11-18",  "moderate",      "moderate",
		"Sweden", "circa mix", "18-30",  "moderate",      "high",
		"Sweden", "circa mix", "> 30",   "moderate",      "moderate",
		
		"Sweden", "circa mud", "< 5",    "moderate",      "low",
		"Sweden", "circa mud", "5-7.5",  "moderate",      "moderate",
		"Sweden", "circa mud", "7.5-11", "moderate",      "moderate",
		"Sweden", "circa mud", "11-18",  "moderate",      "moderate",
		"Sweden", "circa mud", "18-30",  "moderate",      "high",
		"Sweden", "circa mud", "> 30",   "moderate",      "high",
		
		"Sweden", "circa sand", "< 5",    "moderate",     "low",
		"Sweden", "circa sand", "5-7.5",  "moderate",     "moderate",
		"Sweden", "circa sand", "7.5-11", "moderate",     "moderate",
		"Sweden", "circa sand", "11-18",  "moderate",     "moderate",
		"Sweden", "circa sand", "18-30",  "moderate",     "high",
		"Sweden", "circa sand", "> 30",   "moderate",     "high",
		
		"Sweden", "infra hard", "< 5",    "high",         "low",
		"Sweden", "infra hard", "5-7.5",  "high",         "moderate",
		"Sweden", "infra hard", "7.5-11", "high",         "high",
		"Sweden", "infra hard", "11-18",  "high",         "high",
		"Sweden", "infra hard", "18-30",  "high",         "high",
		"Sweden", "infra hard", "> 30",   "high",         "high",
		
		"Sweden", "infra mix", "< 5",    "moderate",      "low",
		"Sweden", "infra mix", "5-7.5",  "moderate",      "moderate",
		"Sweden", "infra mix", "7.5-11", "moderate",      "moderate",
		"Sweden", "infra mix", "11-18",  "moderate",      "high",
		"Sweden", "infra mix", "18-30",  "moderate",      "high",
		"Sweden", "infra mix", "> 30",   "moderate",      "high",
		
		"Sweden", "infra mud", "< 5",    "moderate",      "low",
		"Sweden", "infra mud", "5-7.5",  "moderate",      "moderate",
		"Sweden", "infra mud", "7.5-11", "moderate",      "moderate",
		"Sweden", "infra mud", "11-18",  "moderate",      "high",
		"Sweden", "infra mud", "18-30",  "moderate",      "high",
		"Sweden", "infra mud", "> 30",   "moderate",      "high",
		
		"Sweden", "infra sand", "< 5",    "moderate",     "low",
		"Sweden", "infra sand", "5-7.5",  "moderate",     "moderate",
		"Sweden", "infra sand", "7.5-11", "moderate",     "moderate",
		"Sweden", "infra sand", "11-18",  "moderate",     "moderate",
		"Sweden", "infra sand", "18-30",  "moderate",     "moderate", # s_surf assumed
		"Sweden", "infra sand", "> 30",   "moderate",     "high"
	)                                                           
	
	# counter for missing sensitivity assignments:
	missCount <- 0
	missData <- c()
	
	for(i in 1:nrow(tmp)) {
		terr       <- tmp[[i, "Territory"]]
		bio        <- tmp[[i, "Biotope"]]
		sal        <- tmp[[i, "Sal2"]]
		sensi      <- tmp[[i, "sens_spec"]]
		#
		# - translate short names to MSFD long names
		# - use "infra/circa hard" biotopes for MSFD coarse sediments and rock/reef
		# - use "circa" biotopes for MSFD offshore
		#
		shortName <- case_when(
			bio == "Circalittoral rock and biogenic reef" ~ "circa hard",
			bio == "Circalittoral coarse sediment" ~ "circa hard",
			bio == "Circalittoral mixed sediment" ~ "circa mix",
			bio == "Circalittoral mud" ~ "circa mud",
			bio == "Circalittoral sand" ~ "circa sand",
			bio == "Circalittoral mud or Circalittoral sand" ~ "???",
			
			bio == "Infralittoral rock and biogenic reef" ~ "infra hard",
			bio == "Infralittoral coarse sediment" ~ "infra hard",
			bio == "Infralittoral mixed sediment" ~ "infra mix",
			bio == "Infralittoral mud" ~ "infra mud",
			bio == "Infralittoral sand" ~ "infra sand",
			bio == "Infralittoral mud or Infralittoral sand" ~ "???",
			
			bio == "Offshore circalittoral coarse sediment" ~ "circa hard",
			bio == "Offshore circalittoral mixed sediment" ~ "circa mix",
			bio == "Offshore circalittoral mud" ~ "circa mud",
			bio == "Offshore circalittoral mud or Offshore circalittoral sand" ~ "???",
			bio == "Offshore circalittoral rock and biogenic reef" ~ "circa hard",
			bio == "Offshore circalittoral sand" ~ "circa sand",
			
			TRUE ~ "other"
		)
		
		if (sensi %in% c("Chara","Fucus","Furcellaria","Mytilus","Zostera")) {
			# use high sensitivity:
			tmp$sens[i] <- "high"
			tmp$s_surf[i] <- "high"
		} else {
			if (bio == "Na" | is.na(sal)) {
				# when sensitivity cannot be determine due to lack of data, use "moderate":
				tmp$sens[i] <- "moderate"
				tmp$s_surf[i] <- "moderate"
			} else if (shortName == "???") {
				# if the biotope is either of two possibilities,
				# precautionarily take the one leading to higher sensitivity:
				zone <- substr(str_to_lower(word(bio,1)),1,5)
				if (zone == "offsh") {zone <- "circa"}
				s1a <- subset(cumi_Sensitivities, Territory==terr & Biotope == paste(zone,"mud",sep=" ") & Sal2 == sal)$sens
				if (rlang::is_empty(s1a)) {
					missData <- union(missData,paste(terr,bio,"(",shortName,")",sal,sep=" "))
					s1a <- ""
					missCount <- missCount + 1
				}
				s1b <- subset(cumi_Sensitivities, Territory==terr & Biotope == paste(zone,"sand",sep=" ") & Sal2 == sal)$sens
				if (rlang::is_empty(s1b)) {
					missData <- union(missData,paste(terr,bio,"(",shortName,")",sal,sep=" "))
					s1b <- ""
					missCount <- missCount + 1
				}
				s1 <- c(s1a,s1b)
				s1factor <- factor(s1, levels = cumi_categories, ordered = TRUE)
				s1max <- as.character(max(s1factor))
				tmp$sens[i] <- s1max
				#
				s2a <- subset(cumi_Sensitivities, Territory==terr & Biotope == paste(zone,"mud",sep=" ") & Sal2 == sal)$s_surf
				if (rlang::is_empty(s2a)) {
					missData <- union(missData,paste(terr,bio,"(",shortName,")",sal,sep=" "))
					s2a <- ""
					missCount <- missCount + 1
				}
				s2b <- subset(cumi_Sensitivities, Territory==terr & Biotope == paste(zone,"sand",sep=" ") & Sal2 == sal)$s_surf
				if (rlang::is_empty(s2b)) {
					missData <- union(missData,paste(terr,bio,"(",shortName,")",sal,sep=" "))
					s2b <- ""
					missCount <- missCount + 1
				}
				s2 <- c(s2a,s2b)
				s2factor <- factor(s2, levels = cumi_categories, ordered = TRUE)
				s2max <- as.character(max(s2factor))
				tmp$s_surf[i] <- s2max
			} else {
				# standard case:
				sA <- subset(cumi_Sensitivities, Territory==terr & Biotope == shortName & Sal2 == sal)$sens
				if (rlang::is_empty(sA)) {
					missData <- union(missData,paste(terr,bio,"(",shortName,")",sal,sep=" "))
					sA <- ""
					missCount <- missCount + 1
				}
				tmp$sens[i] <- sA
				#
				sB <- subset(cumi_Sensitivities, Territory==terr & Biotope == shortName & Sal2 == sal)$s_surf
				if (rlang::is_empty(sB)) {
					missData <- union(missData,paste(terr,bio,"(",shortName,")",sal,sep=" "))
					sB <- ""
					missCount <- missCount + 1
				}
				tmp$s_surf[i] <- sB
			}
		}
	}
	
	if (missCount > 0) {
		cat("Missing sensitivity information for:",missData,sep="\n")
		cumi_message(paste("STOPPING here due to",missCount,"missing sensitivities!",sep=" "))
		stop("CumI script ends here.")
	}
	
	# this file is a mix of polygon and multipolygon, so we cast everything to multipolygon first,
	# in order to prevent errors in later spatial operations
	biotopeLayer <- tmp %>% st_cast("MULTIPOLYGON") %>% st_make_valid()
	# as a last step write the layer to a file:
	st_write(biotopeLayer,file.path(myDir,"Biotopes/biotopes-pre_calculated.gpkg"))
}
```


The (pre-calculated) biotope layer now has these attribute columns:

- Biotope = HELCOM broadscale habitat
- sens = general pressure-independant sensitivity
- s_surf = sensitivity against surface abrasion due to bottom trawling
- sens_spec = whether the sensitivity was raised to 'high' due to sensitive species
- level_2 = HELCOM subbasins
- HELCOM_ID = the ID of the HELCOM subbasin
- Territory = country name
- Sal = bottom salinity class
- Sal2 = bottom salinity value range

```{r}
if (use_pre_calculated_data && do_cumi) {
	cumi_message("loading biotope layer ...")
	biotope_file <- file.path(myDir,"Biotopes/biotopes-pre_calculated.gpkg")
	biotopeLayer <- st_read(biotope_file)
}
```


All pressure layers will be clipped at the outline of the biotope map, making the pressure layers lie completely within the biotope coverage (and not e.g. on land). For this, we build a clip layer from the biotope layer:

```{r}
if (! use_pre_calculated_data && do_cumi) {
	cumi_message("... making clipLayer ... st_union() ...")
	clipLayer <- dplyr::select(biotopeLayer,-c(Biotope,sens,s_surf,sens_spec)) %>% st_cast("MULTIPOLYGON") %>% st_cast("POLYGON") %>% st_union()
}
```

Note: this only applies when doing an actual CumI calculation. When the script is set up to only produce pressure maps and not doing a CumI calculation, the pressure data will be clipped by the original assessment area layer.

If the pressure maps are to be stored, we here set up the file for storain the MOP layers:

```{r}
if (store_pressure_maps) {
	pressure_maps_file <- file.path(myDir,paste("Results/CumI-pressure-maps-",format(Sys.time(),"%Y-%m-%dT%H%M"),".gpkg",sep= ""))
}
```

## Pressure data and impact calculation
The initial impact map is just the biotope layer. This impact map gets combined (in principle via a GIS union operation) with each processed pressure layer. With each new pressure, one new column is added named 'impact_nx' where n is a number corresponding to the pressure numbers/identifiers in the following secions and x is either 'A' or 'B' or subsequent characters of the alphabet denoting some partial layer of the pressure or it is missing for those pressures which are not divided into multiple pressure layers.

The assessment period of the test runs was 2011–2016, the period for the current HOLAS III assessment done here is 2016–2021:

```{r}
if (! use_pre_calculated_data && do_cumi) {
	cumi_message("preparing impact layer ...")
	# initial impact layer is just the biotope map:
	impact_map <- biotopeLayer
}
```

The pressure data used here were provided by HELCOM as a result of a data call to the contracting parties. The following list is the description that followed the data package sent out to CumI lead by 2022-07-01:

Cables
: HOLAS 3 data for DK, FI and PL. Data reported as not available for LV and LT. HOLAS 2 data use requested by EE and SE (flaged in the Notes). Complementation with HOLAS 2 data for RU, LV, LT (flaged in the Notes). Data still pending from CPs.

Coastal defence and flood protection (under construction)
: HOLAS 3 data for DE, DK, FI, PL, SE. Data reported as not available for LV and LT. HOLAS 2 data use requested by EE (flaged in the Notes). Complementation with HOLAS 2 data for PL (flaged in the Notes). Please, observe that all 'Status' classifications from data providers were included.

Deposit of dredged material (points and areas)
: Includes a data extract of the database for the years 2016-2020. In the zip package there is one additional shapefile for depositing areas where the data is cross tabulated to have amount as columns. If the more detailed info on e.g. Material or capital/maintenance is needed, this is found in the database extract. Corrections and complementations from the revision still pending.

Dredging (maintenance, points and areas)
: Includes a data extract of the database for the years 2016-2020 and the data submitted for the data call. Data from CPs and corrections from revision still pending. One zip file contains an extract of the original data for maintanance dredging and the other zip file contains the merged 500m buffer from the extract.

Extraction of sand and gravel
: HOLAS 3 data for FI, EE and DE. Data reported as not available for LT. Data still pending from CPs. One zip file contains an extract of the original data and the other zip file contains the merged 500m buffer from the extract. There is also an excel table with reported data by Poland.

Finfish mariculture
: PLC data.

Fishing intensity 2011-2016 average
: Data still pending, to be delivered soon.

Furcellaria harvesting
: Statistical data from EUROSTAT. Spatial data extracted from HOLAS 2 and possible updates confirmed with the country.

Pipelines
: HOLAS 3 data for DK, EE, FI, PL. Data reported as not available for LV and LT. HOLAS 2 data use requested by SE (flaged in the Notes). Data complemented with HOLAS 2 data for RU (flaged in the Notes). Data still pending from CPs.

Recreational boating and sports
: Recreational boating and sports layer from HOLAS 2.

Shellfish mariculture
: Data from EMODnet.

Shipping density
: Raster for all ship types for the years 2006-2020. The raster should be rescaled with depth, if we are to follow the holas2 methodology. The raster for rescaling can be found in the same data package. There are 2 rasters: one for the average depth per 1x1 km grid cell, and another one that can be directly used to multiply the raster (s) one decides to use. The rescaling follows the following values 0-10 m= 1 (100%); 10-15 m= 0,5 (50%); 15-20 m= 0,25 (25%); 20-25 m= 0,1 (10%); 25m < = 0 (0%). In the second raster these values are 1; 0,5; 0,25; 0,1 and 0.

Wind farms (under construction)
: No Status falling 'under construction' received for now in HOLAS 3 data call. Data still pending from CPs.

Wind farms (operational)
: HOLAS 3 data for DK and FI. Data reported as not available for PL and LT. HOLAS 2 data use requested by SE (flaged in the Notes). Data reported as not relevant for LV and EE. Data still pending from CPs.

### 1. Bottom trawling fishery

```{r}
cumi_message("processing trawling fishery ...")
```

The fishery data were provided by ICES. This version of the script uses a preprocessed version of these raw data, where:

1. the raw SAR data have been smoothed from c-squares into a 1x1 km grid using a mean SAR value per 1x1 km grid cell weighted by the area of the involved c-squares
2. the MOP has been calculated (column 'MOP_1'; see script below)
3. the data have been combined with the above pre-calculated biotope map

*The next version of the script will also contain the necessary steps in R to make the preprocessing.*

The SAR values are treated directly as intensity and frequency is ignored, thus the SAR values are directly translated to MOP categories.

The confidence is rated as 'd3t3s1' for all countries except Russia which is rated 'd0t0s0' due to missing data:

- data quality is rated 3 as values are based on reported measurements
- temporal coverage is rated 3 (no year missing)
- spatial coverage is rated 0 for Russia (assumed from how the data look like) and 1 otherwise

```{r}
if (use_pre_calculated_data) {
	cumi_message("... using pre_calculated data ...")

	fishing_file_pre <- file.path(myDir,"Fishery/fishery_pre_calculated.gpkg")
	if (! file.exists(fishing_file_pre)) {
		cumi_message("... cannot find file with pre_processed data - skipping bottom trawling fishery ...")
	} else {
		impact_map <- st_read(fishing_file_pre)
	}
} else {
	cumi_message("... prepare to calculate fishery impact ...")
	# the following file `file.path(myDir,"Fishery/fishery_surface.shp")` contains
	# the raw data before aggregation as compiled from the individual ICES data files
	fishing_file <- file.path(myDir,"Fishery/fishery_surface.shp")
	if (do_cumi) {
	  cumi_message("... intersection with clipLayer ...")
	  fishing_x <- st_read(fishing_file) %>% st_intersection(clipLayer)
	} else {
	  fishing_x <- st_read(fishing_file)
	}
	
	# SARmode <- "quarters"
	SARmode <- "years"
	fishingQuarters <- c("1","2","3","4")
	makeAvg <- function(myLayer,myString) {
		q <- quote(mutate(myLayer,sar_avg = myString))
		eval(parse(text=sub("myString", myString, deparse(q))))
	}
	if (SARmode == "quarters") {
		# treat each quarterly SAR value as a properly scaled value:
		cumi_message("... calculating MOP from SAR values based ony quarterly values ...")
		# columns for SAR values:
		fishingSARcolumns <- c()
		for(myYear in assessmentYears) {
			for(myQuarter in fishingQuarters) {
				fishingSARcolumns <- c(fishingSARcolumns,paste("F",myYear,"_",myQuarter,sep=""))
			}
		}
		# expression to calculate the average SAR:
		sum <- paste(fishingSARcolumns,collapse='+')
		avgSAR <- paste("(", sum, ")/",length(fishingSARcolumns))
		# treat quarterly SAR values lower than 0.05 as zero intensity:
		for (myColumn in fishingSARcolumns) {
			fishing_x[[myColumn]] <- ifelse( fishing_x[[myColumn]]>=0.05, fishing_x[[myColumn]] , 0 )
		}
	}
	if (SARmode == "yearly") {
		# treat the quarterly SAR values as not scaled properly, so we need to add the quarterly values per year
		# and the go on with calculating on the yearly values
		# if they exceed or are equal to 0.05:
		cumi_message("... calculating MOP from SAR values based ony yearly values recalculated from quarterly values ...")
	  makeSum <- function(myLayer,myString,myYear) {
		  #q <- quote(mutate(myLayer,paste("sar_",myYear," = ",myString,sep="")))
		  #eval(parse(text=print(myString)))
	    var <- paste0("sar_",myYear)
	    mutate(myLayer, !!sym(var) := eval(parse(text="print(myString)")))
		}
	  fishingYearSARcolumns <- c()
	  for(myYear in assessmentYears) {
			fishingYearSARcolumns <- c(fishingYearSARcolumns,paste("sar_",myYear,sep=""))
	    fishingQuarterlySARcolumns <- c()
		  for(myQuarter in fishingQuarters) {
				fishingQuarterlySARcolumns <- c(fishingQuarterlySARcolumns,paste("F",myYear,"_",myQuarter,sep=""))
		  }
			yearlySum <- paste(fishingQuarterlySARcolumns,collapse='+')
			## doesn't work ... ####fishing_x <- makeSum(fishing_x,yearlySum,myYear)
	  }
	  # ok, then let's hardcode this then ...
	  fishing_x <- mutate(fishing_x,sar_2016 = F2016_1+F2016_2+F2016_3+F2016_4)
	  fishing_x <- mutate(fishing_x,sar_2017 = F2017_1+F2017_2+F2017_3+F2017_4)
    fishing_x <- mutate(fishing_x,sar_2018 = F2018_1+F2018_2+F2018_3+F2018_4)
	  fishing_x <- mutate(fishing_x,sar_2019 = F2019_1+F2019_2+F2019_3+F2019_4)
	  fishing_x <- mutate(fishing_x,sar_2020 = F2020_1+F2020_2+F2020_3+F2020_4)
	  fishing_x <- mutate(fishing_x,sar_2021 = F2021_1+F2021_2+F2021_3+F2021_4)
	  # treat yearly SAR values lower than 0.05 as zero intensity:
		for (myColumn in fishingYearSARcolumns) {
			fishing_x[[myColumn]] <- ifelse( fishing_x[[myColumn]]>=0.05, fishing_x[[myColumn]] , 0 )
		}
	  # expression for the calculation of average SAR and conversion to MOP:
	  sum <- paste(fishingYearSARcolumns,collapse='+')
	  avgSAR <- paste("(", sum, ")/",length(fishingYearSARcolumns))
	}
	
	# convert SAR into MOP:
	fishing_x <- makeAvg(fishing_x,avgSAR) %>%
		mutate(MOP = case_when(
		sar_avg == 0							~ 'none',
		sar_avg  > 0	 & sar_avg < 0.33 ~ 'very low',
		sar_avg >= 0.33 & sar_avg < 0.66 ~ 'low',
		sar_avg >= 0.66 & sar_avg < 2	   ~ 'moderate',
		sar_avg >= 2							~ 'high',
		TRUE									   ~ 'undefined'
	))
	
	cumi_message("... cleaning up ...")
	# we can now delete the columns we do not need in future
	# and we can remove all polygons with no MOP
	# and dissolve the MOP layer:
	fishing_x <- fishing_x %>%
		dplyr::select(-starts_with("F20")) %>%
		dplyr::select(-c("Shape_Leng","Shape_Area","sar_avg")) %>%
		dplyr::filter(! MOP=='none') %>%
		group_by(MOP) %>% 
		summarize(geometry = st_union(geometry)) %>%
		st_make_valid()
	
	if (store_pressure_maps) {
		st_write(fishing_x,pressure_maps_file, layer = "mop_1")
	}
	
	if (do_cumi) {
		cumi_message(" ... calculating fishing impact -> this will take a lot of time, so see you tomorrow or later ...")
		# the my_union() in the following line is what takes 99.9% of the time in this pressure,
		# you might want to use ArcGIS for this particular 'union' task below as it is even significantly faster than QGIS
		# (4-7 minutes on my machine using ArcGIS compared to approx. 12-15 hours with QGIS via R !!!).
		# When doing the union with QGIS, some sliver polygons will result. These have missing biotope assignment and need to be
		# deleted with `filter(! is.na(Biotope))`
		#
		# (for the current ssessment, the QGIS function was used)
		#
		impact_map <- impact_map %>%
			st_cast("MULTIPOLYGON") %>%
			my_union(fishing_x) %>%
			st_cast("MULTIPOLYGON") %>%
			dplyr::mutate(impact_1 = unname(mapply(cumi_get_impact,MOP,s_surf))) %>%
			dplyr::select(-MOP) %>%
			st_make_valid()
		
		# confidence:
		impact_map <- impact_map %>% mutate(confidence_1 = "none")
		impact_map$confidence_1[impact_map$Territory != "Russia"] <- "d3t3s1"
		impact_map$confidence_1[impact_map$Territory == "Russia"& impact_map$impact_1 != "none"] <- "d3t3s1"
		impact_map$confidence_1[impact_map$Territory == "Russia"& impact_map$impact_1 == "none"] <- "d0t0s0"
		st_write(impact_map,file.path(myDir,"Fishery/fishery_pre_calculated.gpkg"))
	}
}

```
### 2. Mariculture

```{r}
cumi_message("processing of mariculture ...")
```

The data set contains point data from the HELCOM Pollution Load Compilation (PLC) data collection covering the period from 2016 to 2020. The data also show in which years there has been some production. This could in future be used to apply a pressure frequency calculation (see proposal below).

The confidence is rated 'd2t3s1':

- data quality is rated 2 as data are used without the available quantitative information
- temporal coverage is rated 3 (one year missing)
- spatial coverage is rated 1 (assumed, as data set does not include information on reporting countries)

```{r}
cumi_message("... finfish ...")
mari_1_file <- file.path(myDir,"Mariculture/Finfish_PLC/Finfish_PLC.shp")
mari_1 <- st_read(mari_1_file)

if (do_cumi || store_pressure_maps) {
	# In this case, MOP is the same as intensity as frequency is not applicable:
	impact_map <- cumi_process_pressure(mari_1,"mariculture","2A")
}
if (do_cumi) {
	# confidence:
	impact_map <- impact_map %>% mutate(confidence_2A = "d2t3s1")
}

```


The data set was provided by HELCOM and was originally taken from EMODnet. It contains point data and only includes sites from Denmark (taken from the official lists of registered aquaculture sites). Data for Germany are missing. There is no shellfish production in other MS than Denmark and Germany within the HELCOM assessment area.

The production status is not included in the data set and is thus assumed to be "active"). Therefore, all sites are taken into account.

The confidence is rated 'd2t0s1' for Denmark and 'd0t0s0' for Germany:

- data quality is rated 2 for Denmark as data carries no quantitative information
- temporal coverage is rated 0 (no information available for individual years)
- spatial coverage is rated 1 for Denmark, 0 for Germany

```{r}
cumi_message("... shellfish (points) ...")
mari_2_file <- file.path(myDir,"Mariculture/Aquaculture_Shellfish_EMODnets/Aquaculture_Shellfish_EMODnets.shp")
mari_2 <- st_read(mari_2_file)

if (do_cumi || store_pressure_maps) {
	# In this case, MOP is the same as intensity as frequency is not applicable:
	impact_map <- cumi_process_pressure(mari_2,"mariculture","2B")
}
if (do_cumi) {
# confidence:
	impact_map <- impact_map %>% mutate(confidence_2B = "none")
	impact_map$confidence_2B[impact_map$Territory == "Denmark"] <- "d2t0s1"
	impact_map$confidence_2B[impact_map$Territory == "Germany"] <- "d0t0s0"
}
```

These are no polygon data for the assessment period.

```{r eval=FALSE}
cumi_message("... shellfish (areas) ...")
mari_3_file <- file.path(myDir,"Data/...")
mari_3 <- st_read(mari_3_file)

if (do_cumi || store_pressure_maps) {
	impact_map <- cumi_process_pressure(mari_3,"mariculture","2C")
}
```

### 3. Extraction and disposal of sediments

```{r}
cumi_message("processing extraction and disposal of sediments ...")
```

Data layer from HELCOM, reported by Estonia, Finland and Germany. The data are polygon data.

Extraction depth and the spatial extent of the extraction within the polygon is unknown. Therefore, the complete polygon area is precautionarily treated as loss. All listed sites are assumed active when there was at least one event within the assessment period. Otherwise, no impact was assumed.

Frequency could be evaluated from this data set as the data set has information on the yearly amount. This could in future be used to apply a pressure frequency calculation (see proposal below).

The confidence is rated 'd1t1s1' for Estonia, Finland and Germany and 'd0t0s0' for the other countries:

- data quality is rated 1 as the reported extraction amount alone cannot be used (missing information on extraction depth and aereal extent within the extraction site)
- temporal coverage is rated 1 (we can exclude sites which have not been used within the assessment period)
- spatial coverage is rated 1 for Estonia, Finland and Germany, 0 for the remaining countries

```{r}
cumi_message("... extraction of sand and gravel ...")
extraction_file <- file.path(myDir,"Extraction_Disposal/Extraction_of_sand_and_gravel/ExtractonSandGravel.shp")
extraction_x <- st_read(extraction_file) %>% st_zm()

# filter out all sites which had an amount of 0 in all years:
amountColumns <- c()
for(myYear in assessmentYears) {amountColumns <- c(amountColumns,paste("amount",myYear,sep=""))}
# expression to calculate the total amount:
sum <- paste(amountColumns,collapse='+')
sumAmount <- paste("(", sum, ")/",length(amountColumns),"> 0")
filterSum <- function(myLayer,myString) {
	q <- quote(filter(myLayer,myString))
	eval(parse(text=sub("myString", myString, deparse(q))))
}
extraction_x <- filterSum(extraction_x,sumAmount)

if (do_cumi || store_pressure_maps) {
	# In this case, MOP is the same as intensity as frequency is currently ignored:
	impact_map <- cumi_process_pressure(extraction_x,"extraction","3A")
}
if (do_cumi) {
	# confidence:
	impact_map <- impact_map %>% mutate(confidence_3A = "none")
	impact_map$confidence_3A[impact_map$Territory %in% c("Estonia","Finland","Germany")] <- "d1t1s1"
	impact_map$confidence_3A[! impact_map$Territory %in% c("Estonia","Finland","Germany")] <- "d0t0s0"
}

```


Data layer with polygon data. All sites are included in the calculation. No loss is included for the footprint as it is unknown to what extent the actual area is being used and typically only a part of the designated area is actively used.

Frequency could be evaluated from this data set as the data set has information on the years in which the deposit occurs per site. This could in future be used to apply a pressure frequency calculation (see proposal below).

The confidence is rated 'd1t3s1':

- data quality is rated 1 as the reported deposition amount alone cannot be used (missing information on deposition height and areal extent within the deposition site)
- temporal coverage is rated 3 (data from 2021 are missing)
- spatial coverage is rated 1 (all countries have provided data)


```{r}
cumi_message("... deposit of dredged material (areas) ...")
deposit_1_file <- file.path(myDir,"Extraction_Disposal/depositing/depositing_areas_dissolved.shp")
deposit_1 <- st_read(deposit_1_file)

# we remove the German data here to take the ones from the correction data instead:
deposit_1 <- deposit_1 %>% filter(! str_detect(Helcom_sit,"^DE/"))
deposit_1_de_file <- file.path(myDir,"Extraction_Disposal/depositing/depositing_areas_DE.shp")
deposit_1_de <- st_read(deposit_1_de_file) %>% select(geometry)

# the correction from Sweden seems to be an update for most site, but there are two new sites which we include:
deposit_1_se_file <- file.path(myDir,"Extraction_Disposal/depositing/HELCOM_Deposit_polygon_SE.shp")
deposit_1_se <- st_read(deposit_1_se_file) %>%
	st_transform(coordSystem) %>%
	st_zm() %>%
	filter(Deposit_id %in% c("SE362","SE490")) %>%
	select(geometry)

# put all data together:
# as we currently do not evaluate frequency, we can reduce the data to only contain the geometry.
# This makes it easier to include the correction data
deposit_1 <- select(deposit_1,geometry) %>% rbind(.,deposit_1_de,deposit_1_se)

if (do_cumi || store_pressure_maps) {
	# In this case, MOP is the same as intensity as frequency is currently ignored:
	impact_map <- cumi_process_pressure(deposit_1,"depositing","3B")
}
if (do_cumi) {
	# confidence:
	impact_map <- impact_map %>% mutate(confidence_3B = "d1t3s1")
}

```


Data layer with point data. All sites are included in the calculation. No loss is included for the footprint as it is unknown to what extent the actual area is being used and typically only a part of the designated area is actively used.

Frequency could be evaluated from this data set for some sites in some countries (Germany, Sweden) as the data set has information on the years in which the deposit occurs per site. This could in future be used to apply a pressure frequency calculation (see proposal below).

The confidence is rated 'd1t3s1':

- data quality is rated 1 as the reported deposition amount alone cannot be used (missing information on deposition height and areal extent within the deposition site)
- temporal coverage is rated 3 (data from 2021 are missing)
- spatial coverage is rated 1 (all countries have provided data)



```{r}
cumi_message("... deposit of dredged material (points) ...")
deposit_2_file <- file.path(myDir,"Extraction_Disposal/depositing/depositing_points.shp")
deposit_2 <- st_read(deposit_2_file)

# corrections from DE:
deposit_2_de_file <- file.path(myDir,"Extraction_Disposal/depositing/depositing_points_DE.shp")
deposit_2_de <- st_read(deposit_2_de_file)
# remove all entries from main data that have DE corrections:
de_corr <- deposit_2_de$Helcom_sit
deposit_2 <- deposit_2 %>% filter(! Helcom_sit %in% de_corr)
# prepare DE data for inclusion:
deposit_2_de <- select(deposit_2_de,geometry)

# the same game for SE data corrections:
deposit_2_se_file <- file.path(myDir,"Extraction_Disposal/depositing/HELCOM_Deposit_point_SE.shp")
deposit_2_se <- st_read(deposit_2_se_file) %>% st_transform(coordSystem)
# remove all entries from main data that have SE corrections:
se_corr <- deposit_2_se$Deposit_id
deposit_2 <- deposit_2 %>% filter(! Helcom_sit %in% se_corr)
# prepare SE data for inclusion:
deposit_2_se <- select(deposit_2_de,geometry)

deposit_2 <- select(deposit_2,geometry) %>% rbind(.,deposit_2_de,deposit_2_se)

if (do_cumi || store_pressure_maps) {
	# In this case, MOP is the same as intensity as frequency is currently ignored:
	impact_map <- cumi_process_pressure(deposit_2,"depositing","3C")
}
if (do_cumi) {
	# confidence:
	impact_map <- impact_map %>% mutate(confidence_3C = "d1t3s1")
}

```

Germany and Sweden also have provided line data for deposits.

The confidence is rated 'd1t0s1':

- data quality is rated 1 as the reported deposition amount alone cannot be used (missing information on deposition height and areal extent within the deposition site)
- temporal coverage is rated 0 (the data is assumed to only cover one-time events and no information is given for the other assessment years)
- spatial coverage is rated 1 (assumed taht all countries have provided data)


```{r}
deposit_3_file <- file.path(myDir,"Extraction_Disposal/depositing/depositing_lines.shp")
deposit_3 <- st_read(deposit_3_file)
# one of the German entries here seems having a truncated ID as the same site appears in the DE update with a full ID.
# We change it here
deposit_3$Helcom_sit[deposit_3$Helcom_sit == "14"] <- "DE/14"
deposit_3$Dredging_I[deposit_3$Helcom_sit == "DE/14"] <- "DE/14-2016-1"

# it seems the German update replaces the complete German set:
deposit_3_de_file <- file.path(myDir,"Extraction_Disposal/depositing/depositing_lines_DE.shp")
deposit_3_de <- st_read(deposit_3_de_file) %>% select(geometry)
deposit_3 <- filter(deposit_3,! str_detect(Helcom_sit,"^DE/")) %>% select(geometry)

deposit_3 <- rbind(deposit_3,deposit_3_de)

if (do_cumi || store_pressure_maps) {
	# In this case, MOP is the same as intensity as frequency is currently ignored:
	impact_map <- cumi_process_pressure(deposit_3,"depositing","3D")
}
if (do_cumi) {
	# confidence:
	impact_map <- impact_map %>% mutate(confidence_3D = "d1t0s1")
}

```

This data set represent dredging, as reported for HOLAS3 ad hoc data call and data reported according to Recommendation 36/2.  

The data layer contains polygon data for maintenance dredging. There is information on the start and end year wioch could be used for a frequency evaluation (see proposal below). The field "depth" is assumed to mean the water depth.

The confidence is rated 'd1t0s1':

- data quality is rated 1 as the reported dredging amount alone cannot be used (missing information on dredging depth  and areal extent within the dredging site)
- temporal coverage is rated 0 (as temporal information is not yet used)
- spatial coverage is rated 1 (assumed that all countries have provided data)

```{r}
cumi_message("... maintenance dredging (areas) ...")
dredge_a_file <- file.path(myDir,"Dredging/dredgingmantainance_poly.shp")
dredge_1 <- st_read(dredge_a_file) %>% st_zm() %>% select(geometry)

# the original HOLAS III file does not contain any SE data:
# SE data (the only valid file is the one from 2022-07-01, the one from the day before did not contain everything):
dredge_1_se_file <- file.path(myDir,"Dredging/polygonCopy_SE.shp")
dredge_1_se <- st_read(dredge_1_se_file) %>% select(geometry)

# corrected DE data (comparing the initial HOLAS III and the update, these are different sites and years
# and both are kept):
dredge_1_de_file <- file.path(myDir,"Dredging/dredging_areas_DE.shp")
dredge_1_de <- st_read(dredge_1_de_file) %>% st_make_valid() 
# one site is marked "capital", so we save that ine as capital dredging:
dredge_2 <- filter(dredge_1_de,Dredging_a == "capital")
dredge_1_de <- dredge_1_de %>% filter(! Dredging_a == "capital") %>% select(geometry)

dredge_1 <- rbind(dredge_1,dredge_1_de,dredge_1_se)

if (do_cumi || store_pressure_maps) {
	# In this case, MOP is the same as intensity as frequency is currently ignored:
	impact_map <- cumi_process_pressure(dredge_1,"dredging M","3E")
}
if (do_cumi) {
	# confidence:
	impact_map <- impact_map %>% mutate(confidence_3E = "d1t0s1")
}

cumi_message("... capital dredging (areas) ...")

if (do_cumi || store_pressure_maps) {
	# In this case, MOP is the same as intensity as frequency is currently ignored:
	impact_map <- cumi_process_pressure(dredge_2,"dredging CAP","3F")
}
if (do_cumi) {
	# confidence:
	impact_map <- impact_map %>% mutate(confidence_3F = "d1t0s1")
}

```

Point data labelled 'maintenence', so the amount is ignored and the 5000 m^3^ threshold ignored. Most data do have information on the dredging amount.

The confidence is rated 'd1t0s1':

- data quality is rated 1 as the reported dredging amount alone cannot be used (missing information on dredging depth  and areal extent within the dredging site) and most sites do no report the amount
- temporal coverage is rated 0 (as temporal information is not yet used and mostly not available)
- spatial coverage is rated 1 (assumed that all countries have provided data)


```{r}
cumi_message("... maintenence dredging (points) ...")
dredge_p_file <- file.path(myDir,"Dredging/dredgingmantainance_point.shp")
dredge_3 <- st_read(dredge_p_file) %>% st_zm() %>% select(geometry)

# SE data:
dredge_p_se_file <- file.path(myDir,"Dredging/point_SE.shp")
dredge_p_se <- st_read(dredge_p_se_file) %>% select(geometry)

# DE data:
dredge_p_de_file <- file.path(myDir,"Dredging/dredging_points_DE.shp")
dredge_p_de <- st_read(dredge_p_de_file) %>% select(geometry)

dredge_3 <- rbind(dredge_3,dredge_p_se,dredge_p_de)

if (do_cumi || store_pressure_maps) {
	# In this case, MOP is the same as intensity as frequency is currently ignored:
	impact_map <- cumi_process_pressure(dredge_3,"dredging M","3G")
}
if (do_cumi) {
	# confidence:
	impact_map <- impact_map %>% mutate(confidence_3G = "d1t0s1")
}

```

Line data from German, no amount reported, maintenance dredging assumed:

The confidence is rated 'd1t0s1':

- data quality is rated 1 as the dredging amount is not reported
- temporal coverage is rated 0 (as temporal information is not yet used)
- spatial coverage is rated 1 (assumed that all countries have provided data)

```{r}
dredge_l_file <- file.path(myDir,"Dredging/dredging_lines_DE.shp")

dredge_l <- st_read(dredge_l_file)

if (do_cumi || store_pressure_maps) {
	# In this case, MOP is the same as intensity as frequency is currently ignored:
	impact_map <- cumi_process_pressure(dredge_l,"dredging M","3H")
}
if (do_cumi) {
	# confidence:
	impact_map <- impact_map %>% mutate(confidence_3H = "d1t0s1")
}

```



### 4. Pipelines and cables

```{r}
cumi_message("processing pipelines and cables ...")
```

Polygon data. Pipelines in planning are ignored. Data with empty Status are assumed 'operational'. For SE, HOLAS II data should be applied. However, the HOLAS II data do not contain pipelines assigned to SE.

The confidence is rated 'd1t0s1':

- data quality is rated 1 as there are no quantitative data on trenches nd amounts
- temporal coverage is rated 0 (as temporal information is not yet used)
- spatial coverage is rated 1 (assumed that all countries have provided data)


```{r}
cumi_message("... pipelines ...")
pipeline_file1 <- file.path(myDir,"Pipelines_Cables/Pipelines_polygons.shp")

# piplines under construction:
pipeline_c <- st_read(pipeline_file1) %>% st_zm() %>%
	filter(Status == "under construction") %>%
	select(geometry)

pipeline_file1 <- file.path(myDir,"Pipelines_Cables/PIPELINE_append.shp")

# pipelines in operation:
# ignore "planned", treat NULL as operational:
pipeline_o1 <- st_read(pipeline_file1) %>% filter(Status %in% c("operational","built but not in use"))
pipeline_o2 <- st_read(pipeline_file1) %>% filter(is.na(Status))
pipeline_o <- rbind(pipeline_o1,pipeline_o2)

# there is an updated data set from DE, but the Status is either "aslaid" or "4", both of which cannot be interpreted.

if (do_cumi || store_pressure_maps) {
	# In this case, MOP is the same as intensity as frequency does not apply
	impact_map <- cumi_process_pressure(pipeline_c,"pipeline C","4A")
}
if (do_cumi) {
	impact_map <- impact_map %>% mutate(confidence_4A = "d1t0s1")
}

if (do_cumi || store_pressure_maps) {
	impact_map <- cumi_process_pressure(pipeline_o,"pipeline O","4B")
}
if (do_cumi) {
	impact_map <- impact_map %>% mutate(confidence_4B = "d1t0s1")
}

```


Cable data.

The confidence is rated 'd1t0s1':

- data quality is rated 1 as there are no quantitative data
- temporal coverage is rated 0 (as temporal information is not yet used)
- spatial coverage is rated 1 (assumed that all countries have provided data)


```{r}
cumi_message("... cables in operation ...")
# the file CABLES_polygones.shp does only have cables in planning or where application is submitted.
# Thus, there is no cable yet and the data can be ignored.
# The "append" file only has various forms of cable in operation and none under construction:
cable_o_file <- file.path(myDir,"Pipelines_Cables/CABLES_append.shp")
cable_o <- st_read(cable_o_file) %>%
	filter(Status %in% c('Operational', 'operational','completed','Out of use','Unknown')) %>%
	select(geometry) %>%
	st_cast("LINESTRING")

# all assumed to be after construction, i.e. in operation (Status = '4', '11', 'in Probebetrieb'):
cable_o2_file <- file.path(myDir,"Pipelines_Cables/CABLES_DE.shp")
cable_o2 <- st_read(cable_o2_file) %>%
	st_zm() %>%
	select(geometry) %>%
	st_cast("LINESTRING")

cable_o <- rbind(cable_o, cable_o2)

# In this case, MOP is the same as intensity as frequency does not apply:
## this step notoriously fails with an error due to MULTILINESTRINGS
## and missing function arguments in some intermediate step.
### Alternative is to dissect cumi_process_pressure into manual steps:
### - intensity_layer <- cumi_buffer_intensity(pressureData,pressureType)
#intensity_layer <- cumi_buffer_intensity(cable_o,"cable O")
#st_write(intensity_layer,file.path(myDir,"Results/tmp1.shp"))
#st_write(impact_map,file.path(myDir,"Results/tmp2.shp"))
### - union intensity_layer with impact_map in ArcGIS
#readline(prompt="Make sure you have the ArcGIS union result ready as 'impact_map' here: ")
### - apply impact in R
# (the last line st_cast will also remove some nasty LINESTRING and MULTILINESTRING)
#impact_map <- impact_map %>%
#	dplyr::mutate(impact_4C := unname(mapply(cumi_get_impact,intensity,sens))) %>% 
#	dplyr::select(-intensity) %>%
#	filter(! is.na(Biotope)) %>%
#	st_make_valid() %>%
#	st_cast("MULTIPOLYGON")

if (do_cumi || store_pressure_maps) {
	impact_map <- cumi_process_pressure(cable_o,"cable O","4C")
}
if (do_cumi) {
	# confidence:
	impact_map <- impact_map %>% mutate(confidence_4C = "d1t0s1")
}

```



### 5. Platforms and wind farms

```{r}
cumi_message("processing platforms and wind farms ...")
```

These are point data. As we do not know from most of the data which kind of fundament the turbines have, we cannot determine whether or not to treat the footprint area as loss (only for one type 'artificial island' this could be possible but we do not know the extent of the island). Currently, we do not treat the the footprint as loss when the type is unknown. For monopile fundaments, the footprint is treated as loss.

The German data also include information about the fundament type. The monopiles are treated as loss.

The confidence is rated 'd1t0s1':

- data quality is rated 1 as there are no quantitative data
- temporal coverage is rated 0 (as temporal information is not yet used)
- spatial coverage is rated 1 (assumed that all countries have provided data)

```{r}
cumi_message("... wind farms in operation ...")
# the file only seems to contains turbines, at least there is no information on transformer platforms included:
wind_file <- file.path(myDir,"Wind_turbines/WINDTURBINES_append.shp")
wind_x <- st_read(wind_file) %>% select(geometry)

# German data (reading this file will result in warnings on the content of the field
# Pcapacity which we can ignore):
wind_de_file <- file.path(myDir,"Wind_turbines/WIND TURBINES_DE.shp")
wind_de <- st_read(wind_de_file)

wind_x2 <- filter(wind_de,! Foundation == "monopile") %>% select(geometry)
wind_x <- rbind(wind_x,wind_x2)

if (do_cumi || store_pressure_maps) {
	# In this case, MOP is the same as intensity as frequency does not apply:
	impact_map <- cumi_process_pressure(wind_x,"OWF O","5A")
}
if (do_cumi) {
	impact_map <- impact_map %>% mutate(confidence_5A = "d1t0s1")
}

# now the monopiles:
wind_de <- filter(wind_de,Foundation == "monopile")

if (do_cumi || store_pressure_maps) {
	# In this case, MOP is the same as intensity as frequency does not apply:
	impact_map <- cumi_process_pressure(wind_de,"OWF O mono","5B")
}
if (do_cumi) {
	impact_map <- impact_map %>% mutate(confidence_5B = "d1t0s1")
}

```


### 6. Coastal protection

```{r}
cumi_message("processing coastal protection ...")
```

Various data sets are included here.

The main file is polygon data and contains data with status 'operational' and 'executed'. The latter is interpreted as being 'operational' also. Also data without status are treated as 'operational' as they typically have a 'year' attribute with a value earlier than 2021. Another set of polygon data is provided by SE. It has no information on the status and is treated as 'operational'.

The same applies to the main point data and the SE point data.

The line data have status such as 'reconstruction', 'new building', 'operational', 'executed', 'Gældende' and NULL (for older HOLAS II data). All of these are treated as operational. For many of the DK data, it cannot be seen whether it has an impact on the marine environment at all, so these data are used under the assumption that they have. Some older HOLAS II data are marked as 'Under construction' and are consequently treated as such.

The confidence is rated 'd1t0s1':

- data quality is rated 1 as there are no quantitative data
- temporal coverage is rated 0 (as temporal information is not yet used)
- spatial coverage is rated 1 (assumed that all countries have provided data)

```{r}
# main polygon data, all treated as operational:
def_1_file <- file.path(myDir,"Coastal_defense/CoastalDefense_polygons.shp")
def_1 <- st_read(def_1_file) %>% st_zm() %>% st_make_valid() %>% select(geometry)

# SE polygon data, treated as operational:
def_2_file <- file.path(myDir,"Coastal_defense/coastal_defence_3035_SE.shp")
def_2 <- st_read(def_2_file) %>% st_zm() %>% select(geometry)

# main point data, all treated as operational:
def_3_file <- file.path(myDir,"Coastal_defense/CoastalDefense_points.shp")
def_3 <- st_read(def_3_file) %>% select(geometry)

# SE point data, no information on status, treated as operational:
def_4_file <- file.path(myDir,"Coastal_defense/coastal_defence_point_3035_SE.shp")
def_4 <- st_read(def_4_file) %>% st_transform(coordSystem) %>% select(geometry)

# line data:
def_5_file <- file.path(myDir, "Coastal_defense/CoastalDefence_lines_APPEND.shp")
def_5 <- st_read(def_5_file)
def_5_o1 <- filter(def_5, Status %in% c('reconstruction', 'new building', 'operational', 'executed', 'Gældende'))
def_5_o2 <- filter(def_5, is.na(Status))
coastalDef_line_constr <- filter(def_5, Status == "Under construction")


cumi_message("... coastal protection in operation ...")

# polygon data:
coastalDef_polygon <- rbind(def_1,def_2)

if (do_cumi || store_pressure_maps) {
	# MOP is the same as intensity as frequency does not apply:
	impact_map <- cumi_process_pressure(coastalDef_polygon,"coastalDef O","6A")
}
if (do_cumi) {
	impact_map <- impact_map %>% mutate(confidence_6A = "d1t0s1")
}

# point data:
coastalDef_point <- rbind(def_3,def_4)

if (do_cumi || store_pressure_maps) {
	# MOP is the same as intensity as frequency does not apply:
	impact_map <- cumi_process_pressure(coastalDef_point,"coastalDef O","6B")
}
if (do_cumi) {
	impact_map <- impact_map %>% mutate(confidence_6B = "d1t0s1")
}

# line data:
coastalDef_line <- rbind(def_5_o1,def_5_o2)

if (do_cumi || store_pressure_maps) {
	# MOP is the same as intensity as frequency does not apply:
	impact_map <- cumi_process_pressure(coastalDef_line,"coastalDef O","6C")
}
if (do_cumi) {
	impact_map <- impact_map %>% mutate(confidence_6C = "d1t0s1")
}

cumi_message("... coastal protection under construction ...")

# line data:

if (do_cumi || store_pressure_maps) {
	# MOP is the same as intensity as frequency does not apply:
	impact_map <- cumi_process_pressure(coastalDef_line_constr,"coastalDef C","6D")
}
if (do_cumi) {
	impact_map <- impact_map %>% mutate(confidence_6D = "d1t0s1")
}

```


### 7. Shipping

The shipping data are yearly density measurements (period 2016-2020) based on all IMO registered ships operating in the Baltic Sea. Shipping density is defined as the number of ships crossing a 1 x 1km grid cell. The raw AIS data used for creating the density maps is based on HELCOM AIS (Automatic Identification System) data. The HELCOM AIS network hosts all the AIS signals received by the Baltic Sea States since 2005.

The confidence is rated 'd3t3s1':

- data quality is rated 3 as there are quantitative measured data
- temporal coverage is rated 3 (as temporal information is not yet used)
- spatial coverage is rated 1 (assumed that all countries have provided data)


```{r}
cumi_message("processing shipping ...")

ship_folder <- file.path(myDir,"Shipping")

# note: I had to rename the file with the 2020 data since the filename was missing an 's'
# compared to the files for the other years:
myFiles <- c()
for (myYear in assessmentYears[1:5]) {
	myRaster <- paste(myYear," All shiptypes AIS Shipping Density.tif",sep="")
	myFiles <- c(myFiles,file.path(ship_folder,myRaster))
}

# calculate the mean density:
ship_mean <- app(rast(myFiles),mean)

# vectorize (this takes some time to process):
ship_vect <- as.polygons(ship_mean,dissolve=FALSE) %>% st_as_sf()
ship_vect <- filter(ship_vect, mean > 0) %>%
	st_cast("MULTIPOLYGON") %>%
	st_cast("POLYGON") %>%
	rename(density = mean)

# add in the average depth per polygon:
depths <- rast(file.path(myDir,"Base/depth rasters/depth_1x1km.tif"))
tmp <- terra::extract(depths,vect(ship_vect), 'mean')
ship_vect <- cbind(ship_vect,tmp) %>% st_as_sf() %>% rename(depth = depth_1x1km)

# remove all data below 25m depth (= no impact assumed)
ship_vect <- filter(ship_vect,depth <= 25)

# classify depths into zones:
ship_vect <- mutate(ship_vect, depthzone = case_when(
 depth > 0 & depth <= 10 ~ 1,
 depth > 10 & depth <= 15 ~ 2,
 depth > 15 & depth <= 20 ~ 3,
 depth > 20 & depth <= 25 ~ 4,
 TRUE ~ 0
))

# translate the density depending on the depthzone into a new attribute column ‘intensity’:
# Weighted with depth:
# dephtzone 1: equiv. to 100 % => density value is taken directly
# depthzone 2: equiv. to  50 % => density value divided by 2
# depthzone 3: equiv. to  25 % => density value divided by 4
# depthzone 4: equiv. to  10 % => density value divided by 10
# depthzone 5: equiv. to	0 % => polygon is removed (everything over 25 m)

# new attribute column 'intensity':
ship_vect <- dplyr::mutate(ship_vect, intensity = case_when(
  depthzone == 1 ~ density,
  depthzone == 2 ~ density/2.0,
  depthzone == 3 ~ density/4.0,
  depthzone == 4 ~ density/10.0,
  TRUE ~ 0 
))

# new attribute column 'MOP':
# reclassify the intensity into the four MOP classes
# (we ignore frequency at this stage, usinf the maverage density for now, 
# but frequency can be included following the proposal below).
#
# After the above steps, intensity values from 0 to 32166 remain. These are divided pragmatically into the uniform CumI scale:
maxDens <- max(ship_vect$intensity)
ship_vect <- mutate(ship_vect, MOP = case_when(
 intensity >=	  0 & intensity <	maxDens/4 ~ 'very low',
 intensity >=  maxDens/4 & intensity <  maxDens/2 ~ 'low',
 intensity >= maxDens/2 & intensity <  maxDens/4*3 ~ 'moderate',
 intensity >= maxDens/4*3 & intensity <= maxDens ~ 'high',
 TRUE ~ 'unknown'
))

# dissolve the polygons by MOP only to reduce file size and risk of artifacts.
ship_vect <- ship_vect %>% group_by(MOP) %>% summarize() %>% st_cast("MULTIPOLYGON")

if (store_pressure_maps) {
	st_write(ship_vect,pressure_maps_file, layer = "mop_7")
}

if (do_cumi) {
	# the union in the following statement took roughly 30 hours on my machine using the QGIS function, on ArcGIS the union fails with an unspecific error:
	impact_map <- st_cast(impact_map,"MULTIPOLYGON") %>% 
		my_union(ship_vect) %>% 
		dplyr::mutate(impact_7 = unname(mapply(cumi_get_impact,MOP,sens))) %>% 
		dplyr::select(-c(MOP)) %>%
		rename_geometry("geometry") %>%
		filter(! is.na(Biotope))
	
	# confidence:
	impact_map <- impact_map %>% mutate(confidence_7 = "d3t3s1")
}

```



## Calculate cumulative impact

```{r}
if (do_cumi) {cumi_message("Cumulating all impacts ...")}
```


Now, all individual impacts are calculated and integrated into the biotope map. So, we can now do the cumulation step by taking every single polygon, looking at all individual impacts for that polygon and then do a pair-wise combination:


```{r}
if (do_cumi) {
	#
	# the following code is explicit and thus slow (approx. 40 minutes on my machine), will be speed-optimized later
	#
	# make list of all impact columns to loop over:
	impactColumns <- grep("impact_[1-9].?",names(impact_map),value=TRUE)
	
	# initialize a new column 'cumi' for the cumulative impact:
	impact_map <- mutate(impact_map,cumi = NA)
	
	initialColumn <- impactColumns[1]
	columnCount <- length(impactColumns)
	
	# loop over each polygon/multipolygon in the map:
	print(paste("0 of",nrow(impact_map)))
	for (myRowIndex in 1:nrow(impact_map)) {
		rowData <- impact_map[myRowIndex, ]
		if (myRowIndex %% 2000 == 0) {print(paste(myRowIndex,"of",nrow(impact_map))); flush.console()}
		# foreach pair of impact columns, do the cumulation:
		for (myColIndex in 1:(columnCount-1)) {
			if (myColIndex == 1) {i1 <- rowData[[impactColumns[1]]]} else {i1 <- ik}
			i2 <- rowData[[impactColumns[myColIndex+1]]]
			ik <- cumi_get_cumulation(i1,i2)
		}
		impact_map$cumi[myRowIndex] <- ik
	}
}
```

As the last step, cumulative disturbance and loss are separated. The CumI does only evaluated disturbance. The loss layer can be used for e.g. MSFD criterion D6C4.

```{r}
if (do_cumi) {
	impact_map_loss <- impact_map %>% filter(cumi == 'loss')
	impact_map_disturbance <- impact_map %>% filter(! cumi == 'loss')
}

```



```{r}
n2 <- Sys.time()
cumi_message("Finished assesment!")
print(n2)
print(paste("Total assessment processing time:",get_running_time(n1,n2)))

if (do_cumi) {
	st_write(impact_map_disturbance,file.path(myDir,paste("Results/CumI-assessment-",format(Sys.time(),"%Y-%m-%dT%H%M"),".gpkg",sep= "")))
	st_write(impact_map_loss,file.path(myDir,paste("Results/physical_functional-loss-",format(Sys.time(),"%Y-%m-%dT%H%M"),".gpkg",sep= "")))
	
	# a complete file including the area of the polygons, loss and disturbance could be this:
	# impact_map <- impact_map %>% mutate(area = st_area(impact_map))
	# st_write(impact_map,file.path(myDir,paste("Results/CumI-assessment-total-",format(Sys.time(),"%Y-%m-%dT%H%M"),".gpkg",sep= "")))
}
```

The resulting CumI-assessment file has a number of columns now. This is what they mean:

- Biotope = HELCOM broadscale habitat
- sens = general pressure-independant sensitivity
- s_surf = sensitivity against surface abrasion due to bottom trawling
- s_subsurf = sensitivity against subsurface penetration due to bottom trawling (not used in this assessment)
- sens_spec = whether the sensitivity was raised to 'high' due to sensitive species
- level_2 = HELCOM subbasins 2018 (assessment units)
- Territory = country name
- Sal = bottom salinity class (from HELCOM BALANCE project)
- Sal2 = bottom salinity value range (from HELCOM BALANCE project)
- impact_xx = CumI impact category for the component specified by 'xx':
- confidence_xx = CumI confidence rating for the component specified by xx':
	- 1: Bottom trawling fishery (surface abrasion), raster data
	- 2A: Finfish mariculture, point data
	- 2B: Shellfish mariculture, point data
	- 3A: Extraction of sand and gravel, polygon data
	- 3B: Deposit of dredged material, polygon data
	- 3C: Deposit of dredged material, point data
	- 3D: Deposit of dredged material, polyline data
	- 3E: Maintenance dredging, polygon data
	- 3F: Capital dredging, polygon data
	- 3G: Maintenance dredging, point data
	- 3H: Maintenance dredging, polyline data
	- 4A: Pipelines under construction, polygon data
	- 4B: Pipelines in operation, polygon data
	- 4C: Cables in operation, polygon data
	- 5A: OWF in operation, point data
	- 5B: OWF (minopiles) in operation, point data
	- 6A: Coastal protection in operation, polygon data
	- 6B: Coastal protection in operation, point data
	- 6C: Coastal protection in operation, polyline data
	- 6D: Coastal protection under construction, polyline data
	- 7: Shipping, raster data
- cumi: the final cumulative impact category
	
# Limitations in the assessment

- currently only preliminary assignment of sensitivities to MSFD offshore biotopes
- no salinity information in "Limfjord" area and a few other bays and fjords
- no differentiation of fishing pressure according to gear type
- available frequency information not yet used (see next section)
- wind turbine fundament information currently not utilized
- the status of data from Russia is not clear

- change: the footprint of pipelines under construction is now being treated as 'loss'
- change: a buffer model for monopile fundaments for wind turbines is used which is identical to the original model, only change is that the footprint is treated as loss

## Pressure frequency
Frequency is currently not used in the assessment as there was no frequency information for the former data set (years 2011-2016) and thus it could not be part of the CumI development and testing phase. To keep the current assessment as close as possible to the one agreed for HOLAS III, frequency is still left out although some of the current data sets do now carry information on pressure frequency.

In the agreed CumI method, frequency is only determined on the basis of the number of pressure events per yes. However, this kind of information seems to represent a rare case. We much more often have frequency in terms of "in how many of the 6 assessment years did the pressure occur?". So, for this kind of data the frequency can be interpreted as:

* occasional = occurs in 1 (of 6) years
* regular = occurs in 2-3 years
* frequent = occurs in 4-5 years
* persistent = occurs in all 6 years

This approach can be implemented for the updated data sets and used in HOLAS III if agreed upon during the review phase of the assessment results.

# Confidence assessment

For the area for which pressure data are present, the confidence of the assessment is rated according to the categories below. The confidence rating is written as a string in the format 'dxtxsx' where the letters d, t and s stand for the three categories (**d**ata quality, **t**emporal coverage and **s**patial coverage) and the 'x' stands for the numbers within the categories below. Thus, for example, 'd2t3s1' means: data present, quantitative and based on model - 5-6 years are covered within the assessment period of 6 years - and data are present for this particular polygon.

When a pressure occurs but information is missing to assess it, the string will be 'd0t0s0'. This is the only case where all three categories are rated 0.

When not data or information is present for a particular area and thus the MOP/impact cannot be determined, the string 'none' is used for the confidence.

With this notation, we can distinguish between the following situations:

| Data    | Pressure | impact | confidence | remark
|---------|----------|--------|------------|--------
| present | yes      | yes    | 'dxtxsx'   | impact is 'very low', 'low' and so on
| present | no       | 'none' | 'dxtxsx'   | when it is known from the data that the pressure does not occur
| no      | yes      | 'none' | 'd0t0s0'   | case of missing information for a pressure known to occur
| no      | no       | 'none' | 'none'     | when it is known that the pressure does not occur

Currently, no method has been decided for an aggregation of the pressure-specific ratings to an overall confidence score for the whole assessment.

## Data quality
This rating gives information about the nature of the supplied data. The higher the quality of the data and the more information is present in the data, the higher the rating will be. Data can be based on a model, meaning that the applied buffer model in CumI relies on some general considerations on the extent and magnitude of the various MOP zones without being backed up by concrete data. Currently, only the bottom trawling data use real measurements to determine where the MOP zones are located.

* 0. No spatial data present (per pressure and country), only assumptions
* 1. Data present and qualitative
* 2. Data present, quantitative and based on model
* 3. Quantitative data based on real measurements

## Temporal coverage
All pressure data are supposed to cover the whole assessment period of six years. When a year ore more is missing in the data set or no information on the temporal distribution of the pressure is available, the rating is lower.

* 0. No information available on temporal coverage
* 1. 1-2 years are covered within the assessment period of 6 years
* 2. 3-4 years
* 3. 5-6 years

## Spatial coverage
When a specific region or country does not report data and it is known that the pressure occurs in that area, this information can be documented here. It can be rated per pressure polygon but is typicall used country-wide.

* 0. No data present
* 1. Data present


# Outlook
This version of the script is an initial version. It implements the basic features of the CumI that are needed in order to do a CumI assessment with the current HELCOM data set. In the near future, new data set will be available for HOLAS III. This will be the latest point where the script needs changes in order to work with the new or updated data (e.g. integrating pressure frequency for more pressures or a more differentiated approach to derive MOP).

Apart from this, the following updates are planned for the next version:

- some visualizations will be implemented on the resulting impact map, such as graphs on the aerial extent of the various impact levels over the whole assessment area or certain subdivisions of that area
- the pre-processing of the bottom trawling data and the shipping data will be implemented
- the pre-processing of the biotope map
- a distinction between 'no data' and 'no impact' will be implemented
- provide a switch to keep the MOP attribute per pressure in the impact map
- provide a switch to keep the partial impact maps after combining with an individual pressure (in order to easily continue after errors with a particular pressure)
- provide all GIS data as one Geopackage file instead of the mess with shapefiles

[^1]: <https://www.emodnet-seabedhabitats.eu/files/C20211007_EUSeaMap_2021_Baltic_Sea.zip>
[^2]: <https://www.emodnet-seabedhabitats.eu/files/C20211008_EUSeaMap_2021_Arctic_Atlantic.zip>
[^3]: <https://metadata.helcom.fi/geonetwork/srv/eng/catalog.search#/metadata/d4b6296c-fd19-462c-94d2-4c81b9313d77>
